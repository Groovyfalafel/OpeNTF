{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Setup Python 3.8 on Colab Environment.**"
      ],
      "metadata": {
        "id": "hsO795wNk9WL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "yzuvvMImFFWg",
        "outputId": "3f682e38-8a1a-467d-c2ce-53e2a112dd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 0 B/88.7 kB \r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [76.8 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,596 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,474 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [806 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,827 kB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [931 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [936 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [840 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,252 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,036 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 15.1 MB in 5s (2,841 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 75 not upgraded.\n",
            "Need to get 4,676 kB of archives.\n",
            "After this operation, 18.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-minimal amd64 3.8.12-1+bionic3 [762 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8-minimal amd64 3.8.12-1+bionic3 [1,825 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-stdlib amd64 3.8.12-1+bionic3 [1,656 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8 amd64 3.8.12-1+bionic3 [433 kB]\n",
            "Fetched 4,676 kB in 2s (1,879 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.8-minimal_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.12-1+bionic3) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../python3.8-minimal_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.12-1+bionic3) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.8-stdlib_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.12-1+bionic3) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../python3.8_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.12-1+bionic3) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.12-1+bionic3) ...\n",
            "Setting up python3.8-minimal (3.8.12-1+bionic3) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.12-1+bionic3) ...\n",
            "Setting up python3.8 (3.8.12-1+bionic3) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.12\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 75 not upgraded.\n",
            "Need to get 2,882 kB of archives.\n",
            "After this operation, 8,886 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Fetched 2,882 kB in 1s (3,063 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 155939 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pip\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/df/a6ef77a6574781a668791419ffe366c8acd1c3cf4709d210cb53cd5ce1c2/pip-22.0.3-py3-none-any.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 585kB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 9.0.1\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "Successfully installed pip-22.0.3\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.9.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\n",
            "Collecting ipython>=7.23.1\n",
            "  Downloading ipython-8.1.1-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.3/750.3 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline<0.2.0,>=0.1.0\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Collecting jupyter-client<8.0\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets<6.0,>=5.1.0\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado<7.0,>=4.2\n",
            "  Downloading tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.5/427.5 KB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy<2.0,>=1.0.0\n",
            "  Downloading debugpy-1.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=7.23.1->ipykernel) (39.0.1)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 KB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=13\n",
            "  Downloading pyzmq-22.3.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel) (1.11.0)\n",
            "Collecting executing\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting asttokens\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, pickleshare, executing, backcall, traitlets, tornado, pyzmq, python-dateutil, pygments, prompt-toolkit, pexpect, parso, nest-asyncio, entrypoints, decorator, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-2.0.5 backcall-0.2.0 debugpy-1.5.1 decorator-5.1.1 entrypoints-0.4 executing-0.8.3 ipykernel-6.9.1 ipython-8.1.1 jedi-0.18.1 jupyter-client-7.1.2 jupyter-core-4.9.2 matplotlib-inline-0.1.3 nest-asyncio-1.5.4 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.28 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.11.2 python-dateutil-2.8.2 pyzmq-22.3.0 stack-data-0.2.0 tornado-6.1 traitlets-5.1.1 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "jupyter_core",
                  "pexpect",
                  "pickleshare",
                  "traitlets",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "!python --version\n",
        "!sudo apt-get install python3-pip\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing OpeNTF**"
      ],
      "metadata": {
        "id": "6tKkPogYlQxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -R opentf/\n",
        "!git clone https://github.com/fani-lab/opentf\n",
        "%cd opentf/\n",
        "!pip install -r requirements.txt\n",
        "%cd src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fwIEGOF9FT4U",
        "outputId": "5792f134-fb14-4d4e-be27-b0f114968a76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 3166, done.\u001b[K\n",
            "remote: Counting objects: 100% (3166/3166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2244/2244), done.\u001b[K\n",
            "remote: Total 3166 (delta 1385), reused 2481 (delta 879), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3166/3166), 34.66 MiB | 17.18 MiB/s, done.\n",
            "Resolving deltas: 100% (1385/1385), done.\n",
            "/content/opentf\n",
            "Collecting torch>=1.6.0\n",
            "  Downloading torch-1.10.2-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1102422016 bytes == 0x388c2000 @  0x7fc456861615 0x4f69ad 0x5aa051 0x5a9f83 0x5d290c 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x4fa54a 0x556ea9 0x555bc0 0x4fa5dd 0x557802 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.60.0\n",
            "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==5.4\n",
            "  Downloading PyYAML-5.4-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.2/662.2 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.3\n",
            "  Downloading pandas-1.3.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytrec-eval-terrier==0.5.2\n",
            "  Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.4.2\n",
            "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.3->-r requirements.txt (line 7)) (2.8.2)\n",
            "Collecting pytz>=2017.3\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim==3.8.3->-r requirements.txt (line 8)) (1.11.0)\n",
            "Collecting smart-open>=1.8.1\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pytz, typing-extensions, tqdm, threadpoolctl, smart-open, PyYAML, pytrec-eval-terrier, pyparsing, pillow, numpy, kiwisolver, joblib, cycler, torch, scipy, pandas, matplotlib, scikit_learn, gensim\n",
            "Successfully installed PyYAML-5.4 cycler-0.11.0 gensim-3.8.3 joblib-1.1.0 kiwisolver-1.3.2 matplotlib-3.4.2 numpy-1.20.3 pandas-1.3.3 pillow-9.0.1 pyparsing-3.0.7 pytrec-eval-terrier-0.5.2 pytz-2021.3 scikit_learn-0.24.2 scipy-1.6.3 smart-open-5.2.1 threadpoolctl-3.1.0 torch-1.10.2 tqdm-4.60.0 typing-extensions-4.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "kiwisolver",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/opentf/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Default Hyperparameters**"
      ],
      "metadata": {
        "id": "a4G4Omoolyvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat param.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG0nCDddl5w6",
        "outputId": "515b3202-0dd3-4f68-e56a-66660b633d28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import random\n",
            "import torch\n",
            "import numpy as np\n",
            "\n",
            "random.seed(0)\n",
            "torch.manual_seed(0)\n",
            "torch.cuda.manual_seed_all(0)\n",
            "\n",
            "np.random.seed(0)\n",
            "\n",
            "settings = {\n",
            "    'model':{\n",
            "        'baseline': {\n",
            "            'random': {\n",
            "                'b': 4096\n",
            "            },\n",
            "            'fnn':{\n",
            "                'l': [100],  # list of number of nodes in each layer\n",
            "                'lr': 0.1,  # learning rate\n",
            "                'b': 4096,  # batch size\n",
            "                'e': 20,  # epoch\n",
            "                'nns': None,  # number of negative samples\n",
            "                'ns': None,  # 'uniform', 'unigram', 'unigram_b'\n",
            "            },\n",
            "            'bnn':{\n",
            "                'l': [100],  # list of number of nodes in each layer\n",
            "                'lr': 0.1,  # learning rate\n",
            "                'b': 4096,  # batch size\n",
            "                'e': 20,  # epoch\n",
            "                'nns': None,  # number of negative samples\n",
            "                'ns': None,  # 'uniform', 'unigram', 'unigram_b'\n",
            "                's': 1  # # sample_elbo for bnn\n",
            "            },\n",
            "            'emb':{\n",
            "                'd': 100,# embedding dimension\n",
            "                'e': 100,# epoch\n",
            "                'dm': 1,# training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)\n",
            "                'w': 1 #cooccurrence window\n",
            "            }\n",
            "        },\n",
            "        'cmd': ['train', 'test', 'eval', 'plot'],  # 'train', 'test', 'eval'\n",
            "        'nfolds': 3,\n",
            "        'train_test_split': 0.85\n",
            "    },\n",
            "    'data':{\n",
            "        'domain': {\n",
            "            'dblp':{},\n",
            "            'uspt':{},\n",
            "            'imdb':{},\n",
            "        },\n",
            "        'filter': {\n",
            "            'min_nteam': 75,\n",
            "            'min_team_size': 3,\n",
            "        },\n",
            "        'parallel': 1,\n",
            "        'ncore': 0,# <= 0 for all\n",
            "        'bucket_size': 500\n",
            "    },\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change Hyperparameters, e.g., Negative Sampling Heuristics and Number of Negative Samples**\n",
        "```\n",
        "settings['model']['baseline']['fnn']['ns'] = 'uniform'\n",
        "settings['model']['baseline']['fnn']['nns'] = 1\n",
        "settings['model']['baseline']['bnn']['ns'] = 'unigram_b'\n",
        "settings['model']['baseline']['bnn']['nns'] = 2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DbBMkT-2GUyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile param.py \n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "settings = {\n",
        "    'model':{\n",
        "        'baseline': {\n",
        "            'random': {\n",
        "                'b': 4096\n",
        "            },\n",
        "            'fnn':{\n",
        "                'l': [100],  # list of number of nodes in each layer\n",
        "                'lr': 0.1,  # learning rate\n",
        "                'b': 4096,  # batch size\n",
        "                'e': 20,  # epoch\n",
        "                'nns': 1,  # number of negative samples\n",
        "                'ns': 'uniform',  # 'uniform', 'unigram', 'unigram_b'\n",
        "            },\n",
        "            'bnn':{\n",
        "                'l': [100],  # list of number of nodes in each layer\n",
        "                'lr': 0.1,  # learning rate\n",
        "                'b': 4096,  # batch size\n",
        "                'e': 20,  # epoch\n",
        "                'nns': 2,  # number of negative samples\n",
        "                'ns': 'unigram_b',  # 'uniform', 'unigram', 'unigram_b'\n",
        "                's': 1  # # sample_elbo for bnn\n",
        "            },\n",
        "            'emb':{\n",
        "                'd': 100,# embedding dimension\n",
        "                'e': 100,# epoch\n",
        "                'dm': 1,# training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)\n",
        "                'w': 1 #cooccurrence window\n",
        "            }\n",
        "        },\n",
        "        'cmd': ['train', 'test', 'eval', 'plot'],  # 'train', 'test', 'eval'\n",
        "        'nfolds': 3,\n",
        "        'train_test_split': 0.85\n",
        "    },\n",
        "    'data':{\n",
        "        'domain': {\n",
        "            'dblp':{},\n",
        "            'uspt':{},\n",
        "            'imdb':{},\n",
        "        },\n",
        "        'filter': {\n",
        "            'min_nteam': 75,\n",
        "            'min_team_size': 3,\n",
        "        },\n",
        "        'parallel': 1,\n",
        "        'ncore': 0,# <= 0 for all\n",
        "        'bucket_size': 500\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "e_IpSujJGUgX",
        "outputId": "5e673d4c-3955-4570-d8ad-e1b5b54a320b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting param.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing Cache Pickles for Teams Sparse Matrix if Exist`(Optional)`**"
      ],
      "metadata": {
        "id": "a-hr8hQxVS64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R ../data/preprocessed/dblp/toy.dblp.v12.json/"
      ],
      "metadata": {
        "id": "xR1R1nUpVSLg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark on Toy subsets of DBLP and IMDB for non-Bayesian Feedforward (fnn) and Bayesian (bnn) Models as well as Random Baseline**"
      ],
      "metadata": {
        "id": "o41hWOnFoiVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -data ../data/raw/dblp/toy.dblp.v12.json ../data/raw/imdb/toy.title.basics.tsv -domain dblp imdb -model fnn fnn_emb bnn bnn_emb random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUkUAFyIXAD",
        "outputId": "eb42da1c-f69a-4dbb-dea4-3163e403ee52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "File not found! Generating the sparse matrices ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "Pickles not found! Reading raw data from ../data/raw/dblp/toy.dblp.v12.json (progress in bytes) ...\n",
            "\r  0% 0/46630 [00:00<?, ?it/s]JSONDecodeError: There has been error in loading json line `[\n",
            "`!\n",
            "Expecting value: line 2 column 1 (char 2)\n",
            "JSONDecodeError: There has been error in loading json line `]`!\n",
            "Expecting value: line 1 column 1 (char 0)\n",
            "\r100% 46606/46630 [00:00<00:00, 8782053.65it/s]\n",
            "It took 0.00823354721069336 seconds to pickle the data into ./../data/preprocessed/dblp/toy.dblp.v12.json\n",
            "It took 0.07705211639404297 seconds to generate and store the sparse matrices of size (31, 25) at ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 0.00011539459228515625 seconds to load from the pickles.\n",
            "It took 0.0004639625549316406 seconds to load the sparse matrices.\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 37.86146926879883, Time 0.008354902267456055, Overall 0.010493993759155273 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 2.2271452511058136, Time 0.008457660675048828, Overall 0.010595321655273438 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.891037940979004, Time 0.011717557907104492, Overall 0.013856172561645508 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 1.6545597712198894, Time 0.011817216873168945, Overall 0.013955354690551758 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 23.78317642211914, Time 0.017432212829589844, Overall 0.019571542739868164 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 1.3990103777717142, Time 0.01760101318359375, Overall 0.019739389419555664 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 20.005701065063477, Time 0.020586013793945312, Overall 0.02272510528564453 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 2.2228556738959417, Time 0.02067422866821289, Overall 0.0228118896484375 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 23.718902587890625, Time 0.026769399642944336, Overall 0.02890777587890625 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.3952295639935661, Time 0.02683544158935547, Overall 0.028972864151000977 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 16.789087295532227, Time 0.02929973602294922, Overall 0.031438350677490234 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 1.8654541439480252, Time 0.029389142990112305, Overall 0.031526803970336914 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 33.599205017089844, Time 0.036060333251953125, Overall 0.03819918632507324 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.9764238245346968, Time 0.03613400459289551, Overall 0.03827166557312012 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 31.076480865478516, Time 0.03839468955993652, Overall 0.040532827377319336 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 3.452942318386502, Time 0.03851795196533203, Overall 0.04065513610839844 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 35.348628997802734, Time 0.04557609558105469, Overall 0.047714948654174805 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.0793311175178077, Time 0.045662641525268555, Overall 0.047800540924072266 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 19.456682205200195, Time 0.048902034759521484, Overall 0.0510411262512207 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 2.1618535783555775, Time 0.04899311065673828, Overall 0.051131248474121094 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 29.4737606048584, Time 0.05600595474243164, Overall 0.05814504623413086 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.7337506238151998, Time 0.056180477142333984, Overall 0.0583188533782959 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 11.545722961425781, Time 0.059029579162597656, Overall 0.06116819381713867 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 1.2828581068250868, Time 0.059114933013916016, Overall 0.061252593994140625 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 27.596233367919922, Time 0.06531310081481934, Overall 0.06745123863220215 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 1.6233078451717602, Time 0.06537652015686035, Overall 0.06751394271850586 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 11.056278228759766, Time 0.0721275806427002, Overall 0.07426643371582031 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 1.228475358751085, Time 0.07222962379455566, Overall 0.07436776161193848 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 13.543466567993164, Time 0.07897210121154785, Overall 0.08111071586608887 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 0.7966745039995979, Time 0.07906270027160645, Overall 0.08120107650756836 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 10.917153358459473, Time 0.08231353759765625, Overall 0.08445215225219727 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 1.2130170398288302, Time 0.08240294456481934, Overall 0.08454060554504395 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 17.589384078979492, Time 0.08882832527160645, Overall 0.09096646308898926 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 1.034669651704676, Time 0.08889412879943848, Overall 0.09103131294250488 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 8.745837211608887, Time 0.09120321273803711, Overall 0.09334182739257812 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 0.9717596901787652, Time 0.09131145477294922, Overall 0.09344959259033203 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 17.77884292602539, Time 0.09723138809204102, Overall 0.09937000274658203 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 1.0458142897661995, Time 0.09733104705810547, Overall 0.09946894645690918 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 9.140935897827148, Time 0.10032105445861816, Overall 0.10246014595031738 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 1.0156595442030165, Time 0.10040712356567383, Overall 0.10254526138305664 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 18.186370849609375, Time 0.11316180229187012, Overall 0.11530089378356934 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 1.0697865205652572, Time 0.11435508728027344, Overall 0.11649394035339355 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 15.474249839782715, Time 0.11823010444641113, Overall 0.12036871910095215 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 1.7193610933091905, Time 0.12185239791870117, Overall 0.12399125099182129 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 15.932472229003906, Time 0.13512706756591797, Overall 0.1372663974761963 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 0.9372042487649357, Time 0.13524436950683594, Overall 0.13738203048706055 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 12.187929153442383, Time 0.14741063117980957, Overall 0.1495494842529297 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 1.354214350382487, Time 0.14757156372070312, Overall 0.14971017837524414 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 19.43343162536621, Time 0.15485405921936035, Overall 0.15699338912963867 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 1.1431430367862476, Time 0.15494441986083984, Overall 0.15708231925964355 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 20.418760299682617, Time 0.15815067291259766, Overall 0.16028952598571777 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 2.2687511444091797, Time 0.15824365615844727, Overall 0.16038179397583008 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 16.49360466003418, Time 0.1650257110595703, Overall 0.16716456413269043 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 0.97021203882554, Time 0.16510891914367676, Overall 0.16724658012390137 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 16.367244720458984, Time 0.1681067943572998, Overall 0.17024588584899902 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 1.818582746717665, Time 0.16820764541625977, Overall 0.17034554481506348 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 6.436985015869141, Time 0.1748509407043457, Overall 0.17698955535888672 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 0.3786461774040671, Time 0.1749255657196045, Overall 0.1770634651184082 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 12.831171989440918, Time 0.1778876781463623, Overall 0.18002605438232422 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 1.4256857766045465, Time 0.17797327041625977, Overall 0.18011116981506348 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 12.266948699951172, Time 0.1844797134399414, Overall 0.18661832809448242 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 0.7215852176441866, Time 0.18456530570983887, Overall 0.18670344352722168 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 35.58440399169922, Time 0.18752813339233398, Overall 0.189666748046875 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 3.9538226657443576, Time 0.18761062622070312, Overall 0.18974852561950684 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 7.625566482543945, Time 0.19441533088684082, Overall 0.19655370712280273 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 0.4485627342672909, Time 0.19449663162231445, Overall 0.19663405418395996 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 26.74018096923828, Time 0.1976795196533203, Overall 0.19981837272644043 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 2.9711312188042536, Time 0.20740818977355957, Overall 0.2095475196838379 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 14.600028991699219, Time 0.22327041625976562, Overall 0.22540950775146484 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 0.8588252348058364, Time 0.22337126731872559, Overall 0.2255091667175293 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 22.46853256225586, Time 0.22652816772460938, Overall 0.2286672592163086 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 2.496503618028429, Time 0.2333676815032959, Overall 0.23550677299499512 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 13.877779006958008, Time 0.24509191513061523, Overall 0.24723124504089355 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 0.8163399415857652, Time 0.2532947063446045, Overall 0.2554337978363037 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 21.672000885009766, Time 0.2581779956817627, Overall 0.2603168487548828 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 2.4080000983344183, Time 0.2583189010620117, Overall 0.26045703887939453 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 21.064477920532227, Time 0.28073644638061523, Overall 0.28287553787231445 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 1.2390869365018957, Time 0.28084754943847656, Overall 0.2829854488372803 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 32.01314926147461, Time 0.2900846004486084, Overall 0.2922239303588867 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 3.5570165846082897, Time 0.2902042865753174, Overall 0.292341947555542 \n",
            "Epoch    20: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.01165771484375, Time 0.010544061660766602, Overall 0.30587005615234375 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 2.294803394990809, Time 0.010641813278198242, Overall 0.3059666156768799 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 13.698541641235352, Time 0.013698577880859375, Overall 0.3090243339538574 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 1.5220601823594835, Time 0.013789176940917969, Overall 0.3091139793395996 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 17.73072052001953, Time 0.020339250564575195, Overall 0.31566500663757324 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 1.042983560001149, Time 0.020428180694580078, Overall 0.3157532215118408 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 21.09904670715332, Time 0.02359604835510254, Overall 0.3189220428466797 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 2.3443385230170355, Time 0.023685693740844727, Overall 0.31901001930236816 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 33.79732894897461, Time 0.046630859375, Overall 0.34195685386657715 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 1.9880781734690947, Time 0.04674196243286133, Overall 0.34206652641296387 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 23.00370216369629, Time 0.04981851577758789, Overall 0.34514403343200684 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 2.5559669070773654, Time 0.04991865158081055, Overall 0.345242977142334 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 31.71915054321289, Time 0.0566408634185791, Overall 0.35196614265441895 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 1.865832384894876, Time 0.0567319393157959, Overall 0.35205602645874023 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 21.647552490234375, Time 0.060640573501586914, Overall 0.35596609115600586 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 2.4052836100260415, Time 0.06073260307312012, Overall 0.35605740547180176 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 31.458934783935547, Time 0.07293033599853516, Overall 0.3682563304901123 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.8505255755256205, Time 0.07303047180175781, Overall 0.36835479736328125 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 16.17344093322754, Time 0.07643890380859375, Overall 0.3717646598815918 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 1.7970489925808377, Time 0.07653188705444336, Overall 0.3718564510345459 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 21.895902633666992, Time 0.08342409133911133, Overall 0.3787500858306885 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.2879942725686466, Time 0.08352136611938477, Overall 0.3788456916809082 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 15.711454391479492, Time 0.08679866790771484, Overall 0.3821239471435547 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 1.7457171546088324, Time 0.08688950538635254, Overall 0.3822140693664551 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 17.225852966308594, Time 0.09367990493774414, Overall 0.389005184173584 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 1.013285468606388, Time 0.09376311302185059, Overall 0.3890876770019531 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 20.505477905273438, Time 0.09673714637756348, Overall 0.3920624256134033 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 2.278386433919271, Time 0.09682273864746094, Overall 0.3921473026275635 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 11.575553894042969, Time 0.1031191349029541, Overall 0.39844465255737305 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 0.680914934943704, Time 0.1031951904296875, Overall 0.39851975440979004 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 22.8320255279541, Time 0.10591793060302734, Overall 0.4012434482574463 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 2.5368917253282337, Time 0.10599994659423828, Overall 0.4013242721557617 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 15.148372650146484, Time 0.11245369911193848, Overall 0.4077787399291992 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 0.8910807441262638, Time 0.1125340461730957, Overall 0.40785861015319824 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 27.96910858154297, Time 0.11541247367858887, Overall 0.4107377529144287 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 3.1076787312825522, Time 0.11549663543701172, Overall 0.41082143783569336 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 24.934354782104492, Time 0.12182760238647461, Overall 0.41715312004089355 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 1.4667267518884994, Time 0.12190747261047363, Overall 0.41723155975341797 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 25.725738525390625, Time 0.12485265731811523, Overall 0.4201779365539551 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 2.8584153917100696, Time 0.1249382495880127, Overall 0.42026305198669434 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 16.5440616607666, Time 0.13124704360961914, Overall 0.4265727996826172 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 0.9731800976921531, Time 0.13132405281066895, Overall 0.4266488552093506 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 25.816396713256836, Time 0.13427281379699707, Overall 0.4295980930328369 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 2.868488523695204, Time 0.1343543529510498, Overall 0.42967867851257324 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 10.933533668518066, Time 0.1406567096710205, Overall 0.43598222732543945 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 0.6431490393245921, Time 0.14073562622070312, Overall 0.43606066703796387 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 24.94062614440918, Time 0.1437208652496338, Overall 0.43904614448547363 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 2.771180682712131, Time 0.14380383491516113, Overall 0.43912839889526367 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 17.77134132385254, Time 0.15033364295959473, Overall 0.4456593990325928 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 1.0453730190501493, Time 0.15040874481201172, Overall 0.44573259353637695 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 27.7435302734375, Time 0.1542372703552246, Overall 0.44956231117248535 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 3.082614474826389, Time 0.15431809425354004, Overall 0.4496424198150635 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 15.44445514678955, Time 0.1707456111907959, Overall 0.46607136726379395 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 0.9084973615758559, Time 0.17653846740722656, Overall 0.4718644618988037 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 26.507089614868164, Time 0.18119168281555176, Overall 0.4765172004699707 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 2.945232179429796, Time 0.18129515647888184, Overall 0.4766197204589844 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 8.678986549377441, Time 0.18827533721923828, Overall 0.48360109329223633 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 0.5105286205516142, Time 0.18836712837219238, Overall 0.4836916923522949 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 20.79279136657715, Time 0.1914045810699463, Overall 0.48673009872436523 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 2.3103101518419056, Time 0.1914963722229004, Overall 0.48682117462158203 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 20.18438720703125, Time 0.20854878425598145, Overall 0.5038743019104004 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 1.18731689453125, Time 0.20994853973388672, Overall 0.5052738189697266 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 29.019813537597656, Time 0.21231865882873535, Overall 0.5076441764831543 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 3.2244237263997397, Time 0.21241426467895508, Overall 0.5077388286590576 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 14.726350784301758, Time 0.21917510032653809, Overall 0.5145003795623779 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 0.8662559284883387, Time 0.21926093101501465, Overall 0.5145857334136963 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 26.67388343811035, Time 0.22224020957946777, Overall 0.5175657272338867 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 2.9637648264567056, Time 0.22232913970947266, Overall 0.5176534652709961 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 9.888810157775879, Time 0.22890639305114746, Overall 0.5242316722869873 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 0.581694715163287, Time 0.2289876937866211, Overall 0.5243120193481445 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 31.700288772583008, Time 0.2320537567138672, Overall 0.527379035949707 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 3.522254308064779, Time 0.23215317726135254, Overall 0.5274777412414551 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 19.917728424072266, Time 0.23878097534179688, Overall 0.5341064929962158 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 1.1716310837689567, Time 0.23885536193847656, Overall 0.5341796875 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 27.64093780517578, Time 0.24184918403625488, Overall 0.5371739864349365 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 3.0712153116861978, Time 0.24193835258483887, Overall 0.5372631549835205 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 17.39653968811035, Time 0.24858331680297852, Overall 0.5439085960388184 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 1.0233258640064913, Time 0.24866318702697754, Overall 0.543987512588501 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 25.235610961914062, Time 0.2517232894897461, Overall 0.5470483303070068 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 2.803956773546007, Time 0.25180673599243164, Overall 0.5471315383911133 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.833526611328125, Time 0.006697654724121094, Overall 0.5565426349639893 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 2.21297370062934, Time 0.006802558898925781, Overall 0.5566468238830566 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.265080451965332, Time 0.010136842727661133, Overall 0.5599818229675293 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 1.7831350564956665, Time 0.010227203369140625, Overall 0.5600719451904297 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 27.03237533569336, Time 0.017683982849121094, Overall 0.5675289630889893 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 1.5017986297607422, Time 0.017769336700439453, Overall 0.5676138401031494 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 13.877972602844238, Time 0.020828962326049805, Overall 0.5706744194030762 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 1.7347465753555298, Time 0.020925521850585938, Overall 0.570770263671875 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 34.163230895996094, Time 0.02794504165649414, Overall 0.5777900218963623 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 1.897957271999783, Time 0.02802586555480957, Overall 0.5778703689575195 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 11.389960289001465, Time 0.030834436416625977, Overall 0.580679178237915 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 1.423745036125183, Time 0.030929088592529297, Overall 0.5807733535766602 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 19.460546493530273, Time 0.038120269775390625, Overall 0.587965726852417 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.081141471862793, Time 0.03820300102233887, Overall 0.5880470275878906 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 9.32742977142334, Time 0.04083418846130371, Overall 0.590679407119751 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 1.1659287214279175, Time 0.04091811180114746, Overall 0.5907626152038574 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 25.02311134338379, Time 0.047183990478515625, Overall 0.5970292091369629 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 1.3901728524102106, Time 0.04727458953857422, Overall 0.5971190929412842 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 12.692828178405762, Time 0.05014443397521973, Overall 0.599989652633667 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 1.5866035223007202, Time 0.05023956298828125, Overall 0.6000843048095703 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 18.3701114654541, Time 0.05724358558654785, Overall 0.607088565826416 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 1.0205617480807834, Time 0.05732917785644531, Overall 0.6071734428405762 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 15.438636779785156, Time 0.05998396873474121, Overall 0.6098287105560303 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 1.9298295974731445, Time 0.06007027626037598, Overall 0.6099145412445068 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 29.105789184570312, Time 0.06670737266540527, Overall 0.6165521144866943 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.616988288031684, Time 0.06679415702819824, Overall 0.61663818359375 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 9.14268684387207, Time 0.06949853897094727, Overall 0.6193437576293945 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 1.1428358554840088, Time 0.0695955753326416, Overall 0.6194398403167725 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 21.94902229309082, Time 0.07626557350158691, Overall 0.6261105537414551 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.2193901273939345, Time 0.07634758949279785, Overall 0.6261916160583496 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 16.285934448242188, Time 0.0789797306060791, Overall 0.6288242340087891 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 2.0357418060302734, Time 0.07906508445739746, Overall 0.6289093494415283 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 22.07121467590332, Time 0.08681631088256836, Overall 0.6366612911224365 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.22617859310574, Time 0.08690333366394043, Overall 0.6367475986480713 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 13.723642349243164, Time 0.08966565132141113, Overall 0.6395106315612793 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 1.7154552936553955, Time 0.08974957466125488, Overall 0.6395938396453857 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 29.75107192993164, Time 0.09625983238220215, Overall 0.6461050510406494 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 1.6528373294406467, Time 0.096343994140625, Overall 0.6461880207061768 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 13.574429512023926, Time 0.09903669357299805, Overall 0.6488816738128662 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 1.6968036890029907, Time 0.09912467002868652, Overall 0.6489689350128174 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 20.292335510253906, Time 0.10556864738464355, Overall 0.6554133892059326 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 1.1273519727918837, Time 0.10564804077148438, Overall 0.6554923057556152 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 16.984228134155273, Time 0.10832786560058594, Overall 0.658172607421875 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 2.123028516769409, Time 0.10842084884643555, Overall 0.6582655906677246 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 14.872281074523926, Time 0.11510682106018066, Overall 0.6649520397186279 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 0.8262378374735514, Time 0.11519241333007812, Overall 0.6650369167327881 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 18.542652130126953, Time 0.11800742149353027, Overall 0.6678524017333984 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 2.317831516265869, Time 0.11809349060058594, Overall 0.6679377555847168 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 12.868351936340332, Time 0.12897825241088867, Overall 0.6788234710693359 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.7149084409077963, Time 0.12907862663269043, Overall 0.6789231300354004 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 20.975900650024414, Time 0.13204193115234375, Overall 0.6818869113922119 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 2.6219875812530518, Time 0.13213610649108887, Overall 0.6819803714752197 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 18.926834106445312, Time 0.1392076015472412, Overall 0.6890528202056885 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.0514907836914062, Time 0.13929224014282227, Overall 0.6891367435455322 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 18.249217987060547, Time 0.14210748672485352, Overall 0.6919522285461426 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 2.2811522483825684, Time 0.14219284057617188, Overall 0.6920371055603027 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 8.537834167480469, Time 0.15604472160339355, Overall 0.7058906555175781 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 0.4743241204155816, Time 0.1561441421508789, Overall 0.7059879302978516 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 16.220916748046875, Time 0.15889716148376465, Overall 0.7087419033050537 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 2.0276145935058594, Time 0.15899181365966797, Overall 0.7088356018066406 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 11.39267349243164, Time 0.17312073707580566, Overall 0.722966194152832 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 0.6329263051350912, Time 0.1732158660888672, Overall 0.7230596542358398 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.783859252929688, Time 0.1889336109161377, Overall 0.7387793064117432 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 1.972982406616211, Time 0.18905091285705566, Overall 0.7388958930969238 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 22.586193084716797, Time 0.19929170608520508, Overall 0.7491371631622314 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.2547885047064886, Time 0.19938158988952637, Overall 0.7492256164550781 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 13.648416519165039, Time 0.2018725872039795, Overall 0.7517173290252686 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 1.7060520648956299, Time 0.20196056365966797, Overall 0.7518045902252197 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 13.022741317749023, Time 0.2241652011871338, Overall 0.7740108966827393 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 0.7234856287638346, Time 0.22767233848571777, Overall 0.7775180339813232 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 15.730463027954102, Time 0.23067522048950195, Overall 0.7805204391479492 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 1.9663078784942627, Time 0.23077082633972168, Overall 0.7806148529052734 \n",
            "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 16.776182174682617, Time 0.23990440368652344, Overall 0.7897498607635498 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 0.932010120815701, Time 0.2400059700012207, Overall 0.7898504734039307 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 28.756132125854492, Time 0.24317383766174316, Overall 0.7930185794830322 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 3.5945165157318115, Time 0.24325895309448242, Overall 0.7931032180786133 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 7.911396026611328, Time 0.2499525547027588, Overall 0.7997970581054688 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 0.43952200147840714, Time 0.250032901763916, Overall 0.7998769283294678 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 15.108732223510742, Time 0.252108097076416, Overall 0.8019523620605469 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 1.8885915279388428, Time 0.252178430557251, Overall 0.8020224571228027 \n",
            "It took 0.8029751777648926 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 9.107589721679688e-05 seconds to load from the pickles.\n",
            "It took 0.00043010711669921875 seconds to load the sparse matrices.\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 444.0578308105469, Time 0.024172067642211914, Overall 0.02649688720703125 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 26.12104887120864, Time 0.024288177490234375, Overall 0.026611328125 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 183.30967712402344, Time 0.03742170333862305, Overall 0.03974652290344238 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 20.36774190266927, Time 0.03757977485656738, Overall 0.03990340232849121 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 439.3744201660156, Time 0.07271385192871094, Overall 0.07503867149353027 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 25.845554127412683, Time 0.07283425331115723, Overall 0.07515764236450195 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 188.16502380371094, Time 0.08335709571838379, Overall 0.08568143844604492 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 20.907224867078995, Time 0.08347678184509277, Overall 0.0857999324798584 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 386.7190856933594, Time 0.1021122932434082, Overall 0.10443663597106934 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 22.74818151137408, Time 0.10223269462585449, Overall 0.10455584526062012 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 152.74217224121094, Time 0.11208128929138184, Overall 0.11440610885620117 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 16.97135247124566, Time 0.11221170425415039, Overall 0.11453509330749512 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 471.7853088378906, Time 0.13073039054870605, Overall 0.1330549716949463 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 27.752076990464154, Time 0.13084125518798828, Overall 0.1331641674041748 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 232.11781311035156, Time 0.14214515686035156, Overall 0.1444699764251709 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 25.790868123372395, Time 0.1422741413116455, Overall 0.14459729194641113 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 418.7845153808594, Time 0.1704564094543457, Overall 0.17278146743774414 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 24.63438325769761, Time 0.1705946922302246, Overall 0.17291760444641113 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 206.76895141601562, Time 0.1806354522705078, Overall 0.18296027183532715 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 22.974327935112846, Time 0.18076634407043457, Overall 0.1830897331237793 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 397.6075744628906, Time 0.22261285781860352, Overall 0.22493767738342285 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 23.388680850758274, Time 0.22274422645568848, Overall 0.2250669002532959 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 98.0854721069336, Time 0.2335524559020996, Overall 0.23587703704833984 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 10.898385789659288, Time 0.23369288444519043, Overall 0.23601627349853516 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 312.71258544921875, Time 0.2645130157470703, Overall 0.26685285568237305 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 18.3948579676011, Time 0.2646491527557373, Overall 0.26697230339050293 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 193.82550048828125, Time 0.2754952907562256, Overall 0.2778201103210449 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 21.53616672092014, Time 0.27564287185668945, Overall 0.2779667377471924 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 489.03302001953125, Time 0.2948603630065918, Overall 0.29718494415283203 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 28.766648236443014, Time 0.29498982429504395, Overall 0.2973134517669678 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 200.54112243652344, Time 0.3051009178161621, Overall 0.30742502212524414 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 22.282346937391495, Time 0.3052239418029785, Overall 0.30754733085632324 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 461.4981994628906, Time 0.3294563293457031, Overall 0.33178091049194336 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 27.146952909581803, Time 0.32958126068115234, Overall 0.33190441131591797 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 178.0887908935547, Time 0.3545846939086914, Overall 0.35690927505493164 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 19.787643432617188, Time 0.3547353744506836, Overall 0.3570587635040283 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 394.8896179199219, Time 0.38172173500061035, Overall 0.3840463161468506 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 23.228801054113053, Time 0.38182759284973145, Overall 0.38415074348449707 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 152.54820251464844, Time 0.390949010848999, Overall 0.39327406883239746 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 16.94980027940538, Time 0.39107322692871094, Overall 0.39339661598205566 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 323.6602783203125, Time 0.4215402603149414, Overall 0.42386484146118164 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 19.03883990119485, Time 0.4216642379760742, Overall 0.42398786544799805 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 219.97418212890625, Time 0.438704252243042, Overall 0.44102907180786133 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 24.441575792100693, Time 0.43885111808776855, Overall 0.4411747455596924 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 259.73046875, Time 0.46863865852355957, Overall 0.4709634780883789 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 15.278262867647058, Time 0.4687516689300537, Overall 0.47107505798339844 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 215.02435302734375, Time 0.4791903495788574, Overall 0.48151493072509766 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 23.89159478081597, Time 0.4793055057525635, Overall 0.4816286563873291 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 414.3712463378906, Time 0.5090107917785645, Overall 0.5113348960876465 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 24.37477919634651, Time 0.509108304977417, Overall 0.5114309787750244 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 194.34837341308594, Time 0.5301353931427002, Overall 0.5324594974517822 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 21.594263712565105, Time 0.5302748680114746, Overall 0.5325980186462402 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 284.9128112792969, Time 0.5604376792907715, Overall 0.5627703666687012 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 16.759577134076288, Time 0.5605835914611816, Overall 0.5629067420959473 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 186.376708984375, Time 0.5708599090576172, Overall 0.5731844902038574 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 20.70852322048611, Time 0.5710453987121582, Overall 0.573369026184082 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 363.0026550292969, Time 0.5946898460388184, Overall 0.5970141887664795 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 21.353097354664524, Time 0.5948066711425781, Overall 0.597130537033081 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 138.9038543701172, Time 0.6059885025024414, Overall 0.6083123683929443 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 15.433761596679688, Time 0.6060957908630371, Overall 0.6084184646606445 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 308.4321594238281, Time 0.6250956058502197, Overall 0.62742018699646 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 18.143068201401654, Time 0.6252131462097168, Overall 0.6275360584259033 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 164.6736297607422, Time 0.6364572048187256, Overall 0.6387815475463867 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 18.297069973415798, Time 0.6365959644317627, Overall 0.6389195919036865 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 345.9830017089844, Time 0.6575887203216553, Overall 0.6599130630493164 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 20.35194127699908, Time 0.6576943397521973, Overall 0.660017728805542 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 167.69879150390625, Time 0.6673789024353027, Overall 0.669703483581543 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 18.633199055989582, Time 0.6675012111663818, Overall 0.6698243618011475 \n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 268.4657897949219, Time 0.6867866516113281, Overall 0.689110517501831 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 15.792105282054228, Time 0.686873197555542, Overall 0.6891956329345703 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 234.05714416503906, Time 0.6965773105621338, Overall 0.6989016532897949 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 26.006349351671005, Time 0.6966888904571533, Overall 0.699012041091919 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 373.646484375, Time 0.7169108390808105, Overall 0.7192361354827881 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 21.979204963235293, Time 0.7171018123626709, Overall 0.7194256782531738 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 169.95465087890625, Time 0.7384033203125, Overall 0.7407279014587402 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 18.88385009765625, Time 0.7385685443878174, Overall 0.7408919334411621 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 278.0062255859375, Time 0.7794404029846191, Overall 0.7817752361297607 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 16.353307387408087, Time 0.779592752456665, Overall 0.7819161415100098 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 152.7782745361328, Time 0.7950606346130371, Overall 0.7973859310150146 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 16.97536383734809, Time 0.795196533203125, Overall 0.7975199222564697 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 465.07659912109375, Time 0.01675868034362793, Overall 0.8190631866455078 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 27.357447007123163, Time 0.019385814666748047, Overall 0.8216896057128906 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 198.44020080566406, Time 0.030150175094604492, Overall 0.8324549198150635 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 22.04891120062934, Time 0.030275583267211914, Overall 0.8325791358947754 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 388.5081481933594, Time 0.05964946746826172, Overall 0.8619539737701416 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 22.853420481962317, Time 0.059764862060546875, Overall 0.8620686531066895 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 162.8468780517578, Time 0.07034826278686523, Overall 0.872652530670166 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 18.094097561306423, Time 0.07047247886657715, Overall 0.8727757930755615 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 337.01348876953125, Time 0.08931183815002441, Overall 0.8916161060333252 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 19.824322868795957, Time 0.0894172191619873, Overall 0.8917200565338135 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 167.82943725585938, Time 0.10114097595214844, Overall 0.9034454822540283 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 18.647715250651043, Time 0.10126733779907227, Overall 0.9035706520080566 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 314.2102966308594, Time 0.12393665313720703, Overall 0.9262421131134033 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 18.48295862534467, Time 0.12405180931091309, Overall 0.9263548851013184 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 179.9540252685547, Time 0.14645719528198242, Overall 0.9487719535827637 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 19.994891696506077, Time 0.14661288261413574, Overall 0.9489161968231201 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 265.60589599609375, Time 0.16658782958984375, Overall 0.9688920974731445 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 15.623876235064339, Time 0.16669726371765137, Overall 0.9690005779266357 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 177.8440399169922, Time 0.17778635025024414, Overall 0.9800915718078613 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 19.760448879665798, Time 0.17790770530700684, Overall 0.9802112579345703 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 285.5304260253906, Time 0.202955961227417, Overall 1.0052602291107178 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 16.795907413258274, Time 0.20308542251586914, Overall 1.0053889751434326 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 133.6238250732422, Time 0.21440434455871582, Overall 1.0167090892791748 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 14.847091674804688, Time 0.21456599235534668, Overall 1.0168695449829102 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 268.36602783203125, Time 0.2346792221069336, Overall 1.0369834899902344 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 15.786236931295957, Time 0.23478436470031738, Overall 1.0370872020721436 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 138.31454467773438, Time 0.24482488632202148, Overall 1.0471296310424805 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 15.368282741970486, Time 0.24494385719299316, Overall 1.0472471714019775 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 292.20928955078125, Time 0.2662923336029053, Overall 1.068596601486206 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 17.18878173828125, Time 0.26639795303344727, Overall 1.0687010288238525 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 172.33636474609375, Time 0.2758033275604248, Overall 1.0781073570251465 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 19.148484971788193, Time 0.2759122848510742, Overall 1.0782158374786377 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 261.9287109375, Time 0.29608869552612305, Overall 1.098393201828003 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 15.407571231617647, Time 0.2962055206298828, Overall 1.0985090732574463 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 163.60223388671875, Time 0.3068809509277344, Overall 1.1091852188110352 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 18.178025987413193, Time 0.30707216262817383, Overall 1.1093759536743164 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 277.6723937988281, Time 0.3244748115539551, Overall 1.1267800331115723 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 16.333670223460476, Time 0.3245985507965088, Overall 1.1269018650054932 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 207.78041076660156, Time 0.33463335037231445, Overall 1.1369373798370361 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 23.086712307400173, Time 0.3347349166870117, Overall 1.1370375156402588 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 327.6777038574219, Time 0.3628854751586914, Overall 1.1651899814605713 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 19.27515905043658, Time 0.36299943923950195, Overall 1.1653029918670654 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 206.8218536376953, Time 0.3731405735015869, Overall 1.1754448413848877 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 22.980205959743923, Time 0.37326836585998535, Overall 1.1755716800689697 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 377.64874267578125, Time 0.3922910690307617, Overall 1.1945955753326416 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 22.21463192210478, Time 0.3923985958099365, Overall 1.1947016716003418 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 153.68678283691406, Time 0.4019784927368164, Overall 1.2042827606201172 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 17.076309204101562, Time 0.4021029472351074, Overall 1.204406499862671 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 303.3511657714844, Time 0.42005228996276855, Overall 1.2223570346832275 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 17.844186221852024, Time 0.4201633930206299, Overall 1.2224664688110352 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 180.25315856933594, Time 0.43849921226501465, Overall 1.2408034801483154 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 20.028128729926216, Time 0.4386460781097412, Overall 1.2409489154815674 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 235.48985290527344, Time 0.4778110980987549, Overall 1.2801156044006348 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 13.852344288545495, Time 0.47792983055114746, Overall 1.2802331447601318 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 156.06129455566406, Time 0.48934102058410645, Overall 1.2916464805603027 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 17.34014383951823, Time 0.4894742965698242, Overall 1.2917780876159668 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 318.3157043457031, Time 0.5071408748626709, Overall 1.3094456195831299 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 18.724453196806067, Time 0.5072593688964844, Overall 1.3095626831054688 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 166.56936645507812, Time 0.5238723754882812, Overall 1.3261775970458984 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 18.507707383897568, Time 0.5240252017974854, Overall 1.3263287544250488 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 318.32012939453125, Time 0.5431058406829834, Overall 1.345409631729126 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 18.724713493795957, Time 0.5432133674621582, Overall 1.3455162048339844 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 126.9662857055664, Time 0.5584936141967773, Overall 1.360797643661499 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 14.107365078396267, Time 0.5586192607879639, Overall 1.3609223365783691 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 318.4023132324219, Time 0.5772597789764404, Overall 1.379563808441162 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 18.729547837201288, Time 0.5773634910583496, Overall 1.3796665668487549 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 194.16529846191406, Time 0.5883908271789551, Overall 1.3906950950622559 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 21.573922051323784, Time 0.5885260105133057, Overall 1.3908298015594482 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 332.21563720703125, Time 0.6090087890625, Overall 1.4113130569458008 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 19.542096306295957, Time 0.6091153621673584, Overall 1.4114184379577637 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 166.63233947753906, Time 0.6200351715087891, Overall 1.4223401546478271 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 18.51470438639323, Time 0.6201562881469727, Overall 1.4224600791931152 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 263.25689697265625, Time 0.6562271118164062, Overall 1.4585318565368652 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 15.485699821920957, Time 0.6563434600830078, Overall 1.4586470127105713 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 235.64627075195312, Time 0.666724443435669, Overall 1.4690284729003906 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 26.182918972439236, Time 0.6668515205383301, Overall 1.4691545963287354 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 304.781005859375, Time 0.6936063766479492, Overall 1.495910406112671 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 17.928294462316178, Time 0.6937253475189209, Overall 1.4960289001464844 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 194.240478515625, Time 0.7062444686889648, Overall 1.5085492134094238 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 21.582275390625, Time 0.7063806056976318, Overall 1.5086839199066162 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 351.1201171875, Time 0.020023584365844727, Overall 1.546452522277832 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 19.506673177083332, Time 0.02013421058654785, Overall 1.5465617179870605 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 148.72805786132812, Time 0.030562639236450195, Overall 1.5569915771484375 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 18.591007232666016, Time 0.030683517456054688, Overall 1.5571115016937256 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 380.013427734375, Time 0.0542147159576416, Overall 1.5806431770324707 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 21.111857096354168, Time 0.05433058738708496, Overall 1.5807583332061768 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 213.19680786132812, Time 0.06459569931030273, Overall 1.5910241603851318 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 26.649600982666016, Time 0.0647134780883789, Overall 1.5911405086517334 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 455.5800476074219, Time 0.0859839916229248, Overall 1.6124117374420166 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 25.31000264485677, Time 0.08607721328735352, Overall 1.612504005432129 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 118.19065856933594, Time 0.09571456909179688, Overall 1.622143268585205 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 14.773832321166992, Time 0.09584784507751465, Overall 1.6222751140594482 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 416.10980224609375, Time 0.12162399291992188, Overall 1.6480534076690674 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 23.117211235894096, Time 0.12174654006958008, Overall 1.648174524307251 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 180.1134033203125, Time 0.14249587059020996, Overall 1.6689250469207764 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 22.514175415039062, Time 0.14264249801635742, Overall 1.6690702438354492 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 361.49139404296875, Time 0.16135787963867188, Overall 1.6877870559692383 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 20.082855224609375, Time 0.1614854335784912, Overall 1.687913179397583 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 136.699951171875, Time 0.17856788635253906, Overall 1.7049977779388428 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 17.087493896484375, Time 0.17872381210327148, Overall 1.7051515579223633 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 393.2778625488281, Time 0.2203366756439209, Overall 1.746765375137329 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 21.848770141601562, Time 0.22047662734985352, Overall 1.746903657913208 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 193.2274627685547, Time 0.2308027744293213, Overall 1.7572314739227295 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 24.153432846069336, Time 0.23093199729919434, Overall 1.757359266281128 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 234.37515258789062, Time 0.26221799850463867, Overall 1.7886466979980469 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 13.020841810438368, Time 0.26233696937561035, Overall 1.7887647151947021 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 192.13473510742188, Time 0.27214717864990234, Overall 1.7985756397247314 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 24.016841888427734, Time 0.27226758003234863, Overall 1.7986950874328613 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 357.72442626953125, Time 0.2929091453552246, Overall 1.8193373680114746 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 19.873579237196182, Time 0.2930176258087158, Overall 1.8194446563720703 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 98.43081665039062, Time 0.31271815299987793, Overall 1.8391461372375488 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 12.303852081298828, Time 0.31284546852111816, Overall 1.8392724990844727 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 323.1580810546875, Time 0.342085599899292, Overall 1.8685142993927002 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 17.953226725260418, Time 0.34221363067626953, Overall 1.8686408996582031 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 124.89543914794922, Time 0.3512997627258301, Overall 1.8777284622192383 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 15.611929893493652, Time 0.3514363765716553, Overall 1.877863883972168 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 410.0848083496094, Time 0.37065792083740234, Overall 1.8970866203308105 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 22.782489352756077, Time 0.37076807022094727, Overall 1.89719557762146 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 166.34219360351562, Time 0.3812117576599121, Overall 1.9076404571533203 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 20.792774200439453, Time 0.3813631534576416, Overall 1.9077908992767334 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 321.18060302734375, Time 0.40259385108947754, Overall 1.929023265838623 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 17.843366834852432, Time 0.4027130603790283, Overall 1.929140329360962 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 172.16700744628906, Time 0.41361379623413086, Overall 1.94004225730896 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 21.520875930786133, Time 0.413745641708374, Overall 1.940173625946045 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 265.901123046875, Time 0.43566322326660156, Overall 1.9620921611785889 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 14.772284613715279, Time 0.43578648567199707, Overall 1.9622137546539307 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 114.57778930664062, Time 0.4460592269897461, Overall 1.9724879264831543 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 14.322223663330078, Time 0.4461836814880371, Overall 1.9726107120513916 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 310.7489929199219, Time 0.46566081047058105, Overall 1.9920895099639893 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 17.26383293999566, Time 0.46576905250549316, Overall 1.9921965599060059 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 207.89578247070312, Time 0.4756650924682617, Overall 2.00209379196167 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 25.98697280883789, Time 0.47579050064086914, Overall 2.002218246459961 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 411.0791931152344, Time 0.4950218200683594, Overall 2.0214502811431885 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 22.837732950846355, Time 0.49513959884643555, Overall 2.0215671062469482 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 166.44692993164062, Time 0.5052297115325928, Overall 2.031658172607422 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 20.805866241455078, Time 0.5053553581237793, Overall 2.031782627105713 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 264.334716796875, Time 0.5230488777160645, Overall 2.0494775772094727 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 14.685262044270834, Time 0.5231626033782959, Overall 2.0495896339416504 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 139.0541229248047, Time 0.5343255996704102, Overall 2.06075382232666 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 17.381765365600586, Time 0.534461259841919, Overall 2.0608890056610107 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 362.0979919433594, Time 0.5533685684204102, Overall 2.0797975063323975 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 20.11655510796441, Time 0.5535073280334473, Overall 2.07993483543396 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 207.94613647460938, Time 0.5638353824615479, Overall 2.090263605117798 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 25.993267059326172, Time 0.5639536380767822, Overall 2.0903818607330322 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 346.0018005371094, Time 0.583249568939209, Overall 2.109678268432617 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 19.22232225206163, Time 0.5833694934844971, Overall 2.1097970008850098 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 249.406005859375, Time 0.5931541919708252, Overall 2.119582414627075 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 31.175750732421875, Time 0.5933904647827148, Overall 2.1198179721832275 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 310.8369140625, Time 0.6152634620666504, Overall 2.1416921615600586 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 17.268717447916668, Time 0.6153819561004639, Overall 2.1418097019195557 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 154.38587951660156, Time 0.6282827854156494, Overall 2.1547110080718994 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 19.298234939575195, Time 0.6284396648406982, Overall 2.154867172241211 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 325.3382568359375, Time 0.654780387878418, Overall 2.181208848953247 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 18.07434760199653, Time 0.6548941135406494, Overall 2.181321382522583 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 158.91526794433594, Time 0.6657345294952393, Overall 2.1921627521514893 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 19.864408493041992, Time 0.6658542156219482, Overall 2.1922812461853027 \n",
            "Epoch    19: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 284.4574890136719, Time 0.6892890930175781, Overall 2.2157180309295654 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 15.803193834092882, Time 0.6894011497497559, Overall 2.2158284187316895 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 139.03341674804688, Time 0.6993052959442139, Overall 2.225733995437622 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 17.37917709350586, Time 0.6994690895080566, Overall 2.2258968353271484 \n",
            "It took 2.2284395694732666 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 8.082389831542969e-05 seconds to load from the pickles.\n",
            "It took 0.000423431396484375 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:51,321 : INFO : loading Doc2Vec object from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "File not found! Learning skill.emb.d100.w1.dm1 embeddings from scratch ...\n",
            "Loading the skill documents pickle ...\n",
            "File not found! Generating skill documents ...\n",
            "#Documents with word type of skill have created: 31\n",
            "Saving the skill documents ...\n",
            "2022-03-04 05:28:51,385 : INFO : collecting all words and their counts\n",
            "2022-03-04 05:28:51,385 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2022-03-04 05:28:51,386 : INFO : collected 11 word types and 31 unique tags from a corpus of 31 examples and 67 words\n",
            "2022-03-04 05:28:51,386 : INFO : Loading a fresh vocabulary\n",
            "2022-03-04 05:28:51,386 : INFO : effective_min_count=0 retains 11 unique words (100% of original 11, drops 0)\n",
            "2022-03-04 05:28:51,386 : INFO : effective_min_count=0 leaves 67 word corpus (100% of original 67, drops 0)\n",
            "2022-03-04 05:28:51,386 : INFO : deleting the raw counts dictionary of 11 items\n",
            "2022-03-04 05:28:51,386 : INFO : sample=0.001 downsamples 11 most-common words\n",
            "2022-03-04 05:28:51,386 : INFO : downsampling leaves estimated 7 word corpus (11.0% of prior 67)\n",
            "2022-03-04 05:28:51,387 : INFO : estimated required memory for 11 words and 100 dimensions: 32900 bytes\n",
            "2022-03-04 05:28:51,387 : INFO : resetting layer weights\n",
            "  0% 0/10 [00:00<?, ?it/s]2022-03-04 05:28:51,418 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,433 : INFO : EPOCH - 1 : training on 67 raw words (39 effective words) took 0.0s, 17307 effective words/s\n",
            "2022-03-04 05:28:51,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,483 : INFO : EPOCH - 2 : training on 67 raw words (37 effective words) took 0.0s, 16567 effective words/s\n",
            "2022-03-04 05:28:51,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,490 : INFO : EPOCH - 3 : training on 67 raw words (40 effective words) took 0.0s, 19483 effective words/s\n",
            "2022-03-04 05:28:51,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,526 : INFO : EPOCH - 4 : training on 67 raw words (36 effective words) took 0.0s, 17149 effective words/s\n",
            "2022-03-04 05:28:51,540 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,541 : INFO : EPOCH - 5 : training on 67 raw words (38 effective words) took 0.0s, 19635 effective words/s\n",
            "2022-03-04 05:28:51,541 : INFO : training on a 335 raw words (190 effective words) took 0.1s, 1635 effective words/s\n",
            "2022-03-04 05:28:51,541 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            " 10% 1/10 [00:00<00:01,  8.10it/s]2022-03-04 05:28:51,541 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,562 : INFO : EPOCH - 1 : training on 67 raw words (40 effective words) took 0.0s, 20355 effective words/s\n",
            "2022-03-04 05:28:51,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,604 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 17699 effective words/s\n",
            "2022-03-04 05:28:51,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,631 : INFO : EPOCH - 3 : training on 67 raw words (43 effective words) took 0.0s, 20388 effective words/s\n",
            "2022-03-04 05:28:51,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,642 : INFO : EPOCH - 4 : training on 67 raw words (40 effective words) took 0.0s, 19054 effective words/s\n",
            "2022-03-04 05:28:51,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,657 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 17256 effective words/s\n",
            "2022-03-04 05:28:51,657 : INFO : training on a 335 raw words (199 effective words) took 0.1s, 1717 effective words/s\n",
            "2022-03-04 05:28:51,657 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            " 20% 2/10 [00:00<00:00,  8.38it/s]2022-03-04 05:28:51,658 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,693 : INFO : EPOCH - 1 : training on 67 raw words (35 effective words) took 0.0s, 15992 effective words/s\n",
            "2022-03-04 05:28:51,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,699 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 16968 effective words/s\n",
            "2022-03-04 05:28:51,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,701 : INFO : EPOCH - 3 : training on 67 raw words (40 effective words) took 0.0s, 19277 effective words/s\n",
            "2022-03-04 05:28:51,708 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,708 : INFO : EPOCH - 4 : training on 67 raw words (37 effective words) took 0.0s, 17844 effective words/s\n",
            "2022-03-04 05:28:51,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,711 : INFO : EPOCH - 5 : training on 67 raw words (38 effective words) took 0.0s, 18119 effective words/s\n",
            "2022-03-04 05:28:51,712 : INFO : training on a 335 raw words (186 effective words) took 0.1s, 3463 effective words/s\n",
            "2022-03-04 05:28:51,712 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,712 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,715 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,715 : INFO : EPOCH - 1 : training on 67 raw words (41 effective words) took 0.0s, 19919 effective words/s\n",
            "2022-03-04 05:28:51,717 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,717 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 19875 effective words/s\n",
            "2022-03-04 05:28:51,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,724 : INFO : EPOCH - 3 : training on 67 raw words (40 effective words) took 0.0s, 19031 effective words/s\n",
            "2022-03-04 05:28:51,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,730 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,731 : INFO : EPOCH - 4 : training on 67 raw words (39 effective words) took 0.0s, 6725 effective words/s\n",
            "2022-03-04 05:28:51,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,735 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 21654 effective words/s\n",
            "2022-03-04 05:28:51,735 : INFO : training on a 335 raw words (196 effective words) took 0.0s, 8375 effective words/s\n",
            "2022-03-04 05:28:51,735 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,735 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,742 : INFO : EPOCH - 1 : training on 67 raw words (40 effective words) took 0.0s, 18966 effective words/s\n",
            "2022-03-04 05:28:51,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,746 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 19135 effective words/s\n",
            "2022-03-04 05:28:51,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,749 : INFO : EPOCH - 3 : training on 67 raw words (38 effective words) took 0.0s, 19934 effective words/s\n",
            "2022-03-04 05:28:51,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,751 : INFO : EPOCH - 4 : training on 67 raw words (35 effective words) took 0.0s, 19384 effective words/s\n",
            "2022-03-04 05:28:51,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,754 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,754 : INFO : EPOCH - 5 : training on 67 raw words (39 effective words) took 0.0s, 21053 effective words/s\n",
            "2022-03-04 05:28:51,754 : INFO : training on a 335 raw words (188 effective words) took 0.0s, 10094 effective words/s\n",
            "2022-03-04 05:28:51,754 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,754 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,757 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,757 : INFO : EPOCH - 1 : training on 67 raw words (35 effective words) took 0.0s, 18174 effective words/s\n",
            "2022-03-04 05:28:51,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,759 : INFO : EPOCH - 2 : training on 67 raw words (37 effective words) took 0.0s, 25325 effective words/s\n",
            "2022-03-04 05:28:51,762 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,762 : INFO : EPOCH - 3 : training on 67 raw words (37 effective words) took 0.0s, 19051 effective words/s\n",
            "2022-03-04 05:28:51,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,765 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,765 : INFO : EPOCH - 4 : training on 67 raw words (35 effective words) took 0.0s, 16478 effective words/s\n",
            "2022-03-04 05:28:51,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,770 : INFO : EPOCH - 5 : training on 67 raw words (38 effective words) took 0.0s, 8691 effective words/s\n",
            "2022-03-04 05:28:51,770 : INFO : training on a 335 raw words (182 effective words) took 0.0s, 11657 effective words/s\n",
            "2022-03-04 05:28:51,770 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            " 60% 6/10 [00:00<00:00, 20.39it/s]2022-03-04 05:28:51,770 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,772 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,773 : INFO : EPOCH - 1 : training on 67 raw words (37 effective words) took 0.0s, 22049 effective words/s\n",
            "2022-03-04 05:28:51,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,777 : INFO : EPOCH - 2 : training on 67 raw words (39 effective words) took 0.0s, 22959 effective words/s\n",
            "2022-03-04 05:28:51,779 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,780 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,780 : INFO : EPOCH - 3 : training on 67 raw words (37 effective words) took 0.0s, 17778 effective words/s\n",
            "2022-03-04 05:28:51,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,783 : INFO : EPOCH - 4 : training on 67 raw words (40 effective words) took 0.0s, 22206 effective words/s\n",
            "2022-03-04 05:28:51,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,790 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 10280 effective words/s\n",
            "2022-03-04 05:28:51,790 : INFO : training on a 335 raw words (193 effective words) took 0.0s, 9767 effective words/s\n",
            "2022-03-04 05:28:51,790 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,790 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,803 : INFO : EPOCH - 1 : training on 67 raw words (41 effective words) took 0.0s, 20304 effective words/s\n",
            "2022-03-04 05:28:51,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,812 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,812 : INFO : EPOCH - 2 : training on 67 raw words (39 effective words) took 0.0s, 17905 effective words/s\n",
            "2022-03-04 05:28:51,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,814 : INFO : EPOCH - 3 : training on 67 raw words (41 effective words) took 0.0s, 20301 effective words/s\n",
            "2022-03-04 05:28:51,817 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,817 : INFO : EPOCH - 4 : training on 67 raw words (36 effective words) took 0.0s, 17440 effective words/s\n",
            "2022-03-04 05:28:51,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,820 : INFO : EPOCH - 5 : training on 67 raw words (43 effective words) took 0.0s, 20817 effective words/s\n",
            "2022-03-04 05:28:51,820 : INFO : training on a 335 raw words (200 effective words) took 0.0s, 6687 effective words/s\n",
            "2022-03-04 05:28:51,820 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,820 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,823 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,823 : INFO : EPOCH - 1 : training on 67 raw words (39 effective words) took 0.0s, 18156 effective words/s\n",
            "2022-03-04 05:28:51,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,826 : INFO : EPOCH - 2 : training on 67 raw words (39 effective words) took 0.0s, 19794 effective words/s\n",
            "2022-03-04 05:28:51,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,834 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,834 : INFO : EPOCH - 3 : training on 67 raw words (39 effective words) took 0.0s, 5389 effective words/s\n",
            "2022-03-04 05:28:51,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,847 : INFO : EPOCH - 4 : training on 67 raw words (40 effective words) took 0.0s, 17485 effective words/s\n",
            "2022-03-04 05:28:51,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,850 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 19048 effective words/s\n",
            "2022-03-04 05:28:51,850 : INFO : training on a 335 raw words (197 effective words) took 0.0s, 6589 effective words/s\n",
            "2022-03-04 05:28:51,850 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,851 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,853 : INFO : EPOCH - 1 : training on 67 raw words (41 effective words) took 0.0s, 20342 effective words/s\n",
            "2022-03-04 05:28:51,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,865 : INFO : EPOCH - 2 : training on 67 raw words (38 effective words) took 0.0s, 16759 effective words/s\n",
            "2022-03-04 05:28:51,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,868 : INFO : EPOCH - 3 : training on 67 raw words (35 effective words) took 0.0s, 16645 effective words/s\n",
            "2022-03-04 05:28:51,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,899 : INFO : EPOCH - 4 : training on 67 raw words (37 effective words) took 0.0s, 14820 effective words/s\n",
            "2022-03-04 05:28:51,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,903 : INFO : EPOCH - 5 : training on 67 raw words (35 effective words) took 0.0s, 9977 effective words/s\n",
            "2022-03-04 05:28:51,903 : INFO : training on a 335 raw words (186 effective words) took 0.1s, 3534 effective words/s\n",
            "2022-03-04 05:28:51,903 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100% 10/10 [00:00<00:00, 20.58it/s]\n",
            "Saving model for skill.emb.d100.w1.dm1 under directory ./../data/preprocessed/dblp/toy.dblp.v12.json ...\n",
            "2022-03-04 05:28:51,904 : INFO : saving Doc2Vec object under ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl, separately None\n",
            "2022-03-04 05:28:51,905 : INFO : saved ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.28938293457031, Time 0.2170703411102295, Overall 0.21887946128845215 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 2.311140172621783, Time 0.21718335151672363, Overall 0.21899104118347168 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 17.608112335205078, Time 0.2194974422454834, Overall 0.22130537033081055 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 1.9564569261338975, Time 0.21959948539733887, Overall 0.2214066982269287 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 34.10918426513672, Time 0.23760533332824707, Overall 0.23941421508789062 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 2.0064226038315716, Time 0.23772072792053223, Overall 0.23952817916870117 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 16.468996047973633, Time 0.24399423599243164, Overall 0.2458035945892334 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 1.829888449774848, Time 0.24413442611694336, Overall 0.2459418773651123 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 26.197040557861328, Time 0.24971747398376465, Overall 0.2515256404876709 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.5410023857565487, Time 0.24982953071594238, Overall 0.25163698196411133 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 19.816923141479492, Time 0.2520608901977539, Overall 0.25386905670166016 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 2.201880349053277, Time 0.2521517276763916, Overall 0.25395894050598145 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 32.29713439941406, Time 0.25724029541015625, Overall 0.2590484619140625 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.8998314352596508, Time 0.25733351707458496, Overall 0.2591407299041748 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 26.74020767211914, Time 0.25943660736083984, Overall 0.261244535446167 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 2.9711341857910156, Time 0.25952625274658203, Overall 0.2613332271575928 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 34.45058059692383, Time 0.2660400867462158, Overall 0.26784801483154297 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.0265047409955192, Time 0.26613497734069824, Overall 0.2679421901702881 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 21.350526809692383, Time 0.26845669746398926, Overall 0.2702648639678955 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 2.372280756632487, Time 0.2685585021972656, Overall 0.27036571502685547 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 29.383352279663086, Time 0.2738926410675049, Overall 0.27570080757141113 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.728432487039005, Time 0.27398180961608887, Overall 0.2757892608642578 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 17.27570152282715, Time 0.27605223655700684, Overall 0.2778604030609131 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 1.9195223914252386, Time 0.2761387825012207, Overall 0.27794528007507324 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 26.99698829650879, Time 0.28134799003601074, Overall 0.2831563949584961 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 1.5880581350887524, Time 0.2814371585845947, Overall 0.28324437141418457 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 20.577354431152344, Time 0.2837038040161133, Overall 0.28551173210144043 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 2.2863727145724826, Time 0.28380870819091797, Overall 0.2856159210205078 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 33.457027435302734, Time 0.2923614978790283, Overall 0.29416990280151367 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 1.968060437370749, Time 0.29246997833251953, Overall 0.2942774295806885 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 15.447563171386719, Time 0.29482340812683105, Overall 0.2966318130493164 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 1.7163959079318576, Time 0.2949404716491699, Overall 0.29674768447875977 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 24.19440269470215, Time 0.30208420753479004, Overall 0.3038921356201172 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 1.4232001585118912, Time 0.30217647552490234, Overall 0.3039839267730713 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 17.524883270263672, Time 0.30431580543518066, Overall 0.3061239719390869 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 1.9472092522515192, Time 0.3044118881225586, Overall 0.30621933937072754 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 25.123722076416016, Time 0.31137633323669434, Overall 0.3131847381591797 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 1.4778660044950598, Time 0.31241798400878906, Overall 0.3142263889312744 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 15.839691162109375, Time 0.31473374366760254, Overall 0.3165419101715088 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 1.7599656846788194, Time 0.3148312568664551, Overall 0.316638708114624 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 27.82807159423828, Time 0.3200337886810303, Overall 0.3218419551849365 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 1.6369453878963696, Time 0.3201162815093994, Overall 0.32192325592041016 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 13.623557090759277, Time 0.32224202156066895, Overall 0.324049711227417 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 1.5137285656399198, Time 0.3223421573638916, Overall 0.32414913177490234 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 33.65329360961914, Time 0.3273921012878418, Overall 0.32920026779174805 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 1.9796055064481848, Time 0.3274822235107422, Overall 0.32928967475891113 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 17.095060348510742, Time 0.32957911491394043, Overall 0.3313872814178467 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 1.899451149834527, Time 0.3296666145324707, Overall 0.33147382736206055 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 24.2404842376709, Time 0.3347444534301758, Overall 0.33655261993408203 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 1.4259108375100529, Time 0.3348386287689209, Overall 0.33664584159851074 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 18.14167022705078, Time 0.34410905838012695, Overall 0.3459179401397705 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 2.015741136338976, Time 0.34424638748168945, Overall 0.3460538387298584 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 30.325443267822266, Time 0.37453413009643555, Overall 0.3763427734375 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 1.783849603989545, Time 0.37465810775756836, Overall 0.3764650821685791 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 19.531070709228516, Time 0.3770480155944824, Overall 0.378856897354126 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 2.170118967692057, Time 0.37715768814086914, Overall 0.3789646625518799 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 25.105310440063477, Time 0.3935098648071289, Overall 0.39531850814819336 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 1.4767829670625574, Time 0.3936598300933838, Overall 0.39546728134155273 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 15.665833473205566, Time 0.39601922035217285, Overall 0.3978276252746582 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 1.7406481636895075, Time 0.3961176872253418, Overall 0.39792513847351074 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 27.28921890258789, Time 0.40863895416259766, Overall 0.4104475975036621 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 1.6052481707404642, Time 0.40874481201171875, Overall 0.4105520248413086 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 20.403976440429688, Time 0.41092371940612793, Overall 0.4127321243286133 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 2.2671084933810763, Time 0.4110236167907715, Overall 0.4128305912017822 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 25.508668899536133, Time 0.425645112991333, Overall 0.42745304107666016 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 1.5005099352668314, Time 0.42574596405029297, Overall 0.4275531768798828 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 15.518495559692383, Time 0.4309878349304199, Overall 0.4327962398529053 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 1.7242772844102647, Time 0.43110084533691406, Overall 0.432908296585083 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 29.27398681640625, Time 0.4364001750946045, Overall 0.43820810317993164 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 1.7219992244944853, Time 0.4365060329437256, Overall 0.43831348419189453 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 15.344001770019531, Time 0.4389915466308594, Overall 0.4407999515533447 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 1.7048890855577257, Time 0.4390883445739746, Overall 0.44089555740356445 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 27.60951042175293, Time 0.4443027973175049, Overall 0.44611072540283203 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 1.6240888483384077, Time 0.4443964958190918, Overall 0.44620370864868164 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 16.82895278930664, Time 0.453047513961792, Overall 0.45485639572143555 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 1.8698836432562933, Time 0.45318102836608887, Overall 0.4549891948699951 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 25.331932067871094, Time 0.46622252464294434, Overall 0.4680309295654297 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 1.4901136510512407, Time 0.46634578704833984, Overall 0.4681529998779297 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 16.208505630493164, Time 0.46881890296936035, Overall 0.4706273078918457 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 1.800945070054796, Time 0.4689362049102783, Overall 0.47074365615844727 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 37.123783111572266, Time 0.00496363639831543, Overall 0.478712797164917 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 2.183751947739545, Time 0.005049467086791992, Overall 0.47879815101623535 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 16.70228385925293, Time 0.006975412368774414, Overall 0.4807243347167969 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 1.8558093176947699, Time 0.007056236267089844, Overall 0.4808049201965332 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 30.700939178466797, Time 0.013499259948730469, Overall 0.48724842071533203 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 1.805937598733341, Time 0.013586282730102539, Overall 0.4873342514038086 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 13.250755310058594, Time 0.015560626983642578, Overall 0.48930954933166504 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 1.472306145562066, Time 0.01564311981201172, Overall 0.4893918037414551 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 27.49819564819336, Time 0.020164966583251953, Overall 0.4939141273498535 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 1.6175409204819624, Time 0.020247936248779297, Overall 0.49399614334106445 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 12.040948867797852, Time 0.022287607192993164, Overall 0.4960367679595947 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 1.3378832075330946, Time 0.022385358810424805, Overall 0.49613356590270996 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 29.84539794921875, Time 0.027250051498413086, Overall 0.5009994506835938 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 1.7556116440716911, Time 0.02734994888305664, Overall 0.5010983943939209 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 19.82787322998047, Time 0.029479026794433594, Overall 0.5032281875610352 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 2.2030970255533853, Time 0.0295717716217041, Overall 0.5033204555511475 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 33.587711334228516, Time 0.03460073471069336, Overall 0.5083498954772949 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.975747725542854, Time 0.03468966484069824, Overall 0.5084383487701416 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 12.740323066711426, Time 0.03732705116271973, Overall 0.5110762119293213 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 1.4155914518568251, Time 0.0374143123626709, Overall 0.511162519454956 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 28.246456146240234, Time 0.042455196380615234, Overall 0.5162043571472168 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.6615562438964844, Time 0.04254269599914551, Overall 0.5162911415100098 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 17.752071380615234, Time 0.04454231262207031, Overall 0.5182914733886719 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 1.972452375623915, Time 0.044631242752075195, Overall 0.5183796882629395 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 27.827817916870117, Time 0.049546003341674805, Overall 0.5232954025268555 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 1.6369304656982422, Time 0.04963088035583496, Overall 0.5233793258666992 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 10.741201400756836, Time 0.05757713317871094, Overall 0.5313270092010498 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 1.1934668223063152, Time 0.05768704414367676, Overall 0.5314357280731201 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 30.686832427978516, Time 0.06330227851867676, Overall 0.5370519161224365 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 1.8051077898810892, Time 0.06339859962463379, Overall 0.537146806716919 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 15.088050842285156, Time 0.06560540199279785, Overall 0.5393548011779785 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 1.6764500935872395, Time 0.06569361686706543, Overall 0.5394415855407715 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 24.01816177368164, Time 0.07074093818664551, Overall 0.5444900989532471 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 1.4128330455106848, Time 0.07084250450134277, Overall 0.5445914268493652 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 15.72756290435791, Time 0.07305097579956055, Overall 0.5468001365661621 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 1.7475069893731012, Time 0.07313919067382812, Overall 0.5468878746032715 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 25.323312759399414, Time 0.07821941375732422, Overall 0.5519688129425049 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 1.489606632905848, Time 0.0783071517944336, Overall 0.5520634651184082 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 19.48696517944336, Time 0.08045792579650879, Overall 0.5542070865631104 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 2.1652183532714844, Time 0.0805504322052002, Overall 0.5542991161346436 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 26.932004928588867, Time 0.10464835166931152, Overall 0.5783984661102295 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 1.5842355840346392, Time 0.104766845703125, Overall 0.5785155296325684 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 19.629817962646484, Time 0.11407756805419922, Overall 0.5878276824951172 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 2.181090884738498, Time 0.1141974925994873, Overall 0.5879456996917725 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 31.3636417388916, Time 0.12899136543273926, Overall 0.6027412414550781 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 1.8449201022877413, Time 0.1291038990020752, Overall 0.6028525829315186 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 15.630915641784668, Time 0.13140344619750977, Overall 0.6051530838012695 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 1.736768404642741, Time 0.131500244140625, Overall 0.6052486896514893 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 25.807598114013672, Time 0.15452814102172852, Overall 0.6282782554626465 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 1.5180940067066866, Time 0.15466046333312988, Overall 0.6284093856811523 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 15.223583221435547, Time 0.15952396392822266, Overall 0.6332736015319824 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 1.6915092468261719, Time 0.1596364974975586, Overall 0.633385419845581 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 27.435461044311523, Time 0.17031359672546387, Overall 0.6440632343292236 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 1.6138506496653837, Time 0.17708992958068848, Overall 0.6508400440216064 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 15.826635360717773, Time 0.17958378791809082, Overall 0.6533331871032715 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 1.7585150400797527, Time 0.17968249320983887, Overall 0.653430700302124 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 24.883529663085938, Time 0.185028076171875, Overall 0.6587774753570557 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 1.4637370390050553, Time 0.19157862663269043, Overall 0.6653282642364502 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 17.12472915649414, Time 0.19396519660949707, Overall 0.6677145957946777 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 1.9027476840549045, Time 0.19405674934387207, Overall 0.6678054332733154 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 23.546066284179688, Time 0.2174997329711914, Overall 0.6912493705749512 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 1.3850627225988053, Time 0.21849894523620605, Overall 0.6922485828399658 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.08640193939209, Time 0.22079896926879883, Overall 0.6945483684539795 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 1.6762668821546767, Time 0.2209017276763916, Overall 0.694650411605835 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 24.989303588867188, Time 0.22626662254333496, Overall 0.7000160217285156 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 1.4699590346392464, Time 0.2263636589050293, Overall 0.7001123428344727 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 19.7445011138916, Time 0.22868776321411133, Overall 0.7024374008178711 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 2.1938334570990667, Time 0.23378896713256836, Overall 0.707538366317749 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 27.377788543701172, Time 0.23921418190002441, Overall 0.7129635810852051 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 1.6104581496294808, Time 0.23931026458740234, Overall 0.7130587100982666 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 16.74555015563965, Time 0.24164795875549316, Overall 0.7153971195220947 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 1.860616683959961, Time 0.24174165725708008, Overall 0.7154905796051025 \n",
            "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 28.749893188476562, Time 0.24774384498596191, Overall 0.7214932441711426 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 1.6911701875574447, Time 0.24784588813781738, Overall 0.7215943336486816 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 16.558860778808594, Time 0.25008583068847656, Overall 0.7238349914550781 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 1.8398734198676214, Time 0.2501797676086426, Overall 0.7239282131195068 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 18.338594436645508, Time 0.2554020881652832, Overall 0.7291514873504639 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 1.0787408492144417, Time 0.2554900646209717, Overall 0.7292385101318359 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 16.535921096801758, Time 0.25766682624816895, Overall 0.7314159870147705 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 1.8373245663113065, Time 0.25775623321533203, Overall 0.7315051555633545 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.133277893066406, Time 0.0044651031494140625, Overall 0.73897385597229 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 2.1740709940592446, Time 0.004547595977783203, Overall 0.7390551567077637 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 16.10224151611328, Time 0.006380558013916016, Overall 0.7408890724182129 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 2.01278018951416, Time 0.006469249725341797, Overall 0.7409765720367432 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 34.60878372192383, Time 0.011851072311401367, Overall 0.7463595867156982 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 1.922710206773546, Time 0.011929035186767578, Overall 0.746436595916748 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 15.243721961975098, Time 0.013697385787963867, Overall 0.7482054233551025 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 1.9054652452468872, Time 0.013788700103759766, Overall 0.7482964992523193 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 26.112159729003906, Time 0.019015789031982422, Overall 0.7535245418548584 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 1.450675540500217, Time 0.019108295440673828, Overall 0.7536163330078125 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.622987747192383, Time 0.02115321159362793, Overall 0.7556614875793457 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 2.202873468399048, Time 0.021262645721435547, Overall 0.7557699680328369 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 35.02808380126953, Time 0.026375293731689453, Overall 0.7608835697174072 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.946004655626085, Time 0.02645587921142578, Overall 0.7609632015228271 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 22.866439819335938, Time 0.028368234634399414, Overall 0.7628767490386963 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 2.858304977416992, Time 0.028454065322875977, Overall 0.7629618644714355 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 31.09764862060547, Time 0.03399181365966797, Overall 0.7685000896453857 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 1.7276471455891926, Time 0.03409075736999512, Overall 0.7685983180999756 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 17.40577507019043, Time 0.047425270080566406, Overall 0.7819347381591797 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 2.1757218837738037, Time 0.047559261322021484, Overall 0.782066822052002 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 28.3808650970459, Time 0.056626081466674805, Overall 0.7911357879638672 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 1.576714727613661, Time 0.06334805488586426, Overall 0.7978572845458984 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 17.41816520690918, Time 0.06592679023742676, Overall 0.8004350662231445 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 2.1772706508636475, Time 0.06603860855102539, Overall 0.8005461692810059 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 33.740840911865234, Time 0.07410836219787598, Overall 0.808617353439331 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.8744911617702908, Time 0.08031606674194336, Overall 0.8148248195648193 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 19.775989532470703, Time 0.08283019065856934, Overall 0.8173391819000244 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 2.471998691558838, Time 0.08293581008911133, Overall 0.8174436092376709 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 25.513078689575195, Time 0.10772156715393066, Overall 0.8422307968139648 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.4173932605319552, Time 0.1078345775604248, Overall 0.8423421382904053 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 18.36115074157715, Time 0.10987281799316406, Overall 0.84438157081604 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 2.2951438426971436, Time 0.1099705696105957, Overall 0.844477653503418 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 23.880020141601562, Time 0.11518430709838867, Overall 0.849693775177002 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.3266677856445312, Time 0.11527633666992188, Overall 0.8497841358184814 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 17.85411834716797, Time 0.11716794967651367, Overall 0.851693868637085 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 2.231764793395996, Time 0.11727762222290039, Overall 0.8517851829528809 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 26.8709659576416, Time 0.1224665641784668, Overall 0.8569746017456055 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 1.4928314420912001, Time 0.1225595474243164, Overall 0.8570666313171387 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 21.225614547729492, Time 0.12469005584716797, Overall 0.8591985702514648 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 2.6532018184661865, Time 0.1247866153717041, Overall 0.8592941761016846 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 28.720924377441406, Time 0.1302030086517334, Overall 0.8647110462188721 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 1.5956069098578558, Time 0.13029050827026367, Overall 0.8647980690002441 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 19.05063247680664, Time 0.13225340843200684, Overall 0.8667619228363037 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 2.38132905960083, Time 0.13234257698059082, Overall 0.8668498992919922 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 28.53203582763672, Time 0.13874578475952148, Overall 0.8732542991638184 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 1.5851131015353732, Time 0.13884186744689941, Overall 0.8733494281768799 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 13.546672821044922, Time 0.14090275764465332, Overall 0.8754105567932129 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 1.6933341026306152, Time 0.14099454879760742, Overall 0.8755025863647461 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 20.821565628051758, Time 0.1461174488067627, Overall 0.8806262016296387 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 1.1567536460028753, Time 0.14622163772583008, Overall 0.8807296752929688 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 17.680110931396484, Time 0.14820170402526855, Overall 0.8827102184295654 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 2.2100138664245605, Time 0.1482851505279541, Overall 0.8827927112579346 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 23.0064697265625, Time 0.15332722663879395, Overall 0.8878359794616699 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.27813720703125, Time 0.15341997146606445, Overall 0.8879275321960449 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 21.719863891601562, Time 0.15553665161132812, Overall 0.8900454044342041 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 2.7149829864501953, Time 0.15563154220581055, Overall 0.8901395797729492 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 21.658710479736328, Time 0.16079378128051758, Overall 0.8953022956848145 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 1.2032616933186848, Time 0.16087961196899414, Overall 0.8953871726989746 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 19.457012176513672, Time 0.162750244140625, Overall 0.897258996963501 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 2.432126522064209, Time 0.16283607482910156, Overall 0.8973431587219238 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 30.220840454101562, Time 0.18200039863586426, Overall 0.9165093898773193 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 1.67893558078342, Time 0.18350720405578613, Overall 0.9180161952972412 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.627473831176758, Time 0.1858506202697754, Overall 0.9203591346740723 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 1.9534342288970947, Time 0.1859447956085205, Overall 0.920452356338501 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 33.30281066894531, Time 0.1933128833770752, Overall 0.927821159362793 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.8501561482747395, Time 0.19339728355407715, Overall 0.9279050827026367 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 16.826139450073242, Time 0.19549822807312012, Overall 0.930006742477417 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 2.1032674312591553, Time 0.19559216499328613, Overall 0.9300994873046875 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 28.615325927734375, Time 0.2077035903930664, Overall 0.9422121047973633 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 1.5897403293185763, Time 0.20780348777770996, Overall 0.9423108100891113 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 25.50934410095215, Time 0.20981311798095703, Overall 0.9443213939666748 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 3.1886680126190186, Time 0.20990896224975586, Overall 0.9444165229797363 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 28.423120498657227, Time 0.21564602851867676, Overall 0.9501545429229736 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 1.5790622499254015, Time 0.21573710441589355, Overall 0.950244665145874 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 19.528335571289062, Time 0.21800732612609863, Overall 0.9525158405303955 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 2.441041946411133, Time 0.2181262969970703, Overall 0.952634334564209 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 26.901384353637695, Time 0.22394466400146484, Overall 0.9584534168243408 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 1.494521352979872, Time 0.2240438461303711, Overall 0.9585514068603516 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 17.908519744873047, Time 0.2260138988494873, Overall 0.9605224132537842 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 2.238564968109131, Time 0.22611331939697266, Overall 0.9606211185455322 \n",
            "It took 0.9620282649993896 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 6.723403930664062e-05 seconds to load from the pickles.\n",
            "It took 0.0003409385681152344 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:53,864 : INFO : loading Doc2Vec object from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "2022-03-04 05:28:53,865 : INFO : loading vocabulary recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.vocabulary.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loading trainables recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.trainables.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loading wv recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.wv.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loading docvecs recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.docvecs.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loaded ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 324.1528015136719, Time 0.01065683364868164, Overall 0.012133598327636719 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 19.067811853745404, Time 0.010750293731689453, Overall 0.012225866317749023 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 197.55870056152344, Time 0.0169069766998291, Overall 0.018383502960205078 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 21.95096672905816, Time 0.017017364501953125, Overall 0.018493175506591797 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 377.5923156738281, Time 0.03297924995422363, Overall 0.03445577621459961 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 22.211312686695774, Time 0.033074378967285156, Overall 0.03455018997192383 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 131.8585968017578, Time 0.03943967819213867, Overall 0.04091596603393555 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 14.650955200195312, Time 0.039551496505737305, Overall 0.041027069091796875 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 400.5333251953125, Time 0.05060076713562012, Overall 0.052077293395996094 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 23.560783835018384, Time 0.050689697265625, Overall 0.05216550827026367 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 206.6090850830078, Time 0.05689501762390137, Overall 0.05837225914001465 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 22.95656500922309, Time 0.056989192962646484, Overall 0.058464765548706055 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 336.90313720703125, Time 0.06826400756835938, Overall 0.06974053382873535 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 19.8178316004136, Time 0.06837940216064453, Overall 0.0698549747467041 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 141.1392822265625, Time 0.07451677322387695, Overall 0.07599306106567383 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 15.682142469618055, Time 0.07462286949157715, Overall 0.07609868049621582 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 293.9031982421875, Time 0.08626937866210938, Overall 0.08774614334106445 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 17.28842342601103, Time 0.08637166023254395, Overall 0.08784723281860352 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 195.20584106445312, Time 0.09265446662902832, Overall 0.0941309928894043 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 21.689537896050346, Time 0.09277629852294922, Overall 0.09425210952758789 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 290.79083251953125, Time 0.10793471336364746, Overall 0.10941123962402344 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 17.105343089384192, Time 0.10805034637451172, Overall 0.1095266342163086 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 143.0269775390625, Time 0.11934971809387207, Overall 0.12082767486572266 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 15.891886393229166, Time 0.11948037147521973, Overall 0.1209564208984375 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 251.04562377929688, Time 0.13424372673034668, Overall 0.13572049140930176 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 14.767389634076286, Time 0.13434910774230957, Overall 0.13582468032836914 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 134.62142944335938, Time 0.1407334804534912, Overall 0.14220976829528809 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 14.957936604817709, Time 0.14084792137145996, Overall 0.14232349395751953 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 361.12115478515625, Time 0.15233087539672852, Overall 0.1538076400756836 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 21.242420869715072, Time 0.15243172645568848, Overall 0.15390753746032715 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 163.350341796875, Time 0.15863776206970215, Overall 0.16011428833007812 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 18.150037977430557, Time 0.15874409675598145, Overall 0.16021943092346191 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 186.6538543701172, Time 0.1701366901397705, Overall 0.17161321640014648 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 10.979638492359834, Time 0.17023706436157227, Overall 0.17171263694763184 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 180.49856567382812, Time 0.17638683319091797, Overall 0.17786312103271484 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 20.055396185980904, Time 0.17650961875915527, Overall 0.17798566818237305 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 317.1058044433594, Time 0.18766117095947266, Overall 0.18913769721984863 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 18.65328261431526, Time 0.18774890899658203, Overall 0.1892251968383789 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 180.5802764892578, Time 0.19379687309265137, Overall 0.19527292251586914 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 20.06447516547309, Time 0.193892240524292, Overall 0.19536805152893066 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 235.07386779785156, Time 0.20614385604858398, Overall 0.20762038230895996 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 13.82787457634421, Time 0.20623135566711426, Overall 0.20770692825317383 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 188.59988403320312, Time 0.2125861644744873, Overall 0.21406245231628418 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 20.955542670355904, Time 0.2126765251159668, Overall 0.21415233612060547 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 415.20697021484375, Time 0.22396564483642578, Overall 0.22544217109680176 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 24.423939424402572, Time 0.2240581512451172, Overall 0.22553348541259766 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 108.49039459228516, Time 0.23016667366027832, Overall 0.2316431999206543 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 12.054488288031685, Time 0.2302720546722412, Overall 0.23174738883972168 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 291.1599426269531, Time 0.241363525390625, Overall 0.24283957481384277 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 17.127055448644303, Time 0.241469144821167, Overall 0.24294471740722656 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 227.7084197998047, Time 0.24750995635986328, Overall 0.24898648262023926 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 25.30093553331163, Time 0.24760937690734863, Overall 0.2490849494934082 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 207.09613037109375, Time 0.25873804092407227, Overall 0.26021480560302734 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 12.182125315946692, Time 0.2588376998901367, Overall 0.2603135108947754 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 92.94046020507812, Time 0.26518964767456055, Overall 0.2666664123535156 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 10.326717800564236, Time 0.2653036117553711, Overall 0.26677918434143066 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 225.8187713623047, Time 0.2768893241882324, Overall 0.2783658504486084 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 13.283457138959099, Time 0.2769956588745117, Overall 0.2784714698791504 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 277.89532470703125, Time 0.2834029197692871, Overall 0.2848794460296631 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 30.87725830078125, Time 0.283538818359375, Overall 0.2850148677825928 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 260.0650634765625, Time 0.29481983184814453, Overall 0.2962963581085205 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 15.297944910386029, Time 0.2949202060699463, Overall 0.29639554023742676 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 220.3164825439453, Time 0.3011152744293213, Overall 0.30259203910827637 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 24.47960917154948, Time 0.3012220859527588, Overall 0.30269789695739746 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 412.61773681640625, Time 0.3123610019683838, Overall 0.31383705139160156 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 24.271631577435663, Time 0.31246232986450195, Overall 0.3139379024505615 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 195.1291961669922, Time 0.31851911544799805, Overall 0.3199954032897949 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 21.681021796332466, Time 0.3186171054840088, Overall 0.32009243965148926 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 296.8972473144531, Time 0.3336753845214844, Overall 0.33515286445617676 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 17.464543959673712, Time 0.33377814292907715, Overall 0.335254430770874 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 128.17813110351562, Time 0.3412761688232422, Overall 0.34275245666503906 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 14.242014567057291, Time 0.34137701988220215, Overall 0.3428528308868408 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 405.9588623046875, Time 0.3523521423339844, Overall 0.35382843017578125 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 23.879933076746322, Time 0.35244107246398926, Overall 0.3539164066314697 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 133.3762664794922, Time 0.35836172103881836, Overall 0.35983824729919434 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 14.819585164388021, Time 0.35845494270324707, Overall 0.3599374294281006 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 428.80364990234375, Time 0.36977219581604004, Overall 0.371248722076416 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 25.223744111902572, Time 0.36986327171325684, Overall 0.3713390827178955 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 264.41021728515625, Time 0.3758842945098877, Overall 0.37736034393310547 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 29.37891303168403, Time 0.37598252296447754, Overall 0.3774583339691162 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 253.13780212402344, Time 0.010341882705688477, Overall 0.3907918930053711 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 14.890458948471966, Time 0.010436058044433594, Overall 0.3908853530883789 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 122.18386840820312, Time 0.016543149948120117, Overall 0.39699363708496094 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 13.575985378689236, Time 0.01663994789123535, Overall 0.39708900451660156 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 221.7301483154297, Time 0.02781200408935547, Overall 0.4082624912261963 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 13.04294990090763, Time 0.02791118621826172, Overall 0.40836048126220703 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 206.91256713867188, Time 0.03456306457519531, Overall 0.41501450538635254 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 22.990285237630207, Time 0.034676313400268555, Overall 0.4151265621185303 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 376.6322021484375, Time 0.04876279830932617, Overall 0.429213285446167 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 22.154835420496322, Time 0.04885387420654297, Overall 0.4293034076690674 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 200.1957550048828, Time 0.054960012435913086, Overall 0.4354104995727539 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 22.243972778320312, Time 0.05506587028503418, Overall 0.4355154037475586 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 237.10154724121094, Time 0.06634688377380371, Overall 0.44679713249206543 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 13.94714983771829, Time 0.06644868850708008, Overall 0.4468979835510254 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 133.74107360839844, Time 0.07258033752441406, Overall 0.4530303478240967 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 14.860119289822048, Time 0.07268500328063965, Overall 0.45313429832458496 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 360.64520263671875, Time 0.08400106430053711, Overall 0.4644510746002197 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 21.214423684512866, Time 0.08409833908081055, Overall 0.46454763412475586 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 164.412841796875, Time 0.09020161628723145, Overall 0.47065162658691406 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 18.26809353298611, Time 0.09030437469482422, Overall 0.47075414657592773 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 331.41455078125, Time 0.10131311416625977, Overall 0.4817633628845215 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 19.49497357536765, Time 0.10140633583068848, Overall 0.4818558692932129 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 132.71542358398438, Time 0.10768580436706543, Overall 0.48813652992248535 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 14.746158175998264, Time 0.10778594017028809, Overall 0.4882352352142334 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 454.1573791503906, Time 0.11887359619140625, Overall 0.49932336807250977 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 26.715139950022976, Time 0.11897110939025879, Overall 0.4994204044342041 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 181.98793029785156, Time 0.12511634826660156, Overall 0.5055665969848633 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 20.22088114420573, Time 0.12521815299987793, Overall 0.5056676864624023 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 429.8935852050781, Time 0.13625621795654297, Overall 0.5167059898376465 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 25.28785795323989, Time 0.13634777069091797, Overall 0.5167973041534424 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 139.7830047607422, Time 0.14231204986572266, Overall 0.5227622985839844 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 15.531444973415798, Time 0.14240360260009766, Overall 0.522852897644043 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 297.4884033203125, Time 0.15359091758728027, Overall 0.534041166305542 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 17.499317842371322, Time 0.1536731719970703, Overall 0.5341224670410156 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 151.39764404296875, Time 0.15947461128234863, Overall 0.5399243831634521 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 16.82196044921875, Time 0.15958571434020996, Overall 0.5400354862213135 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 526.1587524414062, Time 0.17034435272216797, Overall 0.5507943630218506 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 30.950514849494486, Time 0.17042994499206543, Overall 0.5508794784545898 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 189.15927124023438, Time 0.17630839347839355, Overall 0.5567584037780762 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 21.017696804470486, Time 0.17639684677124023, Overall 0.5568466186523438 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 310.2640380859375, Time 0.18725848197937012, Overall 0.5677084922790527 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 18.25082576976103, Time 0.1873457431793213, Overall 0.5677952766418457 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 199.37289428710938, Time 0.19318795204162598, Overall 0.5736382007598877 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 22.152543809678818, Time 0.19328022003173828, Overall 0.5737297534942627 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 379.3507385253906, Time 0.20415902137756348, Overall 0.584608793258667 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 22.314749325022976, Time 0.2042536735534668, Overall 0.5847032070159912 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 146.3191680908203, Time 0.21046090126037598, Overall 0.5909111499786377 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 16.25768534342448, Time 0.21058320999145508, Overall 0.5910332202911377 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 298.45623779296875, Time 0.22343039512634277, Overall 0.6038804054260254 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 17.556249281939337, Time 0.2235422134399414, Overall 0.6039915084838867 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 230.83779907226562, Time 0.22969532012939453, Overall 0.6101455688476562 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 25.648644341362846, Time 0.2297956943511963, Overall 0.6102452278137207 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 381.82305908203125, Time 0.24084258079528809, Overall 0.6212928295135498 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 22.460179946001837, Time 0.24093270301818848, Overall 0.6213822364807129 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 182.1325225830078, Time 0.24781584739685059, Overall 0.6282670497894287 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 20.236946953667534, Time 0.2479093074798584, Overall 0.628359317779541 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 223.90679931640625, Time 0.2645692825317383, Overall 0.6450197696685791 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 13.170988195082721, Time 0.26465845108032227, Overall 0.6451077461242676 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 246.8092803955078, Time 0.2707390785217285, Overall 0.6511890888214111 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 27.423253377278645, Time 0.27083539962768555, Overall 0.6512846946716309 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 355.9542541503906, Time 0.2816758155822754, Overall 0.6621255874633789 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 20.938485538258274, Time 0.28175926208496094, Overall 0.6622087955474854 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 250.3579864501953, Time 0.2877674102783203, Overall 0.6682181358337402 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 27.817554050021702, Time 0.28786754608154297, Overall 0.6683175563812256 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 297.734375, Time 0.29891467094421387, Overall 0.6793649196624756 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 17.513786764705884, Time 0.29900383949279785, Overall 0.6794538497924805 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 202.0998077392578, Time 0.3049187660217285, Overall 0.685368537902832 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 22.45553419325087, Time 0.30501246452331543, Overall 0.6854619979858398 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 330.1881408691406, Time 0.3158681392669678, Overall 0.6963176727294922 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 19.422831815831803, Time 0.31595563888549805, Overall 0.6964046955108643 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 154.3441162109375, Time 0.3219766616821289, Overall 0.7024266719818115 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 17.14934624565972, Time 0.3220639228820801, Overall 0.7025132179260254 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 287.2308349609375, Time 0.3330080509185791, Overall 0.7134580612182617 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 16.895931468290442, Time 0.3330965042114258, Overall 0.7135457992553711 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 191.9844970703125, Time 0.339261531829834, Overall 0.7197117805480957 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 21.33161078559028, Time 0.3393571376800537, Overall 0.719806432723999 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 277.53436279296875, Time 0.3518366813659668, Overall 0.7322866916656494 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 16.325550752527572, Time 0.3519282341003418, Overall 0.7323777675628662 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 182.06211853027344, Time 0.359544038772583, Overall 0.739995002746582 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 20.229124281141495, Time 0.3596363067626953, Overall 0.7400858402252197 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 451.2745056152344, Time 0.010155439376831055, Overall 0.753138542175293 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 25.07080586751302, Time 0.010239601135253906, Overall 0.7532219886779785 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 164.009033203125, Time 0.015947341918945312, Overall 0.7589302062988281 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 20.501129150390625, Time 0.016058921813964844, Overall 0.7590410709381104 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 340.316650390625, Time 0.02680492401123047, Overall 0.7697880268096924 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 18.906480577256943, Time 0.026908159255981445, Overall 0.7698900699615479 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 122.51885223388672, Time 0.03279685974121094, Overall 0.7757794857025146 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 15.31485652923584, Time 0.03288841247558594, Overall 0.7758705615997314 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 306.09185791015625, Time 0.04382467269897461, Overall 0.7868075370788574 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 17.005103217230904, Time 0.04391193389892578, Overall 0.7868938446044922 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 180.60379028320312, Time 0.04974722862243652, Overall 0.7927296161651611 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 22.57547378540039, Time 0.049839019775390625, Overall 0.7928214073181152 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 341.3136901855469, Time 0.06084084510803223, Overall 0.803823709487915 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 18.961871676974827, Time 0.060927391052246094, Overall 0.8039095401763916 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 121.51146697998047, Time 0.06659197807312012, Overall 0.8095743656158447 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 15.188933372497559, Time 0.06668424606323242, Overall 0.809666633605957 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 302.5458984375, Time 0.07765913009643555, Overall 0.8206417560577393 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 16.80810546875, Time 0.0777437686920166, Overall 0.8207263946533203 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 187.67433166503906, Time 0.0834496021270752, Overall 0.8264319896697998 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 23.459291458129883, Time 0.08353686332702637, Overall 0.8265185356140137 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 415.2032775878906, Time 0.09484648704528809, Overall 0.8378291130065918 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 23.066848754882812, Time 0.09493446350097656, Overall 0.837916374206543 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 162.9917449951172, Time 0.10062885284423828, Overall 0.8436117172241211 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 20.37396812438965, Time 0.10072207450866699, Overall 0.8437042236328125 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 367.9454345703125, Time 0.11170625686645508, Overall 0.854689359664917 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 20.44141303168403, Time 0.11179041862487793, Overall 0.8547725677490234 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 167.7412567138672, Time 0.11788272857666016, Overall 0.8608660697937012 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 20.9676570892334, Time 0.11799502372741699, Overall 0.8609774112701416 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 320.9735412597656, Time 0.13024353981018066, Overall 0.8732266426086426 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 17.831863403320312, Time 0.13033485412597656, Overall 0.8733172416687012 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 177.60572814941406, Time 0.13605189323425293, Overall 0.8790347576141357 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 22.200716018676758, Time 0.13614320755004883, Overall 0.8791253566741943 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 348.7560119628906, Time 0.1473391056060791, Overall 0.8903219699859619 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 19.37533399793837, Time 0.14742732048034668, Overall 0.8904092311859131 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 233.74215698242188, Time 0.1531820297241211, Overall 0.8961646556854248 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 29.217769622802734, Time 0.1532740592956543, Overall 0.8962557315826416 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 412.3738708496094, Time 0.16446757316589355, Overall 0.9074504375457764 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 22.909659491644966, Time 0.16455793380737305, Overall 0.9075403213500977 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 196.48289489746094, Time 0.1704404354095459, Overall 0.9134230613708496 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 24.560361862182617, Time 0.1705493927001953, Overall 0.9135315418243408 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 386.8630065917969, Time 0.18188142776489258, Overall 0.9248645305633545 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 21.492389255099827, Time 0.1819934844970703, Overall 0.9249758720397949 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 211.52268981933594, Time 0.1895456314086914, Overall 0.9325292110443115 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 26.440336227416992, Time 0.1896533966064453, Overall 0.9326364994049072 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 395.6923828125, Time 0.20610499382019043, Overall 0.9490883350372314 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 21.98291015625, Time 0.20619773864746094, Overall 0.9491796493530273 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 210.5931854248047, Time 0.21214532852172852, Overall 0.9551281929016113 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 26.324148178100586, Time 0.21224379539489746, Overall 0.955225944519043 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 325.7163391113281, Time 0.2240896224975586, Overall 0.9670727252960205 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 18.095352172851562, Time 0.2241816520690918, Overall 0.9671638011932373 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 163.83560180664062, Time 0.23033928871154785, Overall 0.9733221530914307 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 20.479450225830078, Time 0.23044228553771973, Overall 0.9734244346618652 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 399.69915771484375, Time 0.2430109977722168, Overall 0.9859952926635742 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 22.205508761935764, Time 0.2431190013885498, Overall 0.9861016273498535 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 178.05410766601562, Time 0.2527732849121094, Overall 0.9957571029663086 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 22.256763458251953, Time 0.2529006004333496, Overall 0.9958832263946533 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 305.04620361328125, Time 0.26683759689331055, Overall 1.0098209381103516 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 16.947011311848957, Time 0.26692771911621094, Overall 1.0099101066589355 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 221.0592803955078, Time 0.2728240489959717, Overall 1.0158073902130127 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 27.632410049438477, Time 0.2729227542877197, Overall 1.0159049034118652 \n",
            "Epoch    15: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 423.1200256347656, Time 0.285463809967041, Overall 1.0284478664398193 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 23.506668090820312, Time 0.2855558395385742, Overall 1.028538465499878 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 236.1533660888672, Time 0.2929799556732178, Overall 1.0359766483306885 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 29.5191707611084, Time 0.2930893898010254, Overall 1.036071538925171 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 461.8120422363281, Time 0.30411195755004883, Overall 1.0470950603485107 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 25.656224568684895, Time 0.3041994571685791, Overall 1.0471813678741455 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 194.67724609375, Time 0.30994415283203125, Overall 1.0529272556304932 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 24.33465576171875, Time 0.3100595474243164, Overall 1.053041696548462 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 354.907470703125, Time 0.3212246894836426, Overall 1.0642073154449463 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 19.717081705729168, Time 0.3213183879852295, Overall 1.064300298690796 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 223.61825561523438, Time 0.32727527618408203, Overall 1.0702581405639648 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 27.952281951904297, Time 0.32737159729003906, Overall 1.0703539848327637 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 305.1754455566406, Time 0.33858537673950195, Overall 1.0815680027008057 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 16.95419141981337, Time 0.33867788314819336, Overall 1.0816600322723389 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 188.31553649902344, Time 0.34456443786621094, Overall 1.0875473022460938 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 23.53944206237793, Time 0.3446693420410156, Overall 1.0876519680023193 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 414.93292236328125, Time 0.3562800884246826, Overall 1.0992629528045654 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 23.051829020182293, Time 0.35637736320495605, Overall 1.0993595123291016 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 170.05374145507812, Time 0.362255334854126, Overall 1.1052379608154297 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 21.256717681884766, Time 0.36235642433166504, Overall 1.1053383350372314 \n",
            "It took 1.1070947647094727 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 0.000152587890625 seconds to load from the pickles.\n",
            "It took 0.0004761219024658203 seconds to load the sparse matrices.\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 0.00010538101196289062 seconds to load from the pickles.\n",
            "It took 0.0003178119659423828 seconds to load the sparse matrices.\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 21.549558639526367, Time 0.0023844242095947266, Overall 0.0035181045532226562 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 7.183186213175456, Time 0.0024776458740234375, Overall 0.0036106109619140625 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 17.319856643676758, Time 0.003537416458129883, Overall 0.004670858383178711 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 8.659928321838379, Time 0.0036242008209228516, Overall 0.00475764274597168 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 12.84377670288086, Time 0.006041049957275391, Overall 0.00717473030090332 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 4.281258900960286, Time 0.006125688552856445, Overall 0.00725865364074707 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 18.8310604095459, Time 0.00717616081237793, Overall 0.008309602737426758 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 9.41553020477295, Time 0.007266998291015625, Overall 0.00839996337890625 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 5.814655780792236, Time 0.009510993957519531, Overall 0.010644197463989258 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.938218593597412, Time 0.009598255157470703, Overall 0.010730981826782227 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 19.04481315612793, Time 0.010468721389770508, Overall 0.011601924896240234 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 9.522406578063965, Time 0.010548830032348633, Overall 0.011681556701660156 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 3.470761299133301, Time 0.012665987014770508, Overall 0.013799190521240234 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.1569204330444336, Time 0.012753963470458984, Overall 0.013887643814086914 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 27.950054168701172, Time 0.013596057891845703, Overall 0.014729499816894531 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 13.975027084350586, Time 0.013681411743164062, Overall 0.014814138412475586 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 2.0285208225250244, Time 0.015790939331054688, Overall 0.016924381256103516 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 0.6761736075083414, Time 0.01586294174194336, Overall 0.016995668411254883 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 36.90449523925781, Time 0.016753673553466797, Overall 0.017887592315673828 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 18.452247619628906, Time 0.01682305335998535, Overall 0.017955780029296875 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 3.86327862739563, Time 0.018901586532592773, Overall 0.0200345516204834 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.28775954246521, Time 0.01897263526916504, Overall 0.020105600357055664 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 39.61162185668945, Time 0.019819259643554688, Overall 0.020952463150024414 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 19.805810928344727, Time 0.019891023635864258, Overall 0.02102351188659668 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 16.111955642700195, Time 0.022264480590820312, Overall 0.023398637771606445 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 5.370651880900065, Time 0.022335290908813477, Overall 0.023468494415283203 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 35.28874206542969, Time 0.023358583450317383, Overall 0.02449178695678711 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 17.644371032714844, Time 0.023439645767211914, Overall 0.024572134017944336 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 23.150497436523438, Time 0.025480985641479492, Overall 0.02661442756652832 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 7.7168324788411455, Time 0.025554418563842773, Overall 0.0266878604888916 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 57.956180572509766, Time 0.02639174461364746, Overall 0.02752518653869629 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 28.978090286254883, Time 0.02646780014038086, Overall 0.027600526809692383 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 0.31891846656799316, Time 0.028481721878051758, Overall 0.029614686965942383 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 0.10630615552266438, Time 0.02855682373046875, Overall 0.029689550399780273 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 55.87533950805664, Time 0.029416561126708984, Overall 0.03054976463317871 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 27.93766975402832, Time 0.029494047164916992, Overall 0.030626535415649414 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 2.9751009941101074, Time 0.03150582313537598, Overall 0.032639265060424805 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 0.9917003313700358, Time 0.03157973289489746, Overall 0.03271293640136719 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 71.5157470703125, Time 0.03241300582885742, Overall 0.03354597091674805 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 35.75787353515625, Time 0.03249001502990723, Overall 0.03362274169921875 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 23.80497169494629, Time 0.03449821472167969, Overall 0.035631656646728516 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 7.934990564982097, Time 0.03457307815551758, Overall 0.035706520080566406 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 52.77552032470703, Time 0.03540682792663574, Overall 0.03654026985168457 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 26.387760162353516, Time 0.035486698150634766, Overall 0.036620140075683594 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 1.1355326175689697, Time 0.03752017021179199, Overall 0.03865337371826172 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 0.3785108725229899, Time 0.03759479522705078, Overall 0.03872823715209961 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 60.60572052001953, Time 0.03843951225280762, Overall 0.03957247734069824 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 30.302860260009766, Time 0.03851723670959473, Overall 0.03964972496032715 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 36.08270263671875, Time 0.04053831100463867, Overall 0.0416715145111084 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 12.027567545572916, Time 0.040610313415527344, Overall 0.04174375534057617 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 56.66070556640625, Time 0.04145979881286621, Overall 0.042592763900756836 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 28.330352783203125, Time 0.04153776168823242, Overall 0.04267072677612305 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 0.5495427846908569, Time 0.043523311614990234, Overall 0.04465627670288086 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 0.18318092823028564, Time 0.04359841346740723, Overall 0.04473137855529785 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 66.16078186035156, Time 0.04443097114562988, Overall 0.04556393623352051 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 33.08039093017578, Time 0.044507503509521484, Overall 0.04564023017883301 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 27.610605239868164, Time 0.04653811454772949, Overall 0.04767107963562012 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 9.203535079956055, Time 0.04661059379577637, Overall 0.047744035720825195 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 65.66681671142578, Time 0.04744362831115723, Overall 0.048577070236206055 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 32.83340835571289, Time 0.04752159118652344, Overall 0.04865407943725586 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 0.06741201877593994, Time 0.04951167106628418, Overall 0.050644636154174805 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 0.022470672925313313, Time 0.04958486557006836, Overall 0.050717830657958984 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 59.829437255859375, Time 0.05043745040893555, Overall 0.05157065391540527 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 29.914718627929688, Time 0.05051541328430176, Overall 0.05164813995361328 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 13.125578880310059, Time 0.05250978469848633, Overall 0.05364274978637695 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 4.375192960103353, Time 0.05258321762084961, Overall 0.05371594429016113 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 67.30813598632812, Time 0.053437232971191406, Overall 0.05457043647766113 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 33.65406799316406, Time 0.05351543426513672, Overall 0.054648399353027344 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 14.442712783813477, Time 0.055512189865112305, Overall 0.05664515495300293 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 4.814237594604492, Time 0.05558514595031738, Overall 0.05671834945678711 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 62.21708679199219, Time 0.05641913414001465, Overall 0.05755209922790527 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 31.108543395996094, Time 0.05649542808532715, Overall 0.05762815475463867 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 20.7673282623291, Time 0.05853462219238281, Overall 0.05966782569885254 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 6.9224427541097, Time 0.0586087703704834, Overall 0.059741973876953125 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 80.19715118408203, Time 0.059441566467285156, Overall 0.060575008392333984 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 40.098575592041016, Time 0.05952048301696777, Overall 0.0606532096862793 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 14.277054786682129, Time 0.06154608726501465, Overall 0.06267929077148438 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 4.759018262227376, Time 0.061620473861694336, Overall 0.06275415420532227 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 75.67807006835938, Time 0.062450408935546875, Overall 0.0635836124420166 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 37.83903503417969, Time 0.06252765655517578, Overall 0.0636606216430664 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 22.849224090576172, Time 0.0018334388732910156, Overall 0.06737542152404785 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 7.616408030192058, Time 0.0019180774688720703, Overall 0.0674598217010498 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.282303810119629, Time 0.002791881561279297, Overall 0.06833338737487793 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 7.1411519050598145, Time 0.002882242202758789, Overall 0.06842327117919922 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 15.817303657531738, Time 0.005029916763305664, Overall 0.0705714225769043 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 5.272434552510579, Time 0.005102634429931641, Overall 0.07064437866210938 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 16.168691635131836, Time 0.005959749221801758, Overall 0.07150077819824219 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 8.084345817565918, Time 0.0060384273529052734, Overall 0.0715794563293457 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 6.825645923614502, Time 0.008144378662109375, Overall 0.0736856460571289 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 2.2752153078715005, Time 0.008218050003051758, Overall 0.07375955581665039 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 18.185161590576172, Time 0.009079456329345703, Overall 0.07462072372436523 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 9.092580795288086, Time 0.009159088134765625, Overall 0.07470011711120605 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 6.271937847137451, Time 0.011210441589355469, Overall 0.0767519474029541 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 2.090645949045817, Time 0.01128530502319336, Overall 0.07682657241821289 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 17.93439292907715, Time 0.012103796005249023, Overall 0.07764506340026855 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 8.967196464538574, Time 0.012195825576782227, Overall 0.07773685455322266 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 5.2647223472595215, Time 0.01423025131225586, Overall 0.07977175712585449 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.754907449086507, Time 0.014310836791992188, Overall 0.07985210418701172 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 23.216163635253906, Time 0.015133857727050781, Overall 0.08067512512207031 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 11.608081817626953, Time 0.015212774276733398, Overall 0.08075356483459473 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 2.168821096420288, Time 0.017231225967407227, Overall 0.08277249336242676 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 0.7229403654734293, Time 0.01731133460998535, Overall 0.08285212516784668 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 28.299907684326172, Time 0.018137216567993164, Overall 0.0836782455444336 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 14.149953842163086, Time 0.01821422576904297, Overall 0.0837547779083252 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 2.2640042304992676, Time 0.020196199417114258, Overall 0.08573722839355469 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 0.7546680768330892, Time 0.02026963233947754, Overall 0.08581018447875977 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 27.19229507446289, Time 0.021109819412231445, Overall 0.08665108680725098 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 13.596147537231445, Time 0.021188974380493164, Overall 0.08672976493835449 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 12.445605278015137, Time 0.02317976951599121, Overall 0.08872127532958984 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 4.148535092671712, Time 0.023253202438354492, Overall 0.08879470825195312 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 24.297956466674805, Time 0.02408742904663086, Overall 0.08962869644165039 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 12.148978233337402, Time 0.024164199829101562, Overall 0.08970499038696289 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 0.12712672352790833, Time 0.02637314796447754, Overall 0.09191417694091797 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 0.04237557450930277, Time 0.026439666748046875, Overall 0.0919806957244873 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 39.11021423339844, Time 0.02724742889404297, Overall 0.0927884578704834 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 19.55510711669922, Time 0.027352333068847656, Overall 0.09289407730102539 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 8.562207221984863, Time 0.02967381477355957, Overall 0.09521603584289551 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 2.8540690739949546, Time 0.029752254486083984, Overall 0.09529376029968262 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 42.699928283691406, Time 0.030805587768554688, Overall 0.09634685516357422 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 21.349964141845703, Time 0.03088212013244629, Overall 0.09642267227172852 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 7.240756511688232, Time 0.032932281494140625, Overall 0.09847378730773926 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 2.4135855038960776, Time 0.033003807067871094, Overall 0.09854459762573242 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 29.49982452392578, Time 0.03386378288269043, Overall 0.09940481185913086 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 14.74991226196289, Time 0.033937931060791016, Overall 0.09947872161865234 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 1.5851658582687378, Time 0.03594326972961426, Overall 0.10148453712463379 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 0.5283886194229126, Time 0.036012887954711914, Overall 0.10155344009399414 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 31.133630752563477, Time 0.03687024116516113, Overall 0.10241127014160156 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 15.566815376281738, Time 0.03694510459899902, Overall 0.10248589515686035 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 11.26675033569336, Time 0.03901243209838867, Overall 0.1045536994934082 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 3.7555834452311196, Time 0.039084672927856445, Overall 0.10462617874145508 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 45.554054260253906, Time 0.03996014595031738, Overall 0.10550141334533691 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 22.777027130126953, Time 0.040039777755737305, Overall 0.10558056831359863 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 7.569538116455078, Time 0.042029380798339844, Overall 0.10757064819335938 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 2.523179372151693, Time 0.04210329055786133, Overall 0.10764479637145996 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 47.188053131103516, Time 0.042936086654663086, Overall 0.10847759246826172 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 23.594026565551758, Time 0.04301285743713379, Overall 0.10855388641357422 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 18.124364852905273, Time 0.04500865936279297, Overall 0.1105499267578125 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 6.041454950968425, Time 0.04508161544799805, Overall 0.11062288284301758 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 42.532047271728516, Time 0.04592442512512207, Overall 0.1114656925201416 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 21.266023635864258, Time 0.04600119590759277, Overall 0.1115419864654541 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 1.1948556900024414, Time 0.048003196716308594, Overall 0.11354446411132812 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 0.3982852300008138, Time 0.04807734489440918, Overall 0.1136178970336914 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 32.01362991333008, Time 0.048918962478637695, Overall 0.11446022987365723 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 16.00681495666504, Time 0.04899716377258301, Overall 0.11453771591186523 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 1.2694764137268066, Time 0.05097603797912598, Overall 0.1165170669555664 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 0.42315880457560223, Time 0.051050662994384766, Overall 0.1165916919708252 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 31.314542770385742, Time 0.05190777778625488, Overall 0.11744904518127441 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 15.657271385192871, Time 0.058295488357543945, Overall 0.12383794784545898 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 1.5945760011672974, Time 0.061124324798583984, Overall 0.12666606903076172 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 0.5315253337224325, Time 0.06118607521057129, Overall 0.12672662734985352 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 41.06740951538086, Time 0.06206488609313965, Overall 0.12760639190673828 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 20.53370475769043, Time 0.06212973594665527, Overall 0.1276702880859375 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 5.185311317443848, Time 0.06418919563293457, Overall 0.1297307014465332 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 1.728437105814616, Time 0.06424570083618164, Overall 0.12978649139404297 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 38.36845016479492, Time 0.06509017944335938, Overall 0.1306314468383789 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 19.18422508239746, Time 0.06515359878540039, Overall 0.13069415092468262 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 2.556353807449341, Time 0.06716227531433105, Overall 0.1327037811279297 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 0.8521179358164469, Time 0.06722021102905273, Overall 0.13276124000549316 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 34.34358215332031, Time 0.06804728507995605, Overall 0.1335887908935547 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 17.171791076660156, Time 0.06811046600341797, Overall 0.1336512565612793 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 28.77434730529785, Time 0.0017480850219726562, Overall 0.1371471881866455 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 7.193586826324463, Time 0.0018084049224853516, Overall 0.1372063159942627 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 7.894406318664551, Time 0.0025234222412109375, Overall 0.13792181015014648 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 7.894406318664551, Time 0.0025873184204101562, Overall 0.1379852294921875 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 16.219764709472656, Time 0.0047266483306884766, Overall 0.14012527465820312 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 4.054941177368164, Time 0.00478363037109375, Overall 0.1401815414428711 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 8.232234954833984, Time 0.0054056644439697266, Overall 0.14080381393432617 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 8.232234954833984, Time 0.005491018295288086, Overall 0.14088916778564453 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 8.356008529663086, Time 0.007619619369506836, Overall 0.14301800727844238 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 2.0890021324157715, Time 0.007676362991333008, Overall 0.14307403564453125 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 8.4896240234375, Time 0.008294105529785156, Overall 0.1436924934387207 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 8.4896240234375, Time 0.008354663848876953, Overall 0.1437525749206543 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 5.124468803405762, Time 0.01042318344116211, Overall 0.14582180976867676 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.2811172008514404, Time 0.010523080825805664, Overall 0.1459212303161621 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 16.661941528320312, Time 0.011153936386108398, Overall 0.14655232429504395 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 16.661941528320312, Time 0.0112152099609375, Overall 0.14661312103271484 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 21.52109146118164, Time 0.013282299041748047, Overall 0.1486806869506836 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 5.38027286529541, Time 0.013339757919311523, Overall 0.14873790740966797 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 11.181884765625, Time 0.013973474502563477, Overall 0.14937186241149902 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 11.181884765625, Time 0.014034509658813477, Overall 0.14943265914916992 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 9.296154975891113, Time 0.0161893367767334, Overall 0.15158796310424805 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 2.3240387439727783, Time 0.01624584197998047, Overall 0.1516437530517578 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 14.583809852600098, Time 0.01689910888671875, Overall 0.1522974967956543 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 14.583809852600098, Time 0.01696038246154785, Overall 0.1523582935333252 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 10.436346054077148, Time 0.019052505493164062, Overall 0.1544508934020996 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 2.609086513519287, Time 0.01910853385925293, Overall 0.15450596809387207 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 25.316360473632812, Time 0.019761323928833008, Overall 0.15515995025634766 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 25.316360473632812, Time 0.019822359085083008, Overall 0.15522003173828125 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 12.479909896850586, Time 0.022061824798583984, Overall 0.15745997428894043 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 3.1199774742126465, Time 0.02211904525756836, Overall 0.1575169563293457 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 23.25408172607422, Time 0.022813081741333008, Overall 0.15821146965026855 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 23.25408172607422, Time 0.022875547409057617, Overall 0.15827322006225586 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 26.651689529418945, Time 0.02498340606689453, Overall 0.16038203239440918 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 6.662922382354736, Time 0.025040626525878906, Overall 0.16043853759765625 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 24.07669448852539, Time 0.02569746971130371, Overall 0.16109561920166016 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 24.07669448852539, Time 0.025758981704711914, Overall 0.16115665435791016 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 2.6523587703704834, Time 0.027895212173461914, Overall 0.16329383850097656 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 0.6630896925926208, Time 0.027953624725341797, Overall 0.16335105895996094 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 19.084426879882812, Time 0.028609037399291992, Overall 0.16400718688964844 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 19.084426879882812, Time 0.028670310974121094, Overall 0.16406822204589844 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 2.201409339904785, Time 0.03083205223083496, Overall 0.1662306785583496 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 0.5503523349761963, Time 0.03088998794555664, Overall 0.16628742218017578 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 17.998289108276367, Time 0.031531333923339844, Overall 0.1669297218322754 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 17.998289108276367, Time 0.03159141540527344, Overall 0.16698884963989258 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 12.52488899230957, Time 0.03369879722595215, Overall 0.1690969467163086 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 3.1312222480773926, Time 0.03375554084777832, Overall 0.16915321350097656 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 25.060405731201172, Time 0.034375667572021484, Overall 0.16977405548095703 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 25.060405731201172, Time 0.03443574905395508, Overall 0.16983342170715332 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 2.3573803901672363, Time 0.036627769470214844, Overall 0.1720263957977295 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.5893450975418091, Time 0.036684513092041016, Overall 0.17208218574523926 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 22.731204986572266, Time 0.037351131439208984, Overall 0.17274951934814453 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 22.731204986572266, Time 0.037413597106933594, Overall 0.17281126976013184 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 7.320591926574707, Time 0.03966045379638672, Overall 0.17505884170532227 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.8301479816436768, Time 0.03971695899963379, Overall 0.17511487007141113 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 24.599180221557617, Time 0.04033327102661133, Overall 0.17573142051696777 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 24.599180221557617, Time 0.04039478302001953, Overall 0.17579245567321777 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 8.771195411682129, Time 0.04282569885253906, Overall 0.1782238483428955 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 2.1927988529205322, Time 0.042882442474365234, Overall 0.17828035354614258 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 19.01167106628418, Time 0.04353189468383789, Overall 0.17893028259277344 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 19.01167106628418, Time 0.04359269142150879, Overall 0.17899036407470703 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 13.674346923828125, Time 0.045679330825805664, Overall 0.1810777187347412 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 3.4185867309570312, Time 0.045735836029052734, Overall 0.18113350868225098 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 22.794742584228516, Time 0.04635143280029297, Overall 0.18174982070922852 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 22.794742584228516, Time 0.04641389846801758, Overall 0.18181180953979492 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 6.138021945953369, Time 0.048563480377197266, Overall 0.1839618682861328 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.5345054864883423, Time 0.04862070083618164, Overall 0.18401837348937988 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 17.067283630371094, Time 0.04922795295715332, Overall 0.18462634086608887 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 17.067283630371094, Time 0.04928898811340332, Overall 0.18468642234802246 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 9.792823791503906, Time 0.051377058029174805, Overall 0.18677592277526855 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 2.4482059478759766, Time 0.0514369010925293, Overall 0.18683481216430664 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 19.074249267578125, Time 0.05208945274353027, Overall 0.18748784065246582 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 19.074249267578125, Time 0.05214953422546387, Overall 0.1875472068786621 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 2.4587903022766113, Time 0.05423545837402344, Overall 0.18963408470153809 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 0.6146975755691528, Time 0.05429267883300781, Overall 0.18969011306762695 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 20.532434463500977, Time 0.05497479438781738, Overall 0.19037318229675293 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 20.532434463500977, Time 0.05503654479980469, Overall 0.19043445587158203 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 12.736185073852539, Time 0.05712103843688965, Overall 0.1925191879272461 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 3.1840462684631348, Time 0.057178497314453125, Overall 0.19257640838623047 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 17.52637481689453, Time 0.05781388282775879, Overall 0.19321227073669434 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 17.52637481689453, Time 0.057874441146850586, Overall 0.19327235221862793 \n",
            "It took 0.19401812553405762 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 6.914138793945312e-05 seconds to load from the pickles.\n",
            "It took 0.0002598762512207031 seconds to load the sparse matrices.\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 223.563232421875, Time 0.007948637008666992, Overall 0.00933527946472168 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 74.52107747395833, Time 0.008021116256713867, Overall 0.009406805038452148 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 175.42575073242188, Time 0.012685060501098633, Overall 0.014071941375732422 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 87.71287536621094, Time 0.012767314910888672, Overall 0.014153003692626953 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 183.82264709472656, Time 0.021719932556152344, Overall 0.023107528686523438 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 61.27421569824219, Time 0.021800518035888672, Overall 0.023186445236206055 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 114.09405517578125, Time 0.027779817581176758, Overall 0.02916717529296875 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 57.047027587890625, Time 0.02787017822265625, Overall 0.029256105422973633 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 160.5645294189453, Time 0.036516666412353516, Overall 0.0379033088684082 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 53.5215098063151, Time 0.03659391403198242, Overall 0.0379796028137207 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 105.30533599853516, Time 0.04124164581298828, Overall 0.04262852668762207 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 52.65266799926758, Time 0.04132437705993652, Overall 0.042710065841674805 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 137.5637664794922, Time 0.049633026123046875, Overall 0.051020145416259766 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 45.8545888264974, Time 0.049742698669433594, Overall 0.05112862586975098 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 115.51200103759766, Time 0.05446934700012207, Overall 0.05585622787475586 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 57.75600051879883, Time 0.05456733703613281, Overall 0.055953264236450195 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 161.4525146484375, Time 0.06335997581481934, Overall 0.06474685668945312 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 53.8175048828125, Time 0.0634453296661377, Overall 0.06483101844787598 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 144.90286254882812, Time 0.06805014610290527, Overall 0.06943702697753906 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 72.45143127441406, Time 0.0681300163269043, Overall 0.06951594352722168 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 131.20765686035156, Time 0.07623982429504395, Overall 0.07762670516967773 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 43.73588562011719, Time 0.07631087303161621, Overall 0.07769656181335449 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 128.22256469726562, Time 0.08098340034484863, Overall 0.08237004280090332 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 64.11128234863281, Time 0.08106064796447754, Overall 0.08244657516479492 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 136.79833984375, Time 0.08948540687561035, Overall 0.09087204933166504 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 45.599446614583336, Time 0.08957791328430176, Overall 0.09096384048461914 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 128.74884033203125, Time 0.09419441223144531, Overall 0.0955812931060791 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 64.37442016601562, Time 0.09427690505981445, Overall 0.09566259384155273 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 187.93748474121094, Time 0.10233497619628906, Overall 0.10372185707092285 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 62.64582824707031, Time 0.10240650177001953, Overall 0.10379219055175781 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 174.080322265625, Time 0.10704159736633301, Overall 0.1084280014038086 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 87.0401611328125, Time 0.10711789131164551, Overall 0.10850358009338379 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 214.4874267578125, Time 0.11512517929077148, Overall 0.11651206016540527 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 71.49580891927083, Time 0.11519765853881836, Overall 0.11658358573913574 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 152.5611114501953, Time 0.1198122501373291, Overall 0.12119913101196289 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 76.28055572509766, Time 0.11989164352416992, Overall 0.1212773323059082 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 118.44998168945312, Time 0.12833404541015625, Overall 0.12972140312194824 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 39.48332722981771, Time 0.12841320037841797, Overall 0.12979912757873535 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 164.81179809570312, Time 0.1331648826599121, Overall 0.1345515251159668 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 82.40589904785156, Time 0.13325119018554688, Overall 0.13463687896728516 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 126.58779907226562, Time 0.14149022102355957, Overall 0.14288640022277832 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 42.19593302408854, Time 0.14158987998962402, Overall 0.1429755687713623 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 152.9593505859375, Time 0.1463327407836914, Overall 0.147719144821167 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 76.47967529296875, Time 0.14642596244812012, Overall 0.1478116512298584 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 91.72357940673828, Time 0.15494894981384277, Overall 0.15633559226989746 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 30.57452646891276, Time 0.1550276279449463, Overall 0.15641355514526367 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 139.39529418945312, Time 0.15985989570617676, Overall 0.16124749183654785 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 69.69764709472656, Time 0.1599593162536621, Overall 0.1613461971282959 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 132.22328186035156, Time 0.1682722568511963, Overall 0.16965866088867188 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 44.07442728678385, Time 0.16835689544677734, Overall 0.16974306106567383 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 141.31890869140625, Time 0.17294621467590332, Overall 0.1743326187133789 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 70.65945434570312, Time 0.1730341911315918, Overall 0.17442035675048828 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 117.78421783447266, Time 0.18105268478393555, Overall 0.18243956565856934 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 39.26140594482422, Time 0.18113303184509277, Overall 0.18251895904541016 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 197.3934783935547, Time 0.18567395210266113, Overall 0.18706202507019043 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 98.69673919677734, Time 0.18576407432556152, Overall 0.1871500015258789 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 103.27717590332031, Time 0.1938467025756836, Overall 0.19523358345031738 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 34.42572530110677, Time 0.19393229484558105, Overall 0.19531822204589844 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 203.55067443847656, Time 0.19846343994140625, Overall 0.19985008239746094 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 101.77533721923828, Time 0.1985633373260498, Overall 0.1999492645263672 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 99.66838073730469, Time 0.20656442642211914, Overall 0.20795106887817383 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 33.22279357910156, Time 0.20664548873901367, Overall 0.20803165435791016 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 213.87713623046875, Time 0.21123147010803223, Overall 0.21261811256408691 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 106.93856811523438, Time 0.2113208770751953, Overall 0.2127068042755127 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 42.244197845458984, Time 0.21936702728271484, Overall 0.22075366973876953 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 14.081399281819662, Time 0.2194530963897705, Overall 0.2208390235900879 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 208.06825256347656, Time 0.22404789924621582, Overall 0.2254347801208496 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 104.03412628173828, Time 0.22413921356201172, Overall 0.2255253791809082 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 111.34632110595703, Time 0.23215508460998535, Overall 0.23354172706604004 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 37.115440368652344, Time 0.2322402000427246, Overall 0.2336258888244629 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 169.78610229492188, Time 0.23708844184875488, Overall 0.23847508430480957 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 84.89305114746094, Time 0.2371835708618164, Overall 0.2385694980621338 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 97.50737762451172, Time 0.24518418312072754, Overall 0.24657106399536133 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 32.50245920817057, Time 0.24526667594909668, Overall 0.24665284156799316 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 208.03208923339844, Time 0.24985909461975098, Overall 0.25124573707580566 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 104.01604461669922, Time 0.24994397163391113, Overall 0.2513298988342285 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 125.17135620117188, Time 0.2578105926513672, Overall 0.2591972351074219 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 41.723785400390625, Time 0.25789546966552734, Overall 0.2592813968658447 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 221.89404296875, Time 0.26407623291015625, Overall 0.26546406745910645 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 110.947021484375, Time 0.26418375968933105, Overall 0.26557040214538574 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 191.80320739746094, Time 0.01056814193725586, Overall 0.28041791915893555 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 63.93440246582031, Time 0.010655879974365234, Overall 0.2805047035217285 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 157.88970947265625, Time 0.015403985977172852, Overall 0.28525352478027344 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 78.94485473632812, Time 0.015492677688598633, Overall 0.2853415012359619 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 224.49916076660156, Time 0.023557662963867188, Overall 0.2934072017669678 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 74.83305358886719, Time 0.023644208908081055, Overall 0.29349327087402344 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 166.262939453125, Time 0.028184175491333008, Overall 0.2980337142944336 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 83.1314697265625, Time 0.028293609619140625, Overall 0.298142671585083 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 183.52755737304688, Time 0.036757707595825195, Overall 0.3066074848175049 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 61.17585245768229, Time 0.03684091567993164, Overall 0.3066897392272949 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 73.18004608154297, Time 0.04157376289367676, Overall 0.31142330169677734 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 36.590023040771484, Time 0.04166150093078613, Overall 0.3115103244781494 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 176.6120147705078, Time 0.049536943435668945, Overall 0.31938672065734863 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 58.87067159016927, Time 0.049620866775512695, Overall 0.3194699287414551 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 160.71755981445312, Time 0.054083824157714844, Overall 0.32393336296081543 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 80.35877990722656, Time 0.054167747497558594, Overall 0.3240163326263428 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 135.58554077148438, Time 0.06200718879699707, Overall 0.33185672760009766 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 45.19518025716146, Time 0.06209754943847656, Overall 0.33194661140441895 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 86.30998229980469, Time 0.06653523445129395, Overall 0.33638429641723633 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 43.154991149902344, Time 0.06662416458129883, Overall 0.3364732265472412 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 206.01968383789062, Time 0.07464480400085449, Overall 0.344494104385376 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 68.67322794596355, Time 0.07473039627075195, Overall 0.34457945823669434 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 126.5046615600586, Time 0.07927322387695312, Overall 0.3491227626800537 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 63.2523307800293, Time 0.07935929298400879, Overall 0.34920811653137207 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 122.04036712646484, Time 0.08725786209106445, Overall 0.35710740089416504 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 40.68012237548828, Time 0.08733892440795898, Overall 0.35718798637390137 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 119.27583312988281, Time 0.09244704246520996, Overall 0.36229729652404785 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 59.637916564941406, Time 0.09253811836242676, Overall 0.36238718032836914 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 111.05253601074219, Time 0.10132837295532227, Overall 0.37117815017700195 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 37.01751200358073, Time 0.10140848159790039, Overall 0.37125730514526367 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 155.16494750976562, Time 0.10585546493530273, Overall 0.3757050037384033 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 77.58247375488281, Time 0.10594582557678223, Overall 0.3757946491241455 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 124.92613220214844, Time 0.11402416229248047, Overall 0.38387393951416016 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 41.64204406738281, Time 0.11411547660827637, Overall 0.38396453857421875 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 215.34762573242188, Time 0.11862945556640625, Overall 0.38847875595092773 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 107.67381286621094, Time 0.11871623992919922, Overall 0.3885653018951416 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 141.239013671875, Time 0.12677907943725586, Overall 0.39662885665893555 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 47.079671223958336, Time 0.1268634796142578, Overall 0.3967125415802002 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 111.20625305175781, Time 0.13137388229370117, Overall 0.40122318267822266 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 55.603126525878906, Time 0.13145899772644043, Overall 0.4013080596923828 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 125.02149963378906, Time 0.1394493579864502, Overall 0.4092986583709717 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 41.67383321126302, Time 0.13953280448913574, Overall 0.4093818664550781 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 169.03916931152344, Time 0.1440107822418213, Overall 0.4138600826263428 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 84.51958465576172, Time 0.1441054344177246, Overall 0.4139542579650879 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 69.76956176757812, Time 0.15198373794555664, Overall 0.4218332767486572 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 23.256520589192707, Time 0.15207219123840332, Overall 0.4219212532043457 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 111.99064636230469, Time 0.15800189971923828, Overall 0.4278526306152344 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 55.995323181152344, Time 0.15812039375305176, Overall 0.42797040939331055 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 111.181396484375, Time 0.16604375839233398, Overall 0.43589353561401367 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 37.060465494791664, Time 0.1661367416381836, Overall 0.4359855651855469 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 179.35977172851562, Time 0.17060351371765137, Overall 0.44045329093933105 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 89.67988586425781, Time 0.17069005966186523, Overall 0.4405388832092285 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 100.52783966064453, Time 0.17863225936889648, Overall 0.44848155975341797 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 33.50927988688151, Time 0.17871785163879395, Overall 0.44856691360473633 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 144.32284545898438, Time 0.18315434455871582, Overall 0.4530036449432373 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 72.16142272949219, Time 0.1832578182220459, Overall 0.4531064033508301 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 141.27816772460938, Time 0.19116735458374023, Overall 0.4610168933868408 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 47.09272257486979, Time 0.19126367568969727, Overall 0.46111249923706055 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 135.0758056640625, Time 0.1961350440979004, Overall 0.4659848213195801 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 67.53790283203125, Time 0.19623899459838867, Overall 0.46608805656433105 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 102.73765563964844, Time 0.20461392402648926, Overall 0.47446370124816895 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 34.24588521321615, Time 0.20470452308654785, Overall 0.47455334663391113 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 102.89509582519531, Time 0.209228515625, Overall 0.4790782928466797 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 51.447547912597656, Time 0.20931577682495117, Overall 0.47916483879089355 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 40.0707893371582, Time 0.2173161506652832, Overall 0.4871656894683838 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 13.356929779052734, Time 0.21739935874938965, Overall 0.48724818229675293 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 97.90495300292969, Time 0.2219247817993164, Overall 0.491774320602417 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 48.952476501464844, Time 0.22201871871948242, Overall 0.4918680191040039 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 111.7119140625, Time 0.23013758659362793, Overall 0.4999873638153076 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 37.2373046875, Time 0.23025846481323242, Overall 0.5001075267791748 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 184.9722442626953, Time 0.23493409156799316, Overall 0.5047836303710938 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 92.48612213134766, Time 0.23502826690673828, Overall 0.5048768520355225 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 83.71971893310547, Time 0.24335145950317383, Overall 0.5132014751434326 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 27.906572977701824, Time 0.2434406280517578, Overall 0.5132894515991211 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 183.54420471191406, Time 0.24811911582946777, Overall 0.5179684162139893 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 91.77210235595703, Time 0.2482316493988037, Overall 0.518080472946167 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 121.26172637939453, Time 0.2566208839416504, Overall 0.526470422744751 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 40.42057545979818, Time 0.25670719146728516, Overall 0.5265562534332275 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 188.73724365234375, Time 0.26144862174987793, Overall 0.5312981605529785 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 94.36862182617188, Time 0.2615523338317871, Overall 0.5314013957977295 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 342.1708679199219, Time 0.0075740814208984375, Overall 0.5418665409088135 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 85.54271697998047, Time 0.00767207145690918, Overall 0.5419631004333496 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 70.71479034423828, Time 0.012093544006347656, Overall 0.5463852882385254 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 70.71479034423828, Time 0.012198686599731445, Overall 0.5464897155761719 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 253.0639190673828, Time 0.020786762237548828, Overall 0.5550796985626221 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 63.2659797668457, Time 0.020891189575195312, Overall 0.5551824569702148 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 100.64994049072266, Time 0.02527618408203125, Overall 0.559567928314209 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 100.64994049072266, Time 0.02537846565246582, Overall 0.5596692562103271 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 230.55616760253906, Time 0.0365605354309082, Overall 0.5708532333374023 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 57.639041900634766, Time 0.03666567802429199, Overall 0.5709571838378906 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 92.85443115234375, Time 0.04343891143798828, Overall 0.5777316093444824 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 92.85443115234375, Time 0.04354548454284668, Overall 0.5778372287750244 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 240.92034912109375, Time 0.05615711212158203, Overall 0.5904498100280762 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 60.23008728027344, Time 0.05625772476196289, Overall 0.5905489921569824 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 98.10147857666016, Time 0.06084942817687988, Overall 0.5951414108276367 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 98.10147857666016, Time 0.060950279235839844, Overall 0.5952413082122803 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 231.92315673828125, Time 0.06952118873596191, Overall 0.6038131713867188 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 57.98078918457031, Time 0.06961822509765625, Overall 0.6039092540740967 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 69.79515075683594, Time 0.0741875171661377, Overall 0.6084792613983154 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 69.79515075683594, Time 0.07426571846008301, Overall 0.6085565090179443 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 171.85232543945312, Time 0.08317923545837402, Overall 0.6174709796905518 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 42.96308135986328, Time 0.08328723907470703, Overall 0.6175782680511475 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 95.57527923583984, Time 0.08777761459350586, Overall 0.6220693588256836 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 95.57527923583984, Time 0.08787703514099121, Overall 0.6221678256988525 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 185.23826599121094, Time 0.09657669067382812, Overall 0.6308684349060059 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 46.309566497802734, Time 0.09667515754699707, Overall 0.6309661865234375 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 89.84111022949219, Time 0.1011054515838623, Overall 0.63539719581604 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 89.84111022949219, Time 0.10120415687561035, Overall 0.6354949474334717 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 118.62872314453125, Time 0.10967779159545898, Overall 0.6439692974090576 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 29.657180786132812, Time 0.10978269577026367, Overall 0.6440744400024414 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 83.56624603271484, Time 0.11414694786071777, Overall 0.6484382152557373 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 83.56624603271484, Time 0.1142425537109375, Overall 0.6485335826873779 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 145.08612060546875, Time 0.1227104663848877, Overall 0.6570019721984863 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 36.27153015136719, Time 0.12282133102416992, Overall 0.6571128368377686 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 65.85070037841797, Time 0.12715601921081543, Overall 0.6614475250244141 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 65.85070037841797, Time 0.12725090980529785, Overall 0.6615417003631592 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 174.36474609375, Time 0.13650226593017578, Overall 0.6707940101623535 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 43.5911865234375, Time 0.13659071922302246, Overall 0.6708812713623047 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 60.84980392456055, Time 0.14091205596923828, Overall 0.6752033233642578 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 60.84980392456055, Time 0.14100384712219238, Overall 0.6752948760986328 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 83.6169662475586, Time 0.1515483856201172, Overall 0.6858398914337158 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 20.90424156188965, Time 0.15162348747253418, Overall 0.6859142780303955 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 76.42691040039062, Time 0.15590119361877441, Overall 0.690192699432373 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 76.42691040039062, Time 0.15598440170288086, Overall 0.6902751922607422 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 139.4669952392578, Time 0.1665809154510498, Overall 0.7008733749389648 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 34.86674880981445, Time 0.16667604446411133, Overall 0.7009677886962891 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 97.53953552246094, Time 0.17135834693908691, Overall 0.7056496143341064 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 97.53953552246094, Time 0.17143726348876953, Overall 0.7057280540466309 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 118.6475830078125, Time 0.17965149879455566, Overall 0.7139427661895752 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 29.661895751953125, Time 0.17972016334533691, Overall 0.7140107154846191 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 132.29519653320312, Time 0.18391823768615723, Overall 0.7182092666625977 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 132.29519653320312, Time 0.18399310111999512, Overall 0.7182838916778564 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 133.2755126953125, Time 0.19230318069458008, Overall 0.7265949249267578 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 33.318878173828125, Time 0.19237828254699707, Overall 0.7266688346862793 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 111.74742889404297, Time 0.19657301902770996, Overall 0.7308647632598877 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 111.74742889404297, Time 0.19664883613586426, Overall 0.7309393882751465 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 123.55662536621094, Time 0.20490097999572754, Overall 0.7391924858093262 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 30.889156341552734, Time 0.20497703552246094, Overall 0.7392675876617432 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 61.79773712158203, Time 0.2093207836151123, Overall 0.7436120510101318 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 61.79773712158203, Time 0.20940136909484863, Overall 0.7436923980712891 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 125.20948028564453, Time 0.21773767471313477, Overall 0.7520289421081543 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 31.302370071411133, Time 0.21784067153930664, Overall 0.752131462097168 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 83.2917251586914, Time 0.2221050262451172, Overall 0.7563965320587158 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 83.2917251586914, Time 0.22218871116638184, Overall 0.7564792633056641 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 85.35384368896484, Time 0.2305457592010498, Overall 0.7648375034332275 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 21.33846092224121, Time 0.23062682151794434, Overall 0.7649178504943848 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 111.56222534179688, Time 0.23551297187805176, Overall 0.7698049545288086 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 111.56222534179688, Time 0.23560285568237305, Overall 0.7698934078216553 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 125.2991714477539, Time 0.24751853942871094, Overall 0.7818119525909424 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 31.324792861938477, Time 0.24763154983520508, Overall 0.7819230556488037 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 125.3450927734375, Time 0.25508570671081543, Overall 0.7893786430358887 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 125.3450927734375, Time 0.25522947311401367, Overall 0.7895214557647705 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 83.94950103759766, Time 0.26452207565307617, Overall 0.7988142967224121 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 20.987375259399414, Time 0.26460838317871094, Overall 0.7988989353179932 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 76.9488296508789, Time 0.26911091804504395, Overall 0.8034026622772217 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 76.9488296508789, Time 0.26920413970947266, Overall 0.803494930267334 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 111.50602722167969, Time 0.27797722816467285, Overall 0.8122692108154297 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 27.876506805419922, Time 0.278059720993042, Overall 0.8123505115509033 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 111.63041687011719, Time 0.28272533416748047, Overall 0.8170173168182373 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 111.63041687011719, Time 0.28284502029418945, Overall 0.817136287689209 \n",
            "It took 0.8189888000488281 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 8.487701416015625e-05 seconds to load from the pickles.\n",
            "It took 0.0003039836883544922 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:58,616 : INFO : loading Doc2Vec object from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "File not found! Learning skill.emb.d100.w1.dm1 embeddings from scratch ...\n",
            "Loading the skill documents pickle ...\n",
            "File not found! Generating skill documents ...\n",
            "#Documents with word type of skill have created: 6\n",
            "Saving the skill documents ...\n",
            "2022-03-04 05:28:58,620 : INFO : collecting all words and their counts\n",
            "2022-03-04 05:28:58,621 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2022-03-04 05:28:58,621 : INFO : collected 7 word types and 6 unique tags from a corpus of 6 examples and 10 words\n",
            "2022-03-04 05:28:58,621 : INFO : Loading a fresh vocabulary\n",
            "2022-03-04 05:28:58,621 : INFO : effective_min_count=0 retains 7 unique words (100% of original 7, drops 0)\n",
            "2022-03-04 05:28:58,621 : INFO : effective_min_count=0 leaves 10 word corpus (100% of original 10, drops 0)\n",
            "2022-03-04 05:28:58,621 : INFO : deleting the raw counts dictionary of 7 items\n",
            "2022-03-04 05:28:58,621 : INFO : sample=0.001 downsamples 7 most-common words\n",
            "2022-03-04 05:28:58,621 : INFO : downsampling leaves estimated 0 word corpus (8.7% of prior 10)\n",
            "2022-03-04 05:28:58,621 : INFO : estimated required memory for 7 words and 100 dimensions: 12700 bytes\n",
            "2022-03-04 05:28:58,621 : INFO : resetting layer weights\n",
            "  0% 0/10 [00:00<?, ?it/s]2022-03-04 05:28:58,624 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,626 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,626 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 9596 effective words/s\n",
            "2022-03-04 05:28:58,627 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,627 : INFO : EPOCH - 2 : training on 10 raw words (8 effective words) took 0.0s, 13766 effective words/s\n",
            "2022-03-04 05:28:58,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,628 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 11013 effective words/s\n",
            "2022-03-04 05:28:58,629 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,629 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 11950 effective words/s\n",
            "2022-03-04 05:28:58,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,630 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,630 : INFO : EPOCH - 5 : training on 10 raw words (8 effective words) took 0.0s, 15559 effective words/s\n",
            "2022-03-04 05:28:58,630 : INFO : training on a 50 raw words (34 effective words) took 0.0s, 5633 effective words/s\n",
            "2022-03-04 05:28:58,630 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,631 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,632 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,632 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11271 effective words/s\n",
            "2022-03-04 05:28:58,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,633 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 12623 effective words/s\n",
            "2022-03-04 05:28:58,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,634 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 12384 effective words/s\n",
            "2022-03-04 05:28:58,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,635 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 13594 effective words/s\n",
            "2022-03-04 05:28:58,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,636 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12051 effective words/s\n",
            "2022-03-04 05:28:58,636 : INFO : training on a 50 raw words (33 effective words) took 0.0s, 5704 effective words/s\n",
            "2022-03-04 05:28:58,636 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,637 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,638 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,638 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,638 : INFO : EPOCH - 1 : training on 10 raw words (7 effective words) took 0.0s, 12820 effective words/s\n",
            "2022-03-04 05:28:58,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,639 : INFO : EPOCH - 2 : training on 10 raw words (6 effective words) took 0.0s, 11130 effective words/s\n",
            "2022-03-04 05:28:58,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,640 : INFO : EPOCH - 3 : training on 10 raw words (9 effective words) took 0.0s, 15520 effective words/s\n",
            "2022-03-04 05:28:58,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,641 : INFO : EPOCH - 4 : training on 10 raw words (8 effective words) took 0.0s, 15198 effective words/s\n",
            "2022-03-04 05:28:58,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,642 : INFO : EPOCH - 5 : training on 10 raw words (8 effective words) took 0.0s, 15783 effective words/s\n",
            "2022-03-04 05:28:58,642 : INFO : training on a 50 raw words (38 effective words) took 0.0s, 6579 effective words/s\n",
            "2022-03-04 05:28:58,642 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,643 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,644 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,644 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,644 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11957 effective words/s\n",
            "2022-03-04 05:28:58,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,645 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,645 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 13043 effective words/s\n",
            "2022-03-04 05:28:58,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,646 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 11108 effective words/s\n",
            "2022-03-04 05:28:58,647 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,647 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 8668 effective words/s\n",
            "2022-03-04 05:28:58,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,648 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12028 effective words/s\n",
            "2022-03-04 05:28:58,648 : INFO : training on a 50 raw words (31 effective words) took 0.0s, 5297 effective words/s\n",
            "2022-03-04 05:28:58,649 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,649 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,650 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,650 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11375 effective words/s\n",
            "2022-03-04 05:28:58,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,651 : INFO : EPOCH - 2 : training on 10 raw words (8 effective words) took 0.0s, 14776 effective words/s\n",
            "2022-03-04 05:28:58,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,652 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,652 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 12341 effective words/s\n",
            "2022-03-04 05:28:58,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,653 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 13046 effective words/s\n",
            "2022-03-04 05:28:58,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,654 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,654 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12121 effective words/s\n",
            "2022-03-04 05:28:58,654 : INFO : training on a 50 raw words (34 effective words) took 0.0s, 5972 effective words/s\n",
            "2022-03-04 05:28:58,654 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,654 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,656 : INFO : EPOCH - 1 : training on 10 raw words (8 effective words) took 0.0s, 15625 effective words/s\n",
            "2022-03-04 05:28:58,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,657 : INFO : EPOCH - 2 : training on 10 raw words (8 effective words) took 0.0s, 13888 effective words/s\n",
            "2022-03-04 05:28:58,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,658 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 12938 effective words/s\n",
            "2022-03-04 05:28:58,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,659 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,659 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 10732 effective words/s\n",
            "2022-03-04 05:28:58,660 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,660 : INFO : EPOCH - 5 : training on 10 raw words (7 effective words) took 0.0s, 9963 effective words/s\n",
            "2022-03-04 05:28:58,660 : INFO : training on a 50 raw words (36 effective words) took 0.0s, 6031 effective words/s\n",
            "2022-03-04 05:28:58,661 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,661 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,662 : INFO : EPOCH - 1 : training on 10 raw words (7 effective words) took 0.0s, 12902 effective words/s\n",
            "2022-03-04 05:28:58,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,663 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 12692 effective words/s\n",
            "2022-03-04 05:28:58,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,664 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,664 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 8836 effective words/s\n",
            "2022-03-04 05:28:58,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,665 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 12102 effective words/s\n",
            "2022-03-04 05:28:58,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,666 : INFO : EPOCH - 5 : training on 10 raw words (7 effective words) took 0.0s, 13890 effective words/s\n",
            "2022-03-04 05:28:58,667 : INFO : training on a 50 raw words (33 effective words) took 0.0s, 5640 effective words/s\n",
            "2022-03-04 05:28:58,667 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,667 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,668 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11381 effective words/s\n",
            "2022-03-04 05:28:58,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,669 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 12754 effective words/s\n",
            "2022-03-04 05:28:58,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,670 : INFO : EPOCH - 3 : training on 10 raw words (9 effective words) took 0.0s, 12500 effective words/s\n",
            "2022-03-04 05:28:58,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,671 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 13420 effective words/s\n",
            "2022-03-04 05:28:58,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,673 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12625 effective words/s\n",
            "2022-03-04 05:28:58,673 : INFO : training on a 50 raw words (35 effective words) took 0.0s, 6018 effective words/s\n",
            "2022-03-04 05:28:58,673 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,673 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,674 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11898 effective words/s\n",
            "2022-03-04 05:28:58,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,675 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,675 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 13781 effective words/s\n",
            "2022-03-04 05:28:58,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,676 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 13054 effective words/s\n",
            "2022-03-04 05:28:58,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,677 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,677 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 7365 effective words/s\n",
            "2022-03-04 05:28:58,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,721 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 140 effective words/s\n",
            "2022-03-04 05:28:58,721 : INFO : training on a 50 raw words (32 effective words) took 0.0s, 660 effective words/s\n",
            "2022-03-04 05:28:58,721 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,722 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,724 : INFO : EPOCH - 1 : training on 10 raw words (8 effective words) took 0.0s, 11698 effective words/s\n",
            "2022-03-04 05:28:58,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,726 : INFO : EPOCH - 2 : training on 10 raw words (10 effective words) took 0.0s, 17240 effective words/s\n",
            "2022-03-04 05:28:58,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,727 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 7302 effective words/s\n",
            "2022-03-04 05:28:58,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,730 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,730 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 12894 effective words/s\n",
            "2022-03-04 05:28:58,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,732 : INFO : EPOCH - 5 : training on 10 raw words (8 effective words) took 0.0s, 13262 effective words/s\n",
            "2022-03-04 05:28:58,732 : INFO : training on a 50 raw words (39 effective words) took 0.0s, 3794 effective words/s\n",
            "2022-03-04 05:28:58,732 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100% 10/10 [00:00<00:00, 92.68it/s]\n",
            "Saving model for skill.emb.d100.w1.dm1 under directory ./../data/preprocessed/imdb/toy.title.basics.tsv ...\n",
            "2022-03-04 05:28:58,732 : INFO : saving Doc2Vec object under ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl, separately None\n",
            "2022-03-04 05:28:58,733 : INFO : saved ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 20.89476776123047, Time 0.002061128616333008, Overall 0.0032889842987060547 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 6.964922587076823, Time 0.0021347999572753906, Overall 0.0033617019653320312 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 15.67884349822998, Time 0.0029821395874023438, Overall 0.004209756851196289 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 7.83942174911499, Time 0.0030519962310791016, Overall 0.004278898239135742 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 16.935617446899414, Time 0.0053195953369140625, Overall 0.006548166275024414 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 5.645205815633138, Time 0.005401134490966797, Overall 0.006627798080444336 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 15.893596649169922, Time 0.006142139434814453, Overall 0.007369518280029297 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 7.946798324584961, Time 0.006207704544067383, Overall 0.0074346065521240234 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 11.834761619567871, Time 0.008309125900268555, Overall 0.0095367431640625 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 3.944920539855957, Time 0.008369922637939453, Overall 0.009596586227416992 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.236940383911133, Time 0.009076833724975586, Overall 0.010304450988769531 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 8.618470191955566, Time 0.009141206741333008, Overall 0.010368108749389648 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 6.85523796081543, Time 0.011214733123779297, Overall 0.012442350387573242 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 2.28507932027181, Time 0.011275291442871094, Overall 0.012502193450927734 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 16.59016227722168, Time 0.011975526809692383, Overall 0.013203620910644531 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 8.29508113861084, Time 0.012041568756103516, Overall 0.013268470764160156 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 7.202470302581787, Time 0.014084577560424805, Overall 0.015311956405639648 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.400823434193929, Time 0.014146089553833008, Overall 0.015372753143310547 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 18.503576278686523, Time 0.014856338500976562, Overall 0.01608419418334961 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 9.251788139343262, Time 0.014921188354492188, Overall 0.016147851943969727 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 15.47766399383545, Time 0.016865015029907227, Overall 0.01809239387512207 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 5.159221331278483, Time 0.016923904418945312, Overall 0.018150806427001953 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 22.997556686401367, Time 0.017645835876464844, Overall 0.018872976303100586 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 11.498778343200684, Time 0.017710447311401367, Overall 0.01893758773803711 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 7.586587905883789, Time 0.019732952117919922, Overall 0.02096104621887207 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 2.528862635294596, Time 0.019821643829345703, Overall 0.02104926109313965 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 27.344085693359375, Time 0.02057027816772461, Overall 0.021797895431518555 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 13.672042846679688, Time 0.020647764205932617, Overall 0.02187490463256836 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 11.254692077636719, Time 0.022660017013549805, Overall 0.02388787269592285 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 3.7515640258789062, Time 0.022736787796020508, Overall 0.02396416664123535 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 29.239416122436523, Time 0.02346205711364746, Overall 0.024689674377441406 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 14.619708061218262, Time 0.023540258407592773, Overall 0.024766921997070312 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 6.819766044616699, Time 0.025517940521240234, Overall 0.02674555778503418 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 2.2732553482055664, Time 0.025593042373657227, Overall 0.02682018280029297 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 38.22959899902344, Time 0.026326894760131836, Overall 0.02755451202392578 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 19.11479949951172, Time 0.026402711868286133, Overall 0.027629852294921875 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 11.993060111999512, Time 0.028311491012573242, Overall 0.029539108276367188 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 3.9976867039998374, Time 0.02838587760925293, Overall 0.029613018035888672 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 39.81480407714844, Time 0.02908921241760254, Overall 0.030316829681396484 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 19.90740203857422, Time 0.029165267944335938, Overall 0.030392169952392578 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 1.0248712301254272, Time 0.03110647201538086, Overall 0.032334089279174805 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 0.3416237433751424, Time 0.031183481216430664, Overall 0.03241086006164551 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 27.39421844482422, Time 0.03190946578979492, Overall 0.03313708305358887 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 13.69710922241211, Time 0.03198814392089844, Overall 0.03321480751037598 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 1.065588116645813, Time 0.033937692642211914, Overall 0.03516507148742676 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 0.3551960388819377, Time 0.034010887145996094, Overall 0.035237789154052734 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 35.0877685546875, Time 0.03474020957946777, Overall 0.035967350006103516 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 17.54388427734375, Time 0.03482675552368164, Overall 0.03605365753173828 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 7.7620849609375, Time 0.03687143325805664, Overall 0.03809857368469238 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 2.5873616536458335, Time 0.03694510459899902, Overall 0.038172006607055664 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 29.870519638061523, Time 0.037660837173461914, Overall 0.03888845443725586 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 14.935259819030762, Time 0.03773999214172363, Overall 0.03896665573120117 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 9.307663917541504, Time 0.0396878719329834, Overall 0.04091501235961914 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 3.1025546391805015, Time 0.039763450622558594, Overall 0.040990352630615234 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 33.38908386230469, Time 0.04052424430847168, Overall 0.04175162315368652 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 16.694541931152344, Time 0.04059910774230957, Overall 0.04182624816894531 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 16.438919067382812, Time 0.04256582260131836, Overall 0.0437929630279541 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 5.4796396891276045, Time 0.04263949394226074, Overall 0.043866872787475586 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 29.96393394470215, Time 0.04335975646972656, Overall 0.044586896896362305 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 14.981966972351074, Time 0.04343461990356445, Overall 0.044661521911621094 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 7.338017463684082, Time 0.04539966583251953, Overall 0.046627044677734375 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 2.4460058212280273, Time 0.045472145080566406, Overall 0.04669976234436035 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 40.022727966308594, Time 0.046175479888916016, Overall 0.04740285873413086 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 20.011363983154297, Time 0.046254634857177734, Overall 0.047481536865234375 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 1.5313664674758911, Time 0.0481867790222168, Overall 0.04941439628601074 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 0.5104554891586304, Time 0.0482635498046875, Overall 0.04949069023132324 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 36.87295150756836, Time 0.04898977279663086, Overall 0.050217390060424805 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 18.43647575378418, Time 0.04906964302062988, Overall 0.050296783447265625 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 0.3642873466014862, Time 0.05102133750915527, Overall 0.052248239517211914 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 0.12142911553382874, Time 0.051097869873046875, Overall 0.05232501029968262 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 36.68831253051758, Time 0.051824331283569336, Overall 0.05305194854736328 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 18.34415626525879, Time 0.051900625228881836, Overall 0.05312752723693848 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 11.25161075592041, Time 0.05396723747253418, Overall 0.055194854736328125 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 3.7505369186401367, Time 0.05404162406921387, Overall 0.055268287658691406 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 33.49126434326172, Time 0.05478692054748535, Overall 0.0560145378112793 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 16.74563217163086, Time 0.054871320724487305, Overall 0.056098222732543945 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 12.398804664611816, Time 0.056809186935424805, Overall 0.05803656578063965 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 4.1329348882039385, Time 0.05689239501953125, Overall 0.05811929702758789 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 35.37033462524414, Time 0.05761361122131348, Overall 0.05884075164794922 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 17.68516731262207, Time 0.05769228935241699, Overall 0.05891919136047363 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 22.583873748779297, Time 0.0015101432800292969, Overall 0.06236720085144043 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 7.527957916259766, Time 0.0017457008361816406, Overall 0.06258773803710938 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.683688163757324, Time 0.0025458335876464844, Overall 0.06338691711425781 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 7.341844081878662, Time 0.002634286880493164, Overall 0.06347465515136719 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 20.920425415039062, Time 0.004632711410522461, Overall 0.06547355651855469 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 6.9734751383463545, Time 0.004724979400634766, Overall 0.06556534767150879 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 15.167448043823242, Time 0.005422115325927734, Overall 0.06626296043395996 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 7.583724021911621, Time 0.0054972171783447266, Overall 0.06633710861206055 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 15.470659255981445, Time 0.007471561431884766, Overall 0.06831192970275879 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 5.1568864186604815, Time 0.007546663284301758, Overall 0.06838703155517578 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.41344451904297, Time 0.008264303207397461, Overall 0.06910490989685059 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 8.706722259521484, Time 0.008341073989868164, Overall 0.06918144226074219 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 12.0974760055542, Time 0.010243415832519531, Overall 0.07108426094055176 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 4.032492001851399, Time 0.010315656661987305, Overall 0.07115578651428223 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 15.773385047912598, Time 0.0110321044921875, Overall 0.07187294960021973 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 7.886692523956299, Time 0.011114120483398438, Overall 0.07195472717285156 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 7.61578369140625, Time 0.012991189956665039, Overall 0.07383179664611816 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 2.5385945638020835, Time 0.013065576553344727, Overall 0.07390594482421875 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 19.649751663208008, Time 0.013766288757324219, Overall 0.07460737228393555 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 9.824875831604004, Time 0.013839483261108398, Overall 0.07468008995056152 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 4.4168477058410645, Time 0.015747547149658203, Overall 0.07658815383911133 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.4722825686136882, Time 0.015820026397705078, Overall 0.07666015625 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 21.22811508178711, Time 0.01649761199951172, Overall 0.07733798027038574 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 10.614057540893555, Time 0.016573667526245117, Overall 0.07741379737854004 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 6.123331069946289, Time 0.018433332443237305, Overall 0.07927417755126953 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 2.041110356648763, Time 0.018507003784179688, Overall 0.07934737205505371 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 27.269987106323242, Time 0.019257068634033203, Overall 0.08009767532348633 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 13.634993553161621, Time 0.029869794845581055, Overall 0.0907125473022461 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 1.3229196071624756, Time 0.03348731994628906, Overall 0.0943291187286377 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 0.4409732023874919, Time 0.03358006477355957, Overall 0.0944209098815918 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 32.64762878417969, Time 0.03482627868652344, Overall 0.09566807746887207 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 16.323814392089844, Time 0.034920692443847656, Overall 0.09576153755187988 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 1.8833765983581543, Time 0.0379638671875, Overall 0.09880542755126953 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 0.6277921994527181, Time 0.03804373741149902, Overall 0.09888410568237305 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 36.68771743774414, Time 0.03919792175292969, Overall 0.10004878044128418 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 18.34385871887207, Time 0.039290666580200195, Overall 0.10013198852539062 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 1.0939708948135376, Time 0.04221320152282715, Overall 0.10305476188659668 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 0.3646569649378459, Time 0.04228949546813965, Overall 0.10313010215759277 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 34.89491653442383, Time 0.04323720932006836, Overall 0.10407876968383789 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 17.447458267211914, Time 0.04331564903259277, Overall 0.1041562557220459 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 3.513800859451294, Time 0.04604053497314453, Overall 0.10688185691833496 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 1.1712669531504314, Time 0.04611802101135254, Overall 0.10695886611938477 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 48.71968078613281, Time 0.04706263542175293, Overall 0.10790419578552246 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 24.359840393066406, Time 0.04714202880859375, Overall 0.10798311233520508 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 5.770809173583984, Time 0.04989123344421387, Overall 0.1107325553894043 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 1.9236030578613281, Time 0.049963951110839844, Overall 0.11080503463745117 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 53.82622528076172, Time 0.05089235305786133, Overall 0.11173391342163086 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 26.91311264038086, Time 0.050971269607543945, Overall 0.11181235313415527 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 19.72037124633789, Time 0.0537567138671875, Overall 0.11459827423095703 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 6.57345708211263, Time 0.0538330078125, Overall 0.11467361450195312 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 66.85899353027344, Time 0.05477404594421387, Overall 0.1156156063079834 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 33.42949676513672, Time 0.05484914779663086, Overall 0.11568999290466309 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 27.232532501220703, Time 0.05757284164428711, Overall 0.11841416358947754 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 9.077510833740234, Time 0.0576481819152832, Overall 0.11848902702331543 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 57.6411018371582, Time 0.05856823921203613, Overall 0.11940956115722656 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 28.8205509185791, Time 0.05864739418029785, Overall 0.11948823928833008 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 21.036672592163086, Time 0.061331748962402344, Overall 0.12217330932617188 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 7.012224197387695, Time 0.06141090393066406, Overall 0.12225198745727539 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 57.419158935546875, Time 0.06234908103942871, Overall 0.12319064140319824 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 28.709579467773438, Time 0.06259799003601074, Overall 0.12343907356262207 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 9.536870002746582, Time 0.06531906127929688, Overall 0.1261608600616455 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 3.178956667582194, Time 0.06539678573608398, Overall 0.1262376308441162 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 59.75401306152344, Time 0.06634068489074707, Overall 0.1271822452545166 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 29.87700653076172, Time 0.06641936302185059, Overall 0.1272599697113037 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 12.584416389465332, Time 0.06905794143676758, Overall 0.129899263381958 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 4.19480546315511, Time 0.06913113594055176, Overall 0.12997126579284668 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 48.65335464477539, Time 0.06999945640563965, Overall 0.13084053993225098 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 24.326677322387695, Time 0.07007479667663574, Overall 0.13091516494750977 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 35.70063781738281, Time 0.07286524772644043, Overall 0.13370633125305176 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 11.900212605794271, Time 0.07294845581054688, Overall 0.1337893009185791 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 59.10893630981445, Time 0.07393813133239746, Overall 0.1347792148590088 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 29.554468154907227, Time 0.07404112815856934, Overall 0.13488197326660156 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 0.12711110711097717, Time 0.07701587677001953, Overall 0.13785719871520996 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 0.04237036903699239, Time 0.07710123062133789, Overall 0.13794159889221191 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 59.45218276977539, Time 0.078125, Overall 0.13896656036376953 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 29.726091384887695, Time 0.07821989059448242, Overall 0.13906097412109375 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 0.5067961812019348, Time 0.08120894432067871, Overall 0.14205074310302734 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 0.16893206040064493, Time 0.0812838077545166, Overall 0.14212369918823242 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 58.49680709838867, Time 0.08208203315734863, Overall 0.14292263984680176 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 29.248403549194336, Time 0.08215951919555664, Overall 0.14299941062927246 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 29.68310546875, Time 0.0016489028930664062, Overall 0.14674615859985352 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 7.4207763671875, Time 0.001725912094116211, Overall 0.1468219757080078 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 8.177983283996582, Time 0.002328157424926758, Overall 0.14742445945739746 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 8.177983283996582, Time 0.0024073123931884766, Overall 0.14750385284423828 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 27.368253707885742, Time 0.004532575607299805, Overall 0.1496288776397705 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 6.8420634269714355, Time 0.0046062469482421875, Overall 0.1497020721435547 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 8.26734733581543, Time 0.005201816558837891, Overall 0.1502981185913086 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 8.26734733581543, Time 0.005280256271362305, Overall 0.1503760814666748 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 19.435958862304688, Time 0.0073163509368896484, Overall 0.15241289138793945 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 4.858989715576172, Time 0.007391929626464844, Overall 0.15248775482177734 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 8.700787544250488, Time 0.008001327514648438, Overall 0.15309762954711914 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 8.700787544250488, Time 0.008078813552856445, Overall 0.15317440032958984 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 14.1765775680542, Time 0.010095357894897461, Overall 0.15519142150878906 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 3.54414439201355, Time 0.010173559188842773, Overall 0.15526962280273438 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 9.42677116394043, Time 0.01077127456665039, Overall 0.1558678150177002 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 9.42677116394043, Time 0.010846853256225586, Overall 0.1559429168701172 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 14.108482360839844, Time 0.012883663177490234, Overall 0.15797972679138184 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 3.527120590209961, Time 0.012966156005859375, Overall 0.15806221961975098 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 7.344514846801758, Time 0.013582706451416016, Overall 0.15867924690246582 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 7.344514846801758, Time 0.013660192489624023, Overall 0.15875625610351562 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 9.944671630859375, Time 0.015685558319091797, Overall 0.1607820987701416 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 2.4861679077148438, Time 0.015758514404296875, Overall 0.16085433959960938 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 11.793458938598633, Time 0.01634383201599121, Overall 0.16144013404846191 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 11.793458938598633, Time 0.016437292098999023, Overall 0.16153335571289062 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 7.9289751052856445, Time 0.018417835235595703, Overall 0.1635303497314453 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.9822437763214111, Time 0.018504858016967773, Overall 0.16360092163085938 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 12.551904678344727, Time 0.01908707618713379, Overall 0.1641833782196045 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 12.551904678344727, Time 0.01916193962097168, Overall 0.16425776481628418 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 7.125901699066162, Time 0.021160125732421875, Overall 0.16625690460205078 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.7814754247665405, Time 0.021235227584838867, Overall 0.16633152961730957 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 14.289322853088379, Time 0.021825551986694336, Overall 0.16692161560058594 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 14.289322853088379, Time 0.02190232276916504, Overall 0.16699814796447754 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 7.452751636505127, Time 0.02408885955810547, Overall 0.16918540000915527 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.8631879091262817, Time 0.02416253089904785, Overall 0.16925811767578125 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 12.100137710571289, Time 0.024784564971923828, Overall 0.16988086700439453 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 12.100137710571289, Time 0.024860620498657227, Overall 0.16995620727539062 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 21.408519744873047, Time 0.02688431739807129, Overall 0.1719803810119629 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 5.352129936218262, Time 0.026965618133544922, Overall 0.17206144332885742 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 9.878581047058105, Time 0.027588605880737305, Overall 0.1726851463317871 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 9.878581047058105, Time 0.027663707733154297, Overall 0.1727597713470459 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 8.557249069213867, Time 0.029638290405273438, Overall 0.17473483085632324 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 2.139312267303467, Time 0.02971363067626953, Overall 0.17480993270874023 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 15.772207260131836, Time 0.030299901962280273, Overall 0.17539620399475098 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 15.772207260131836, Time 0.030378341674804688, Overall 0.1754746437072754 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 20.26165199279785, Time 0.03237462043762207, Overall 0.17747092247009277 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 5.065412998199463, Time 0.03246569633483887, Overall 0.17756152153015137 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 17.312129974365234, Time 0.03305315971374512, Overall 0.17814946174621582 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 17.312129974365234, Time 0.03313136100769043, Overall 0.17822718620300293 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 0.6246523857116699, Time 0.03507113456726074, Overall 0.18016719818115234 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.15616309642791748, Time 0.03514385223388672, Overall 0.18023920059204102 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 16.662796020507812, Time 0.03575730323791504, Overall 0.18085360527038574 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 16.662796020507812, Time 0.035837650299072266, Overall 0.18093347549438477 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 16.27337074279785, Time 0.03783679008483887, Overall 0.18293309211730957 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 4.068342685699463, Time 0.037912845611572266, Overall 0.18300914764404297 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 18.453947067260742, Time 0.03852081298828125, Overall 0.18361735343933105 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 18.453947067260742, Time 0.03859543800354004, Overall 0.18369150161743164 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 17.39864158630371, Time 0.040613651275634766, Overall 0.18570995330810547 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 4.349660396575928, Time 0.04068875312805176, Overall 0.18578481674194336 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 11.397185325622559, Time 0.04127860069274902, Overall 0.18637490272521973 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 11.397185325622559, Time 0.041356563568115234, Overall 0.18645238876342773 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 16.983680725097656, Time 0.04331064224243164, Overall 0.18840694427490234 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 4.245920181274414, Time 0.043387413024902344, Overall 0.18848323822021484 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.353394508361816, Time 0.0439915657043457, Overall 0.1890876293182373 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 15.353394508361816, Time 0.044066667556762695, Overall 0.1891629695892334 \n",
            "Epoch    16: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 19.571727752685547, Time 0.04646873474121094, Overall 0.19156575202941895 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 4.892931938171387, Time 0.04653811454772949, Overall 0.1916344165802002 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 16.733802795410156, Time 0.04738140106201172, Overall 0.19247865676879883 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 16.733802795410156, Time 0.04749011993408203, Overall 0.19258713722229004 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 12.509761810302734, Time 0.04955339431762695, Overall 0.19464969635009766 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 3.1274404525756836, Time 0.049631357192993164, Overall 0.19472765922546387 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 16.245176315307617, Time 0.05024218559265137, Overall 0.19533872604370117 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 16.245176315307617, Time 0.05032157897949219, Overall 0.19541716575622559 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 10.59842586517334, Time 0.052324771881103516, Overall 0.19742131233215332 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 2.649606466293335, Time 0.052399635314941406, Overall 0.1974954605102539 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 14.011007308959961, Time 0.05301403999328613, Overall 0.19811010360717773 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 14.011007308959961, Time 0.05309104919433594, Overall 0.19818663597106934 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 10.42996883392334, Time 0.05519509315490723, Overall 0.20029115676879883 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 2.607492208480835, Time 0.05527186393737793, Overall 0.20036840438842773 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 13.532951354980469, Time 0.05587434768676758, Overall 0.20097041130065918 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 13.532951354980469, Time 0.05596041679382324, Overall 0.20105648040771484 \n",
            "It took 0.20196771621704102 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 8.392333984375e-05 seconds to load from the pickles.\n",
            "It took 0.0002994537353515625 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:59,722 : INFO : loading Doc2Vec object from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "2022-03-04 05:28:59,722 : INFO : loading vocabulary recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.vocabulary.* with mmap=None\n",
            "2022-03-04 05:28:59,722 : INFO : loading trainables recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.trainables.* with mmap=None\n",
            "2022-03-04 05:28:59,723 : INFO : loading wv recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.wv.* with mmap=None\n",
            "2022-03-04 05:28:59,723 : INFO : loading docvecs recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.docvecs.* with mmap=None\n",
            "2022-03-04 05:28:59,723 : INFO : loaded ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 177.44537353515625, Time 0.011749744415283203, Overall 0.013112783432006836 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 59.148457845052086, Time 0.011878013610839844, Overall 0.013239860534667969 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 104.9969253540039, Time 0.020729780197143555, Overall 0.022092103958129883 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 52.49846267700195, Time 0.020830392837524414, Overall 0.022191286087036133 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 116.69597625732422, Time 0.029870271682739258, Overall 0.031232118606567383 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 38.898658752441406, Time 0.029957294464111328, Overall 0.03131818771362305 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 106.08340454101562, Time 0.035085201263427734, Overall 0.03644728660583496 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 53.04170227050781, Time 0.03517723083496094, Overall 0.036538124084472656 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 142.20498657226562, Time 0.043784141540527344, Overall 0.04514622688293457 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 47.40166219075521, Time 0.0438687801361084, Overall 0.04522991180419922 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 81.33821868896484, Time 0.04893803596496582, Overall 0.050299882888793945 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 40.66910934448242, Time 0.04903459548950195, Overall 0.05039572715759277 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 137.81874084472656, Time 0.05742359161376953, Overall 0.05878496170043945 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 45.93958028157552, Time 0.057505130767822266, Overall 0.05886697769165039 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 112.0657958984375, Time 0.06216621398925781, Overall 0.06352758407592773 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 56.03289794921875, Time 0.06225252151489258, Overall 0.0636134147644043 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 107.39189910888672, Time 0.07061219215393066, Overall 0.07197380065917969 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 35.79729970296224, Time 0.07068920135498047, Overall 0.07205009460449219 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 88.29478454589844, Time 0.0753786563873291, Overall 0.07674002647399902 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 44.14739227294922, Time 0.07546830177307129, Overall 0.0768289566040039 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 94.01165008544922, Time 0.0838620662689209, Overall 0.08522367477416992 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 31.33721669514974, Time 0.08395218849182129, Overall 0.08531332015991211 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 144.73338317871094, Time 0.08872008323669434, Overall 0.09008169174194336 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 72.36669158935547, Time 0.08881068229675293, Overall 0.09017157554626465 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 153.01698303222656, Time 0.09780454635620117, Overall 0.0991661548614502 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 51.00566101074219, Time 0.09790921211242676, Overall 0.09927010536193848 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 193.7552947998047, Time 0.1033484935760498, Overall 0.10471105575561523 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 96.87764739990234, Time 0.10346484184265137, Overall 0.10482621192932129 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 87.720703125, Time 0.11575722694396973, Overall 0.11712026596069336 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 29.240234375, Time 0.11585712432861328, Overall 0.1172177791595459 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 120.17443084716797, Time 0.12088561058044434, Overall 0.12224745750427246 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 60.087215423583984, Time 0.12098193168640137, Overall 0.12234306335449219 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 25.979341506958008, Time 0.1298673152923584, Overall 0.13123726844787598 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 8.659780502319336, Time 0.12996768951416016, Overall 0.13132882118225098 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 179.7688751220703, Time 0.1348865032196045, Overall 0.13624835014343262 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 89.88443756103516, Time 0.13498258590698242, Overall 0.13634371757507324 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 74.29985046386719, Time 0.14371132850646973, Overall 0.14507317543029785 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 24.766616821289062, Time 0.14380121231079102, Overall 0.14516234397888184 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 147.40487670898438, Time 0.1488628387451172, Overall 0.1502244472503662 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 73.70243835449219, Time 0.14896464347839355, Overall 0.15032577514648438 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 42.73161697387695, Time 0.1577739715576172, Overall 0.1591355800628662 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 14.24387232462565, Time 0.15786194801330566, Overall 0.15922331809997559 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 183.22549438476562, Time 0.16309642791748047, Overall 0.1644585132598877 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 91.61274719238281, Time 0.1631927490234375, Overall 0.16455388069152832 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 29.381481170654297, Time 0.17173504829406738, Overall 0.1730971336364746 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 9.793827056884766, Time 0.17182183265686035, Overall 0.17318272590637207 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 184.6741943359375, Time 0.17658591270446777, Overall 0.1779472827911377 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 92.33709716796875, Time 0.17667031288146973, Overall 0.17803144454956055 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 30.559093475341797, Time 0.1850452423095703, Overall 0.18640685081481934 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 10.1863644917806, Time 0.18513774871826172, Overall 0.18649888038635254 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 220.49916076660156, Time 0.18985724449157715, Overall 0.19121861457824707 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 110.24958038330078, Time 0.1899425983428955, Overall 0.19130349159240723 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 48.30070114135742, Time 0.19870853424072266, Overall 0.20007085800170898 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 16.10023371378581, Time 0.19879770278930664, Overall 0.20015883445739746 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 184.85479736328125, Time 0.20366740226745605, Overall 0.20502877235412598 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 92.42739868164062, Time 0.20375680923461914, Overall 0.20511770248413086 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 56.572113037109375, Time 0.21291589736938477, Overall 0.2142772674560547 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 18.857371012369793, Time 0.2129981517791748, Overall 0.21435880661010742 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 168.908935546875, Time 0.21773195266723633, Overall 0.21909356117248535 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 84.4544677734375, Time 0.2178189754486084, Overall 0.21918010711669922 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 60.33464431762695, Time 0.2263014316558838, Overall 0.2276628017425537 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 20.111548105875652, Time 0.22639250755310059, Overall 0.2277534008026123 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 150.388427734375, Time 0.2312605381011963, Overall 0.23262238502502441 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 75.1942138671875, Time 0.23135805130004883, Overall 0.23273372650146484 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 33.725685119628906, Time 0.23995637893676758, Overall 0.2413179874420166 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 11.241895039876303, Time 0.24004459381103516, Overall 0.24140596389770508 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 186.1919708251953, Time 0.2448256015777588, Overall 0.2461869716644287 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 93.09598541259766, Time 0.2449204921722412, Overall 0.24628114700317383 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 84.26667785644531, Time 0.2566952705383301, Overall 0.2580573558807373 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 28.088892618815105, Time 0.2567896842956543, Overall 0.2581510543823242 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 167.1018829345703, Time 0.2643861770629883, Overall 0.2657489776611328 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 83.55094146728516, Time 0.26450014114379883, Overall 0.26586174964904785 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 67.44584655761719, Time 0.27431249618530273, Overall 0.27567410469055176 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 22.481948852539062, Time 0.274397611618042, Overall 0.2757585048675537 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 226.41604614257812, Time 0.279371976852417, Overall 0.2807333469390869 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 113.20802307128906, Time 0.2794632911682129, Overall 0.2808244228363037 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 56.681732177734375, Time 0.28797364234924316, Overall 0.2893350124359131 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 18.893910725911457, Time 0.2880728244781494, Overall 0.28943419456481934 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 193.0804901123047, Time 0.2933981418609619, Overall 0.29476046562194824 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 96.54024505615234, Time 0.29352283477783203, Overall 0.2948949337005615 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 134.6439666748047, Time 0.007748603820800781, Overall 0.30573272705078125 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 44.8813222249349, Time 0.007847785949707031, Overall 0.3058319091796875 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 119.81596374511719, Time 0.013702154159545898, Overall 0.31168699264526367 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 59.907981872558594, Time 0.013804912567138672, Overall 0.31178903579711914 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 179.365478515625, Time 0.02835679054260254, Overall 0.3263416290283203 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 59.788492838541664, Time 0.02845144271850586, Overall 0.326434850692749 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 146.49461364746094, Time 0.03553462028503418, Overall 0.33351874351501465 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 73.24730682373047, Time 0.035640716552734375, Overall 0.33362412452697754 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 182.90762329101562, Time 0.044545650482177734, Overall 0.3425302505493164 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 60.969207763671875, Time 0.04463768005371094, Overall 0.3426210880279541 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 108.89891052246094, Time 0.04935097694396973, Overall 0.3473348617553711 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 54.44945526123047, Time 0.04943990707397461, Overall 0.3474233150482178 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 211.67120361328125, Time 0.05833792686462402, Overall 0.3563220500946045 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 70.55706787109375, Time 0.05843186378479004, Overall 0.3564152717590332 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 144.79859924316406, Time 0.06440401077270508, Overall 0.36238765716552734 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 72.39929962158203, Time 0.06449151039123535, Overall 0.3624746799468994 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 126.98641967773438, Time 0.07312512397766113, Overall 0.3711094856262207 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 42.32880655924479, Time 0.07321476936340332, Overall 0.3711977005004883 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 150.51803588867188, Time 0.07803225517272949, Overall 0.37601613998413086 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 75.25901794433594, Time 0.07812738418579102, Overall 0.3761107921600342 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 98.41445922851562, Time 0.0866246223449707, Overall 0.38460850715637207 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 32.80481974283854, Time 0.0867166519165039, Overall 0.38470005989074707 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 96.48518371582031, Time 0.0917813777923584, Overall 0.38976526260375977 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 48.242591857910156, Time 0.09192061424255371, Overall 0.3899040222167969 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 60.15469741821289, Time 0.1003568172454834, Overall 0.39834094047546387 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 20.051565806070965, Time 0.10044097900390625, Overall 0.3984243869781494 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 143.73614501953125, Time 0.10512328147888184, Overall 0.4031074047088623 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 71.86807250976562, Time 0.1052093505859375, Overall 0.40319299697875977 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 91.19586181640625, Time 0.11461019515991211, Overall 0.4125940799713135 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 30.39862060546875, Time 0.1146993637084961, Overall 0.41268253326416016 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 172.74203491210938, Time 0.11964035034179688, Overall 0.41762423515319824 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 86.37101745605469, Time 0.11973166465759277, Overall 0.41771483421325684 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 65.93112182617188, Time 0.12839531898498535, Overall 0.4263789653778076 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 21.977040608723957, Time 0.12848424911499023, Overall 0.4264676570892334 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 126.44061279296875, Time 0.13334321975708008, Overall 0.43132758140563965 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 63.220306396484375, Time 0.13343238830566406, Overall 0.4314157962799072 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 112.19284057617188, Time 0.14332890510559082, Overall 0.4413132667541504 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 37.397613525390625, Time 0.14346694946289062, Overall 0.4414513111114502 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 176.4554443359375, Time 0.14946937561035156, Overall 0.44745326042175293 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 88.22772216796875, Time 0.149566650390625, Overall 0.44755005836486816 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 89.25654602050781, Time 0.15837907791137695, Overall 0.4563636779785156 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 29.752182006835938, Time 0.15845966339111328, Overall 0.45644307136535645 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 134.22323608398438, Time 0.16327500343322754, Overall 0.461259126663208 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 67.11161804199219, Time 0.16336512565612793, Overall 0.461348295211792 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 47.97418975830078, Time 0.17189836502075195, Overall 0.4698824882507324 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 15.99139658610026, Time 0.17200851440429688, Overall 0.46999192237854004 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 154.2019500732422, Time 0.1769418716430664, Overall 0.47492527961730957 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 77.1009750366211, Time 0.17703652381896973, Overall 0.4750196933746338 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 70.27954864501953, Time 0.18562102317810059, Overall 0.48360514640808105 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 23.42651621500651, Time 0.18571019172668457, Overall 0.48369359970092773 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 201.6096954345703, Time 0.19057273864746094, Overall 0.4885568618774414 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 100.80484771728516, Time 0.19066834449768066, Overall 0.4886512756347656 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 60.53083419799805, Time 0.19928956031799316, Overall 0.49727368354797363 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 20.176944732666016, Time 0.19937539100646973, Overall 0.4973585605621338 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 191.0591583251953, Time 0.20429515838623047, Overall 0.5022788047790527 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 95.52957916259766, Time 0.20438265800476074, Overall 0.5023660659790039 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 42.816402435302734, Time 0.21306204795837402, Overall 0.5110471248626709 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 14.272134145100912, Time 0.21314787864685059, Overall 0.511131763458252 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 180.95375061035156, Time 0.21816706657409668, Overall 0.516150951385498 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 90.47687530517578, Time 0.21827220916748047, Overall 0.5162553787231445 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 42.84201431274414, Time 0.22690033912658691, Overall 0.5249021053314209 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 14.28067143758138, Time 0.22700929641723633, Overall 0.5249924659729004 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 180.3522186279297, Time 0.23192477226257324, Overall 0.5299086570739746 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 90.17610931396484, Time 0.23201823234558105, Overall 0.5300014019012451 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 73.51598358154297, Time 0.2405698299407959, Overall 0.5385537147521973 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 24.505327860514324, Time 0.24065470695495605, Overall 0.5386381149291992 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 156.46229553222656, Time 0.24542689323425293, Overall 0.5434107780456543 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 78.23114776611328, Time 0.2455143928527832, Overall 0.5434978008270264 \n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 70.57200622558594, Time 0.2540273666381836, Overall 0.5520110130310059 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 23.524002075195312, Time 0.2541072368621826, Overall 0.552091121673584 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 174.23965454101562, Time 0.2588791847229004, Overall 0.5568628311157227 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 87.11982727050781, Time 0.2589848041534424, Overall 0.5569684505462646 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 56.78665542602539, Time 0.2673652172088623, Overall 0.5653491020202637 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 18.928885142008465, Time 0.2674527168273926, Overall 0.5654358863830566 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 162.47628784179688, Time 0.2721850872039795, Overall 0.5701689720153809 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 81.23814392089844, Time 0.2722785472869873, Overall 0.5702614784240723 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 77.61183166503906, Time 0.28069543838500977, Overall 0.5786795616149902 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 25.87061055501302, Time 0.28078460693359375, Overall 0.5787689685821533 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 264.0872497558594, Time 0.28557252883911133, Overall 0.5835564136505127 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 132.0436248779297, Time 0.2856612205505371, Overall 0.5836443901062012 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 172.86056518554688, Time 0.007709503173828125, Overall 0.5943076610565186 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 43.21514129638672, Time 0.0077991485595703125, Overall 0.5943965911865234 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 61.495513916015625, Time 0.012599468231201172, Overall 0.5991973876953125 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 61.495513916015625, Time 0.0126953125, Overall 0.599292516708374 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 238.7032928466797, Time 0.021565914154052734, Overall 0.6081638336181641 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 59.67582321166992, Time 0.021657943725585938, Overall 0.60825514793396 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 56.358272552490234, Time 0.027092695236206055, Overall 0.6136915683746338 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 56.358272552490234, Time 0.027199506759643555, Overall 0.6137971878051758 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 164.607666015625, Time 0.04201769828796387, Overall 0.6286163330078125 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 41.15191650390625, Time 0.042128801345825195, Overall 0.6287269592285156 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 56.020172119140625, Time 0.04725456237792969, Overall 0.6338522434234619 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 56.020172119140625, Time 0.04735445976257324, Overall 0.6339516639709473 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 232.95985412597656, Time 0.056397438049316406, Overall 0.6429951190948486 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 58.23996353149414, Time 0.05648159980773926, Overall 0.6430785655975342 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 57.229835510253906, Time 0.061031341552734375, Overall 0.6476292610168457 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 57.229835510253906, Time 0.06112217903137207, Overall 0.647719144821167 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 153.38121032714844, Time 0.06999349594116211, Overall 0.6565914154052734 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 38.34530258178711, Time 0.07007479667663574, Overall 0.6566720008850098 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 74.46890258789062, Time 0.07467222213745117, Overall 0.6612699031829834 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 74.46890258789062, Time 0.07475519180297852, Overall 0.6613521575927734 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 150.65771484375, Time 0.08335018157958984, Overall 0.6699488162994385 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 37.6644287109375, Time 0.08343505859375, Overall 0.6700325012207031 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 56.64616775512695, Time 0.08795404434204102, Overall 0.6745519638061523 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 56.64616775512695, Time 0.088043212890625, Overall 0.6746406555175781 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 144.879150390625, Time 0.0966649055480957, Overall 0.6832630634307861 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 36.21978759765625, Time 0.09675216674804688, Overall 0.6833498477935791 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 75.64248657226562, Time 0.10123085975646973, Overall 0.687828779220581 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 75.64248657226562, Time 0.10133552551269531, Overall 0.6879332065582275 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 86.31511688232422, Time 0.1099545955657959, Overall 0.6965525150299072 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 21.578779220581055, Time 0.11004233360290527, Overall 0.6966400146484375 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 89.75019836425781, Time 0.11455035209655762, Overall 0.7011487483978271 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 89.75019836425781, Time 0.11465048789978027, Overall 0.7012476921081543 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 84.934326171875, Time 0.12347817420959473, Overall 0.710075855255127 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 21.23358154296875, Time 0.1235649585723877, Overall 0.7101619243621826 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 78.14482116699219, Time 0.12877392768859863, Overall 0.7153720855712891 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 78.14482116699219, Time 0.12886953353881836, Overall 0.7154667377471924 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 163.0548095703125, Time 0.13803434371948242, Overall 0.724632978439331 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 40.763702392578125, Time 0.1381361484527588, Overall 0.7247335910797119 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 128.84295654296875, Time 0.14391517639160156, Overall 0.7305145263671875 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 128.84295654296875, Time 0.1440131664276123, Overall 0.7306110858917236 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 81.20283508300781, Time 0.1533198356628418, Overall 0.739917516708374 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 20.300708770751953, Time 0.15339875221252441, Overall 0.7399961948394775 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 74.84832763671875, Time 0.1578834056854248, Overall 0.744481086730957 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 74.84832763671875, Time 0.15797066688537598, Overall 0.7445681095123291 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 77.09957885742188, Time 0.1666395664215088, Overall 0.7532377243041992 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 19.27489471435547, Time 0.16672706604003906, Overall 0.7533245086669922 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 71.31852722167969, Time 0.17195439338684082, Overall 0.7585532665252686 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 71.31852722167969, Time 0.17206048965454102, Overall 0.7586586475372314 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 119.45675659179688, Time 0.1818249225616455, Overall 0.7684226036071777 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 29.86418914794922, Time 0.1819162368774414, Overall 0.7685132026672363 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 87.80877685546875, Time 0.1865828037261963, Overall 0.7731807231903076 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 87.80877685546875, Time 0.18668341636657715, Overall 0.7732808589935303 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 94.174560546875, Time 0.1955738067626953, Overall 0.7821717262268066 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 23.54364013671875, Time 0.19567179679870605, Overall 0.7822697162628174 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 125.71942138671875, Time 0.20022797584533691, Overall 0.7868256568908691 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 125.71942138671875, Time 0.2003321647644043, Overall 0.7869293689727783 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 95.54637145996094, Time 0.20910954475402832, Overall 0.7957074642181396 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 23.886592864990234, Time 0.20919370651245117, Overall 0.7957911491394043 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 97.98548126220703, Time 0.21367573738098145, Overall 0.8002736568450928 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 97.98548126220703, Time 0.21376490592956543, Overall 0.8003625869750977 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 78.5185546875, Time 0.2225637435913086, Overall 0.8091614246368408 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 19.629638671875, Time 0.22265100479125977, Overall 0.8092482089996338 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 98.54474639892578, Time 0.22751355171203613, Overall 0.8141114711761475 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 98.54474639892578, Time 0.2276015281677246, Overall 0.8141987323760986 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 82.19507598876953, Time 0.23624110221862793, Overall 0.8228390216827393 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 20.548768997192383, Time 0.23633766174316406, Overall 0.8229351043701172 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 95.62377166748047, Time 0.24085712432861328, Overall 0.8274550437927246 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 95.62377166748047, Time 0.24094843864440918, Overall 0.8275458812713623 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 71.4222412109375, Time 0.24972891807556152, Overall 0.8363265991210938 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 17.855560302734375, Time 0.2498188018798828, Overall 0.8364160060882568 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 112.08317565917969, Time 0.25433778762817383, Overall 0.8409357070922852 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 112.08317565917969, Time 0.2544248104095459, Overall 0.8410220146179199 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 44.908870697021484, Time 0.26312732696533203, Overall 0.8497254848480225 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 11.227217674255371, Time 0.2632172107696533, Overall 0.8498144149780273 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 69.69280242919922, Time 0.267864465713501, Overall 0.8544621467590332 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 69.69280242919922, Time 0.26795387268066406, Overall 0.8545513153076172 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 84.4041976928711, Time 0.2767188549041748, Overall 0.8633167743682861 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 21.101049423217773, Time 0.2768058776855469, Overall 0.8634033203125 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 123.36332702636719, Time 0.28158140182495117, Overall 0.8681802749633789 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 123.36332702636719, Time 0.28169727325439453, Overall 0.8682947158813477 \n",
            "It took 0.8701348304748535 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark Output Folder on toy.dblp for Baselines**"
      ],
      "metadata": {
        "id": "-Q06TnofpXeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/toy.dblp.v12.json/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ion5hv6viDa2",
        "outputId": "1f781217-4f15-491a-99e9-73aa2c123414"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnn  bnn_emb  fnn  fnn_emb  random\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's look at the Bayesian (bnn) Results**\n",
        "\n",
        "```\n",
        "#team:31, #skills:11, #members:13\n",
        "layers:[100], learning rate:0.1, batch size:4096, epoch:20, \n",
        "#negative samples:2, negative sampling: unigram_b, elbo samples:1\n",
        "```"
      ],
      "metadata": {
        "id": "AMe6O86CpuPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5P-YCCFkAkg",
        "outputId": "44544bd3-b696-46db-b4f1-fdcb7d89e097"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.test.pred\t\t    state_dict_model.f1.e15.pt\n",
            "f0.test.pred.eval.mean.csv  state_dict_model.f1.e16.pt\n",
            "f0.test.pred.eval.roc.pkl   state_dict_model.f1.e17.pt\n",
            "f0.train_valid_loss.png     state_dict_model.f1.e18.pt\n",
            "f1.test.pred\t\t    state_dict_model.f1.e19.pt\n",
            "f1.test.pred.eval.mean.csv  state_dict_model.f1.e1.pt\n",
            "f1.test.pred.eval.roc.pkl   state_dict_model.f1.e2.pt\n",
            "f1.train_valid_loss.png     state_dict_model.f1.e3.pt\n",
            "f2.test.pred\t\t    state_dict_model.f1.e4.pt\n",
            "f2.test.pred.eval.mean.csv  state_dict_model.f1.e5.pt\n",
            "f2.test.pred.eval.roc.pkl   state_dict_model.f1.e6.pt\n",
            "f2.train_valid_loss.png     state_dict_model.f1.e7.pt\n",
            "state_dict_model.f0.e0.pt   state_dict_model.f1.e8.pt\n",
            "state_dict_model.f0.e10.pt  state_dict_model.f1.e9.pt\n",
            "state_dict_model.f0.e11.pt  state_dict_model_f1.pt\n",
            "state_dict_model.f0.e12.pt  state_dict_model.f2.e0.pt\n",
            "state_dict_model.f0.e13.pt  state_dict_model.f2.e10.pt\n",
            "state_dict_model.f0.e14.pt  state_dict_model.f2.e11.pt\n",
            "state_dict_model.f0.e15.pt  state_dict_model.f2.e12.pt\n",
            "state_dict_model.f0.e16.pt  state_dict_model.f2.e13.pt\n",
            "state_dict_model.f0.e17.pt  state_dict_model.f2.e14.pt\n",
            "state_dict_model.f0.e18.pt  state_dict_model.f2.e15.pt\n",
            "state_dict_model.f0.e19.pt  state_dict_model.f2.e16.pt\n",
            "state_dict_model.f0.e1.pt   state_dict_model.f2.e17.pt\n",
            "state_dict_model.f0.e2.pt   state_dict_model.f2.e18.pt\n",
            "state_dict_model.f0.e3.pt   state_dict_model.f2.e19.pt\n",
            "state_dict_model.f0.e4.pt   state_dict_model.f2.e1.pt\n",
            "state_dict_model.f0.e5.pt   state_dict_model.f2.e2.pt\n",
            "state_dict_model.f0.e6.pt   state_dict_model.f2.e3.pt\n",
            "state_dict_model.f0.e7.pt   state_dict_model.f2.e4.pt\n",
            "state_dict_model.f0.e8.pt   state_dict_model.f2.e5.pt\n",
            "state_dict_model.f0.e9.pt   state_dict_model.f2.e6.pt\n",
            "state_dict_model_f0.pt\t    state_dict_model.f2.e7.pt\n",
            "state_dict_model.f1.e0.pt   state_dict_model.f2.e8.pt\n",
            "state_dict_model.f1.e10.pt  state_dict_model.f2.e9.pt\n",
            "state_dict_model.f1.e11.pt  state_dict_model_f2.pt\n",
            "state_dict_model.f1.e12.pt  test.pred.eval.mean.csv\n",
            "state_dict_model.f1.e13.pt  test.roc.png\n",
            "state_dict_model.f1.e14.pt  train_valid_loss.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Plot for 3-Fold Cross-Validated Models on Test Set**"
      ],
      "metadata": {
        "id": "KhtwppXbrEEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1/test.roc.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-75NPqckkbGm",
        "outputId": "b543bb82-7a68-4bc9-a509-34efc1f5667e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1/test.pred.eval.mean.csv', index_col = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "bdooeMNexjjl",
        "outputId": "3e070546-d40e-4efa-ce94-5a85abaa08a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6833bc74-df16-45bd-9f0d-55d43cec74a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.233333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.072222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.388889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.877778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.077371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.253334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.464721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.036111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.143426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.279246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.631657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6833bc74-df16-45bd-9f0d-55d43cec74a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6833bc74-df16-45bd-9f0d-55d43cec74a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6833bc74-df16-45bd-9f0d-55d43cec74a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 mean\n",
              "P_2          0.100000\n",
              "P_5          0.200000\n",
              "P_10         0.233333\n",
              "recall_2     0.072222\n",
              "recall_5     0.388889\n",
              "recall_10    0.877778\n",
              "ndcg_cut_2   0.077371\n",
              "ndcg_cut_5   0.253334\n",
              "ndcg_cut_10  0.464721\n",
              "map_cut_2    0.036111\n",
              "map_cut_5    0.143426\n",
              "map_cut_10   0.279246\n",
              "aucroc       0.631657"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}
