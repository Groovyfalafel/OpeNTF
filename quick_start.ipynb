{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick_start.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Setup Python 3.8 on Colab Environment.**"
      ],
      "metadata": {
        "id": "hsO795wNk9WL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "yzuvvMImFFWg",
        "outputId": "168f6753-bfe2-4c99-ecae-b6eb8e3a4498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Wait\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [2 In\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [76.8 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [931 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,596 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,827 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,036 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,474 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [806 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [840 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,252 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [936 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 15.1 MB in 6s (2,460 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 75 not upgraded.\n",
            "Need to get 4,676 kB of archives.\n",
            "After this operation, 18.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-minimal amd64 3.8.12-1+bionic3 [762 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8-minimal amd64 3.8.12-1+bionic3 [1,825 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-stdlib amd64 3.8.12-1+bionic3 [1,656 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8 amd64 3.8.12-1+bionic3 [433 kB]\n",
            "Fetched 4,676 kB in 5s (1,035 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.8-minimal_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.12-1+bionic3) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../python3.8-minimal_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.12-1+bionic3) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.8-stdlib_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.12-1+bionic3) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../python3.8_3.8.12-1+bionic3_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.12-1+bionic3) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.12-1+bionic3) ...\n",
            "Setting up python3.8-minimal (3.8.12-1+bionic3) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.12-1+bionic3) ...\n",
            "Setting up python3.8 (3.8.12-1+bionic3) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.12\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 75 not upgraded.\n",
            "Need to get 2,882 kB of archives.\n",
            "After this operation, 8,886 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Fetched 2,882 kB in 2s (1,673 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 155939 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pip\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/df/a6ef77a6574781a668791419ffe366c8acd1c3cf4709d210cb53cd5ce1c2/pip-22.0.3-py3-none-any.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 588kB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 9.0.1\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "Successfully installed pip-22.0.3\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.9.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-8.1.1-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.3/750.3 KB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client<8.0\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado<7.0,>=4.2\n",
            "  Downloading tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.5/427.5 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy<2.0,>=1.0.0\n",
            "  Downloading debugpy-1.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\n",
            "Collecting matplotlib-inline<0.2.0,>=0.1.0\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Collecting traitlets<6.0,>=5.1.0\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.2.0-py3-none-any.whl (21 kB)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 KB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=7.23.1->ipykernel) (39.0.1)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=13\n",
            "  Downloading pyzmq-22.3.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel) (1.11.0)\n",
            "Collecting executing\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting asttokens\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, pickleshare, executing, backcall, traitlets, tornado, pyzmq, python-dateutil, pygments, prompt-toolkit, pexpect, parso, nest-asyncio, entrypoints, decorator, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-2.0.5 backcall-0.2.0 debugpy-1.5.1 decorator-5.1.1 entrypoints-0.4 executing-0.8.3 ipykernel-6.9.1 ipython-8.1.1 jedi-0.18.1 jupyter-client-7.1.2 jupyter-core-4.9.2 matplotlib-inline-0.1.3 nest-asyncio-1.5.4 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.28 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.11.2 python-dateutil-2.8.2 pyzmq-22.3.0 stack-data-0.2.0 tornado-6.1 traitlets-5.1.1 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "jupyter_core",
                  "pexpect",
                  "pickleshare",
                  "traitlets",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "!python --version\n",
        "!sudo apt-get install python3-pip\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing OpeNTF**"
      ],
      "metadata": {
        "id": "6tKkPogYlQxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -R opentf/\n",
        "!git clone https://github.com/fani-lab/opentf\n",
        "%cd opentf/\n",
        "!pip install -r requirements.txt\n",
        "%cd src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fwIEGOF9FT4U",
        "outputId": "71dacd03-0429-4f4a-e46f-b2c99c8ab301"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 3145, done.\u001b[K\n",
            "remote: Counting objects: 100% (3145/3145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2226/2226), done.\u001b[K\n",
            "remote: Total 3145 (delta 1373), reused 2473 (delta 876), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3145/3145), 34.58 MiB | 15.75 MiB/s, done.\n",
            "Resolving deltas: 100% (1373/1373), done.\n",
            "/content/opentf\n",
            "Collecting torch>=1.6.0\n",
            "  Downloading torch-1.10.2-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1102422016 bytes == 0x374e2000 @  0x7f3eb8210615 0x4f69ad 0x5aa051 0x5a9f83 0x5d290c 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd 0x556ea9 0x4fa54a 0x556ea9 0x555bc0 0x4fa5dd 0x557802 0x555bc0 0x4fa5dd 0x556ea9 0x555bc0 0x4fa5dd\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.60.0\n",
            "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==5.4\n",
            "  Downloading PyYAML-5.4-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.2/662.2 KB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.3\n",
            "  Downloading pandas-1.3.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytrec-eval-terrier==0.5.2\n",
            "  Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.4.2\n",
            "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.3->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim==3.8.3->-r requirements.txt (line 8)) (1.11.0)\n",
            "Collecting smart-open>=1.8.1\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pytz, typing-extensions, tqdm, threadpoolctl, smart-open, PyYAML, pytrec-eval-terrier, pyparsing, pillow, numpy, kiwisolver, joblib, cycler, torch, scipy, pandas, matplotlib, scikit_learn, gensim\n",
            "Successfully installed PyYAML-5.4 cycler-0.11.0 gensim-3.8.3 joblib-1.1.0 kiwisolver-1.3.2 matplotlib-3.4.2 numpy-1.20.3 pandas-1.3.3 pillow-9.0.1 pyparsing-3.0.7 pytrec-eval-terrier-0.5.2 pytz-2021.3 scikit_learn-0.24.2 scipy-1.6.3 smart-open-5.2.1 threadpoolctl-3.1.0 torch-1.10.2 tqdm-4.60.0 typing-extensions-4.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "kiwisolver",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/opentf/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Default Hyperparameters**"
      ],
      "metadata": {
        "id": "a4G4Omoolyvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat param.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG0nCDddl5w6",
        "outputId": "c0142145-b4c7-473c-8050-48e93da28bf3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import random\n",
            "import torch\n",
            "import numpy as np\n",
            "\n",
            "random.seed(0)\n",
            "torch.manual_seed(0)\n",
            "torch.cuda.manual_seed_all(0)\n",
            "\n",
            "np.random.seed(0)\n",
            "\n",
            "settings = {\n",
            "    'model':{\n",
            "        'baseline': {\n",
            "            'random': {\n",
            "                'b': 4096\n",
            "            },\n",
            "            'fnn':{\n",
            "                'l': [100],  # list of number of nodes in each layer\n",
            "                'lr': 0.1,  # learning rate\n",
            "                'b': 4096,  # batch size\n",
            "                'e': 20,  # epoch\n",
            "                'nns': None,  # number of negative samples\n",
            "                'ns': None,  # 'uniform', 'unigram', 'unigram_b'\n",
            "            },\n",
            "            'bnn':{\n",
            "                'l': [100],  # list of number of nodes in each layer\n",
            "                'lr': 0.1,  # learning rate\n",
            "                'b': 4096,  # batch size\n",
            "                'e': 20,  # epoch\n",
            "                'nns': None,  # number of negative samples\n",
            "                'ns': None,  # 'uniform', 'unigram', 'unigram_b'\n",
            "                's': 1  # # sample_elbo for bnn\n",
            "            },\n",
            "            'emb':{\n",
            "                'd': 100,# embedding dimension\n",
            "                'e': 100,# epoch\n",
            "                'dm': 1,# training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)\n",
            "                'w': 1 #cooccurrence window\n",
            "            }\n",
            "        },\n",
            "        'cmd': ['train', 'test', 'eval', 'plot'],  # 'train', 'test', 'eval'\n",
            "        'nfolds': 3,\n",
            "        'train_test_split': 0.85\n",
            "    },\n",
            "    'data':{\n",
            "        'domain': {\n",
            "            'dblp':{},\n",
            "            'uspt':{},\n",
            "            'imdb':{},\n",
            "        },\n",
            "        'filter': {\n",
            "            'min_nteam': 75,\n",
            "            'min_team_size': 3,\n",
            "        },\n",
            "        'parallel': 1,\n",
            "        'ncore': 0,# <= 0 for all\n",
            "        'bucket_size': 500\n",
            "    },\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chane a Hyperparameter, e.g., Negative Sampling Heuristics**\n",
        "```\n",
        "settings['model']['baseline']['fnn']['ns'] = 'uniform'\n",
        "settings['model']['baseline']['fnn']['nns'] = 1\n",
        "settings['model']['baseline']['bnn']['ns'] = 'unigram_b'\n",
        "settings['model']['baseline']['bnn']['nns'] = 2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DbBMkT-2GUyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile param.py \n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "settings = {\n",
        "    'model':{\n",
        "        'baseline': {\n",
        "            'random': {\n",
        "                'b': 4096\n",
        "            },\n",
        "            'fnn':{\n",
        "                'l': [100],  # list of number of nodes in each layer\n",
        "                'lr': 0.1,  # learning rate\n",
        "                'b': 4096,  # batch size\n",
        "                'e': 20,  # epoch\n",
        "                'nns': 1,  # number of negative samples\n",
        "                'ns': 'uniform',  # 'uniform', 'unigram', 'unigram_b'\n",
        "            },\n",
        "            'bnn':{\n",
        "                'l': [100],  # list of number of nodes in each layer\n",
        "                'lr': 0.1,  # learning rate\n",
        "                'b': 4096,  # batch size\n",
        "                'e': 20,  # epoch\n",
        "                'nns': 2,  # number of negative samples\n",
        "                'ns': 'unigram_b',  # 'uniform', 'unigram', 'unigram_b'\n",
        "                's': 1  # # sample_elbo for bnn\n",
        "            },\n",
        "            'emb':{\n",
        "                'd': 100,# embedding dimension\n",
        "                'e': 100,# epoch\n",
        "                'dm': 1,# training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)\n",
        "                'w': 1 #cooccurrence window\n",
        "            }\n",
        "        },\n",
        "        'cmd': ['train', 'test', 'eval', 'plot'],  # 'train', 'test', 'eval'\n",
        "        'nfolds': 3,\n",
        "        'train_test_split': 0.85\n",
        "    },\n",
        "    'data':{\n",
        "        'domain': {\n",
        "            'dblp':{},\n",
        "            'uspt':{},\n",
        "            'imdb':{},\n",
        "        },\n",
        "        'filter': {\n",
        "            'min_nteam': 75,\n",
        "            'min_team_size': 3,\n",
        "        },\n",
        "        'parallel': 1,\n",
        "        'ncore': 0,# <= 0 for all\n",
        "        'bucket_size': 500\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "e_IpSujJGUgX",
        "outputId": "f99a9c83-bbd5-43f5-f6a1-9bdfb0f84ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting param.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing Cache Pickles for Teams Sparce Matrix if Exist`(Optional)`**"
      ],
      "metadata": {
        "id": "a-hr8hQxVS64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R ../data/preprocessed/dblp/toy.dblp.v12.json/"
      ],
      "metadata": {
        "id": "xR1R1nUpVSLg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark on Toy subset of DBLP for non-Bayesian Feedforward (fnn) and Bayesian (bnn) Models**"
      ],
      "metadata": {
        "id": "o41hWOnFoiVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -data ../data/raw/dblp/toy.dblp.v12.json -domain dblp -model fnn bnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUkUAFyIXAD",
        "outputId": "9f8895d7-d953-4267-d1c2-80e54a3efdbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "File not found! Generating the sparse matrices ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "Pickles not found! Reading raw data from ../data/raw/dblp/toy.dblp.v12.json (progress in bytes) ...\n",
            "\r  0% 0/46630 [00:00<?, ?it/s]JSONDecodeError: There has been error in loading json line `[\n",
            "`!\n",
            "Expecting value: line 2 column 1 (char 2)\n",
            "JSONDecodeError: There has been error in loading json line `]`!\n",
            "Expecting value: line 1 column 1 (char 0)\n",
            "\r100% 46606/46630 [00:00<00:00, 14041066.82it/s]\n",
            "It took 0.0004496574401855469 seconds to pickle the data into ./../data/preprocessed/dblp/toy.dblp.v12.json\n",
            "It took 0.027997732162475586 seconds to generate and store the sparse matrices of size (31, 25) at ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 38.868099212646484, Time 0.006888628005981445, Overall 0.009534835815429688 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 2.286358777214499, Time 0.006992816925048828, Overall 0.00963735580444336 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 15.80270767211914, Time 0.009239435195922852, Overall 0.011884927749633789 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 1.755856408013238, Time 0.009329080581665039, Overall 0.011973857879638672 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 25.21894073486328, Time 0.014026403427124023, Overall 0.016672372817993164 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 1.4834671020507812, Time 0.014137744903564453, Overall 0.016783475875854492 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 11.584088325500488, Time 0.016221284866333008, Overall 0.018866777420043945 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 1.2871209250556097, Time 0.016306400299072266, Overall 0.018950939178466797 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 25.64533805847168, Time 0.020717144012451172, Overall 0.02336263656616211 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.5085492975571577, Time 0.020797014236450195, Overall 0.023442745208740234 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 13.609314918518066, Time 0.02294445037841797, Overall 0.025590181350708008 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 1.5121461020575628, Time 0.023035287857055664, Overall 0.025680065155029297 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 22.23078727722168, Time 0.027901887893676758, Overall 0.030547142028808594 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.3076933692483341, Time 0.027979612350463867, Overall 0.030624866485595703 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 7.565790176391602, Time 0.029882431030273438, Overall 0.032527923583984375 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 0.8406433529324002, Time 0.029964685440063477, Overall 0.03260922431945801 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 35.12837219238281, Time 0.03426098823547363, Overall 0.03690624237060547 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.066374834846048, Time 0.03434443473815918, Overall 0.03698921203613281 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 11.890203475952148, Time 0.036261558532714844, Overall 0.03890681266784668 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 1.3211337195502386, Time 0.03635239601135254, Overall 0.03899693489074707 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 23.01722526550293, Time 0.04049873352050781, Overall 0.04314422607421875 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.3539544273825252, Time 0.040574073791503906, Overall 0.043219804763793945 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 15.930505752563477, Time 0.04246830940246582, Overall 0.045113325119018555 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 1.7700561947292752, Time 0.04254937171936035, Overall 0.04519391059875488 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 38.270042419433594, Time 0.04662775993347168, Overall 0.049272775650024414 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 2.251178965849035, Time 0.04670381546020508, Overall 0.049349069595336914 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 36.873619079589844, Time 0.048590660095214844, Overall 0.05123615264892578 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 4.097068786621094, Time 0.04867291450500488, Overall 0.051317453384399414 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 27.30874252319336, Time 0.0527498722076416, Overall 0.05539512634277344 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 1.606396619011374, Time 0.05283045768737793, Overall 0.05547595024108887 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 17.834285736083984, Time 0.054744720458984375, Overall 0.05739021301269531 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 1.9815873040093317, Time 0.054827213287353516, Overall 0.05747270584106445 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 18.54025650024414, Time 0.05890011787414551, Overall 0.06154513359069824 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 1.0906033235437729, Time 0.05898404121398926, Overall 0.06162858009338379 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 19.328859329223633, Time 0.06084728240966797, Overall 0.0634925365447998 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 2.147651036580404, Time 0.06093096733093262, Overall 0.06357550621032715 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 14.173882484436035, Time 0.06496095657348633, Overall 0.06760597229003906 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 0.8337577932021197, Time 0.06503891944885254, Overall 0.06768417358398438 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 18.869606018066406, Time 0.06691169738769531, Overall 0.06955695152282715 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 2.0966228908962674, Time 0.06699800491333008, Overall 0.06964302062988281 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 22.940059661865234, Time 0.07115507125854492, Overall 0.07380056381225586 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 1.3494152742273666, Time 0.07123303413391113, Overall 0.07387852668762207 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 20.84394645690918, Time 0.07307863235473633, Overall 0.07572412490844727 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 2.315994050767687, Time 0.07317852973937988, Overall 0.07582306861877441 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 20.72052001953125, Time 0.07734465599060059, Overall 0.07999014854431152 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 1.2188541187959558, Time 0.07741808891296387, Overall 0.0800626277923584 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 15.744548797607422, Time 0.07928013801574707, Overall 0.0819253921508789 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 1.7493943108452692, Time 0.07936906814575195, Overall 0.08201408386230469 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 11.13480281829834, Time 0.08346438407897949, Overall 0.08610963821411133 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 0.6549884010763729, Time 0.08353972434997559, Overall 0.08618521690368652 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 18.77586555480957, Time 0.08544111251831055, Overall 0.08808660507202148 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 2.08620728386773, Time 0.08552169799804688, Overall 0.08816647529602051 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 13.816595077514648, Time 0.08954548835754395, Overall 0.09219074249267578 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 0.8127408869126264, Time 0.08962202072143555, Overall 0.09226679801940918 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 15.228389739990234, Time 0.09151172637939453, Overall 0.09415674209594727 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 1.6920433044433594, Time 0.09159278869628906, Overall 0.0942375659942627 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 12.189634323120117, Time 0.09566855430603027, Overall 0.09831380844116211 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 0.7170373131247127, Time 0.09574508666992188, Overall 0.09839034080505371 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 18.79627799987793, Time 0.09765148162841797, Overall 0.1002967357635498 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 2.08847533331977, Time 0.09773421287536621, Overall 0.10037899017333984 \n",
            "Epoch    15: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 17.00518035888672, Time 0.10182642936706543, Overall 0.10447192192077637 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 1.0003047269933365, Time 0.10190463066101074, Overall 0.10455036163330078 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 22.12286949157715, Time 0.10378789901733398, Overall 0.10643315315246582 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 2.4580966101752386, Time 0.10387086868286133, Overall 0.10651540756225586 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 19.01552963256836, Time 0.10810637474060059, Overall 0.11075186729431152 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 1.1185605666216683, Time 0.1081991195678711, Overall 0.11084365844726562 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 29.12561798095703, Time 0.11008572578430176, Overall 0.1127312183380127 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 3.2361797756618924, Time 0.11020636558532715, Overall 0.11285090446472168 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 23.354856491088867, Time 0.11446523666381836, Overall 0.1171102523803711 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 1.37381508771111, Time 0.11454224586486816, Overall 0.1171877384185791 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 27.19263458251953, Time 0.11660575866699219, Overall 0.11925148963928223 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 3.02140384250217, Time 0.11673927307128906, Overall 0.1193840503692627 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 7.254262924194336, Time 0.12098836898803711, Overall 0.12363386154174805 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 0.42672134848201976, Time 0.12107324600219727, Overall 0.1237187385559082 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 32.27606201171875, Time 0.12305927276611328, Overall 0.12570476531982422 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 3.5862291124131946, Time 0.12316370010375977, Overall 0.1258087158203125 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 9.788779258728027, Time 0.13010811805725098, Overall 0.13275456428527832 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 0.5758105446310604, Time 0.13024520874023438, Overall 0.1328907012939453 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 22.629024505615234, Time 0.1335756778717041, Overall 0.13622117042541504 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 2.5143360561794705, Time 0.13366436958312988, Overall 0.13630890846252441 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.8421630859375, Time 0.004026889801025391, Overall 0.1423020362854004 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 2.3436566521139706, Time 0.0041332244873046875, Overall 0.1424086093902588 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 16.401695251464844, Time 0.00619196891784668, Overall 0.14446663856506348 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 1.8224105834960938, Time 0.006287813186645508, Overall 0.1445620059967041 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 25.014537811279297, Time 0.011334896087646484, Overall 0.14961028099060059 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 1.471443400663488, Time 0.011420488357543945, Overall 0.14969587326049805 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 13.329676628112793, Time 0.013396978378295898, Overall 0.1516721248626709 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 1.4810751809014215, Time 0.013483762741088867, Overall 0.15176987648010254 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 24.59455680847168, Time 0.018019437789916992, Overall 0.1562948226928711 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 1.4467386357924517, Time 0.018101215362548828, Overall 0.15637660026550293 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 11.225784301757812, Time 0.02003765106201172, Overall 0.15831255912780762 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 1.2473093668619792, Time 0.020131587982177734, Overall 0.15840601921081543 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 16.24554443359375, Time 0.02429342269897461, Overall 0.1625678539276123 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 0.9556202607996324, Time 0.024371623992919922, Overall 0.16264677047729492 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 21.040170669555664, Time 0.02628183364868164, Overall 0.16455650329589844 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 2.3377967410617404, Time 0.02636575698852539, Overall 0.16463994979858398 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 27.823623657226562, Time 0.030486583709716797, Overall 0.1687617301940918 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.636683744542739, Time 0.030590534210205078, Overall 0.16886496543884277 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 17.543235778808594, Time 0.032411813735961914, Overall 0.1706867218017578 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 1.9492484198676214, Time 0.03251218795776367, Overall 0.17078661918640137 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 24.009536743164062, Time 0.03668642044067383, Overall 0.17496204376220703 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.4123256907743567, Time 0.03676962852478027, Overall 0.17504429817199707 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 29.647144317626953, Time 0.03946208953857422, Overall 0.17773723602294922 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 3.2941271464029946, Time 0.03956413269042969, Overall 0.17783832550048828 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 7.863761901855469, Time 0.04397916793823242, Overall 0.18225431442260742 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 0.46257422952090993, Time 0.04405355453491211, Overall 0.1823277473449707 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 32.393821716308594, Time 0.04595661163330078, Overall 0.18423151969909668 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 3.5993135240342884, Time 0.04603981971740723, Overall 0.18431401252746582 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 23.4017333984375, Time 0.05009317398071289, Overall 0.1883678436279297 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 1.3765725528492647, Time 0.05016946792602539, Overall 0.1884443759918213 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 28.5552978515625, Time 0.05205368995666504, Overall 0.19032883644104004 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 3.1728108723958335, Time 0.05213665962219238, Overall 0.19041109085083008 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 25.225448608398438, Time 0.056128740310668945, Overall 0.19440364837646484 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 1.4838499181410845, Time 0.05620551109313965, Overall 0.19448089599609375 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 33.0114860534668, Time 0.05804944038391113, Overall 0.19632458686828613 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 3.667942894829644, Time 0.05813312530517578, Overall 0.19640731811523438 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 8.321453094482422, Time 0.06219792366027832, Overall 0.20047307014465332 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 0.48949724085190716, Time 0.06227540969848633, Overall 0.20055031776428223 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 29.990955352783203, Time 0.06415557861328125, Overall 0.20243072509765625 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 3.332328372531467, Time 0.06424498558044434, Overall 0.20251941680908203 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 12.942488670349121, Time 0.06822729110717773, Overall 0.20650219917297363 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 0.761322862961713, Time 0.06830406188964844, Overall 0.20657920837402344 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 31.60140609741211, Time 0.07039856910705566, Overall 0.20867371559143066 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 3.511267344156901, Time 0.07051539421081543, Overall 0.20879006385803223 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 6.963932514190674, Time 0.07515931129455566, Overall 0.21343493461608887 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 0.40964308907003966, Time 0.07525348663330078, Overall 0.21352839469909668 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 41.37749099731445, Time 0.0772249698638916, Overall 0.2154998779296875 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 4.597498999701606, Time 0.07731103897094727, Overall 0.21558547019958496 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 28.202777862548828, Time 0.08150649070739746, Overall 0.21978163719177246 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 1.6589869330911076, Time 0.08158373832702637, Overall 0.21985840797424316 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 39.12431335449219, Time 0.08344221115112305, Overall 0.22171735763549805 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 4.34714592827691, Time 0.08354568481445312, Overall 0.22182011604309082 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 18.27781105041504, Time 0.087677001953125, Overall 0.2259519100189209 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 1.075165355906767, Time 0.0877542495727539, Overall 0.2260291576385498 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 57.824100494384766, Time 0.08971714973449707, Overall 0.22799229621887207 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 6.424900054931641, Time 0.08980894088745117, Overall 0.22808313369750977 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 13.604779243469238, Time 0.09539556503295898, Overall 0.2336711883544922 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 0.8002811319687787, Time 0.09547114372253418, Overall 0.23374605178833008 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 45.97228240966797, Time 0.09881472587585449, Overall 0.2371072769165039 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 5.108031378851996, Time 0.09894561767578125, Overall 0.23722076416015625 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 16.501134872436523, Time 0.10660719871520996, Overall 0.24488377571105957 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 0.9706549924962661, Time 0.10669732093811035, Overall 0.24497199058532715 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 51.80534744262695, Time 0.10872435569763184, Overall 0.24699926376342773 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 5.756149715847439, Time 0.10881423950195312, Overall 0.24708914756774902 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 16.490192413330078, Time 0.1133122444152832, Overall 0.2515871524810791 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 0.970011318431181, Time 0.11339163780212402, Overall 0.251666784286499 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 45.09357833862305, Time 0.11530900001525879, Overall 0.2535841464996338 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 5.010397593180339, Time 0.11539459228515625, Overall 0.25366902351379395 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 11.471632957458496, Time 0.1194314956665039, Overall 0.2577061653137207 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 0.6748019386740292, Time 0.11952853202819824, Overall 0.25780320167541504 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 44.357879638671875, Time 0.12138605117797852, Overall 0.2596609592437744 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 4.928653293185764, Time 0.12147045135498047, Overall 0.25974535942077637 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 8.040119171142578, Time 0.12551403045654297, Overall 0.26378917694091797 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 0.4729481865377987, Time 0.12558698654174805, Overall 0.26386213302612305 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 57.10557174682617, Time 0.12741827964782715, Overall 0.26569318771362305 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 6.34506352742513, Time 0.1275172233581543, Overall 0.2657926082611084 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 20.04747200012207, Time 0.1315457820892334, Overall 0.2698216438293457 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 1.17926305883071, Time 0.1316230297088623, Overall 0.2698972225189209 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 48.27355194091797, Time 0.13346505165100098, Overall 0.271740198135376 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 5.3637279934353295, Time 0.1335606575012207, Overall 0.2718350887298584 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 38.401580810546875, Time 0.0037033557891845703, Overall 0.27727508544921875 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 2.133421156141493, Time 0.003778696060180664, Overall 0.27735066413879395 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 12.985238075256348, Time 0.0055696964263916016, Overall 0.2791416645050049 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 1.6231547594070435, Time 0.005651712417602539, Overall 0.2792229652404785 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 19.80780792236328, Time 0.009808540344238281, Overall 0.28338050842285156 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 1.1004337734646268, Time 0.009887218475341797, Overall 0.2834594249725342 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 24.33113670349121, Time 0.011635780334472656, Overall 0.28520727157592773 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 3.0413920879364014, Time 0.01171565055847168, Overall 0.28528666496276855 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 29.354890823364258, Time 0.01586294174194336, Overall 0.28943467140197754 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 1.630827267964681, Time 0.015941619873046875, Overall 0.28951382637023926 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.775718688964844, Time 0.01771378517150879, Overall 0.29128575325012207 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 2.2219648361206055, Time 0.017796039581298828, Overall 0.2913675308227539 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 25.82021713256836, Time 0.02199411392211914, Overall 0.2955660820007324 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.434456507364909, Time 0.022072792053222656, Overall 0.29564499855041504 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 26.74820899963379, Time 0.023827791213989258, Overall 0.29739928245544434 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 3.3435261249542236, Time 0.0239105224609375, Overall 0.2974820137023926 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 42.83470153808594, Time 0.028025150299072266, Overall 0.30159687995910645 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 2.379705641004774, Time 0.02810359001159668, Overall 0.30167579650878906 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 17.743375778198242, Time 0.029848098754882812, Overall 0.303419828414917 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 2.2179219722747803, Time 0.029932022094726562, Overall 0.30350327491760254 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 28.210023880004883, Time 0.03414106369018555, Overall 0.30771303176879883 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 1.5672235488891602, Time 0.03423357009887695, Overall 0.30780482292175293 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 16.805387496948242, Time 0.035944461822509766, Overall 0.30951619148254395 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 2.1006734371185303, Time 0.036090850830078125, Overall 0.3096628189086914 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 23.665931701660156, Time 0.040550947189331055, Overall 0.31412291526794434 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.3147739834255643, Time 0.04062318801879883, Overall 0.3141942024230957 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 19.860301971435547, Time 0.042415618896484375, Overall 0.31598711013793945 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 2.4825377464294434, Time 0.042502641677856445, Overall 0.3160738945007324 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 28.08772850036621, Time 0.04663991928100586, Overall 0.32021141052246094 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.5604293611314561, Time 0.04671454429626465, Overall 0.32028675079345703 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 14.177030563354492, Time 0.04848885536193848, Overall 0.32206058502197266 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 1.7721288204193115, Time 0.04856991767883301, Overall 0.322141170501709 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 19.351150512695312, Time 0.052695274353027344, Overall 0.3262672424316406 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.0750639173719618, Time 0.052771806716918945, Overall 0.3263437747955322 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 12.398041725158691, Time 0.0545201301574707, Overall 0.3280916213989258 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 1.5497552156448364, Time 0.05459880828857422, Overall 0.3281700611114502 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 36.051727294921875, Time 0.05869936943054199, Overall 0.33227109909057617 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 2.002873738606771, Time 0.0587773323059082, Overall 0.3323493003845215 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 12.573692321777344, Time 0.0605778694152832, Overall 0.3341493606567383 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 1.571711540222168, Time 0.06065845489501953, Overall 0.3342301845550537 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 16.87942123413086, Time 0.06481790542602539, Overall 0.33838987350463867 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 0.937745624118381, Time 0.06489849090576172, Overall 0.338470458984375 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 10.686605453491211, Time 0.06673383712768555, Overall 0.3403055667877197 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 1.3358256816864014, Time 0.06681537628173828, Overall 0.34038662910461426 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 11.272163391113281, Time 0.07173848152160645, Overall 0.3453104496002197 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 0.6262312995062934, Time 0.07181596755981445, Overall 0.34538769721984863 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 11.497665405273438, Time 0.07365036010742188, Overall 0.34722232818603516 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 1.4372081756591797, Time 0.07376217842102051, Overall 0.3473334312438965 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 7.534966468811035, Time 0.07814216613769531, Overall 0.3517138957977295 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.41860924826727974, Time 0.07823562622070312, Overall 0.351806640625 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 12.394344329833984, Time 0.07997560501098633, Overall 0.3535473346710205 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 1.549293041229248, Time 0.08005857467651367, Overall 0.35363054275512695 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 22.08655548095703, Time 0.08425617218017578, Overall 0.35782814025878906 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.2270308600531683, Time 0.08432865142822266, Overall 0.35790061950683594 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 14.107027053833008, Time 0.08609127998352051, Overall 0.3596630096435547 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 1.763378381729126, Time 0.08617544174194336, Overall 0.35974693298339844 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 29.68954849243164, Time 0.09036540985107422, Overall 0.3639373779296875 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 1.6494193606906467, Time 0.0904383659362793, Overall 0.3640103340148926 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 12.567941665649414, Time 0.09215545654296875, Overall 0.36572718620300293 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 1.5709927082061768, Time 0.09225320816040039, Overall 0.36582446098327637 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 24.784902572631836, Time 0.09641599655151367, Overall 0.36998796463012695 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 1.3769390318128798, Time 0.09649872779846191, Overall 0.3700697422027588 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 14.052434921264648, Time 0.09826326370239258, Overall 0.37183499336242676 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 1.756554365158081, Time 0.0983438491821289, Overall 0.371915340423584 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 21.886741638183594, Time 0.10253143310546875, Overall 0.37610340118408203 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.2159300910101996, Time 0.10260653495788574, Overall 0.376178503036499 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 17.26756477355957, Time 0.10438132286071777, Overall 0.37795329093933105 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 2.1584455966949463, Time 0.10446286201477051, Overall 0.3780343532562256 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 8.575087547302246, Time 0.10956072807312012, Overall 0.3831326961517334 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 0.47639375262790257, Time 0.10963582992553711, Overall 0.383206844329834 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 14.06101131439209, Time 0.11200881004333496, Overall 0.38558149337768555 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 1.7576264142990112, Time 0.11209797859191895, Overall 0.3856699466705322 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 14.540138244628906, Time 0.11736869812011719, Overall 0.3909413814544678 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 0.8077854580349393, Time 0.11745643615722656, Overall 0.39102792739868164 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 18.544193267822266, Time 0.11935257911682129, Overall 0.39292454719543457 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 2.318024158477783, Time 0.11943435668945312, Overall 0.3930060863494873 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 9.144205093383789, Time 0.12360644340515137, Overall 0.39717817306518555 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 0.5080113940768771, Time 0.12368226051330566, Overall 0.39725422859191895 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 17.907787322998047, Time 0.12541580200195312, Overall 0.3989877700805664 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 2.238473415374756, Time 0.12551593780517578, Overall 0.39908742904663086 \n",
            "It took 0.3999171257019043 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 9.107589721679688e-05 seconds to load from the pickles.\n",
            "It took 0.0004630088806152344 seconds to load the sparse matrices.\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 337.42852783203125, Time 0.02044057846069336, Overall 0.022736549377441406 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 19.848736931295957, Time 0.020562410354614258, Overall 0.022856950759887695 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 213.52210998535156, Time 0.03197503089904785, Overall 0.0342707633972168 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 23.724678887261284, Time 0.032134294509887695, Overall 0.03442883491516113 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 319.1553955078125, Time 0.04572463035583496, Overall 0.0480189323425293 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 18.773846794577207, Time 0.04581141471862793, Overall 0.04810452461242676 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 187.7079315185547, Time 0.05288195610046387, Overall 0.0551760196685791 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 20.856436835394966, Time 0.05296754837036133, Overall 0.05526089668273926 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 288.1966857910156, Time 0.06510543823242188, Overall 0.06739950180053711 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 16.95274622300092, Time 0.06518387794494629, Overall 0.06747722625732422 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 70.45561981201172, Time 0.07164621353149414, Overall 0.07394003868103027 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 7.828402201334636, Time 0.07173347473144531, Overall 0.07402658462524414 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 403.9219970703125, Time 0.08388376235961914, Overall 0.08617782592773438 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 23.760117474724264, Time 0.08396244049072266, Overall 0.08625531196594238 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 196.68228149414062, Time 0.09047889709472656, Overall 0.0927729606628418 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 21.853586832682293, Time 0.09056997299194336, Overall 0.09286308288574219 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 342.0171813964844, Time 0.10259270668029785, Overall 0.10488700866699219 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 20.118657729204962, Time 0.10267376899719238, Overall 0.10496687889099121 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 153.73764038085938, Time 0.10905838012695312, Overall 0.11135220527648926 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 17.081960042317707, Time 0.1091456413269043, Overall 0.11143875122070312 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 352.779052734375, Time 0.12103605270385742, Overall 0.12333011627197266 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 20.751708984375, Time 0.12111687660217285, Overall 0.12340974807739258 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 177.95484924316406, Time 0.12748074531555176, Overall 0.1297750473022461 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 19.77276102701823, Time 0.12756729125976562, Overall 0.12986087799072266 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 316.18695068359375, Time 0.14096522331237793, Overall 0.14325928688049316 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 18.599232393152572, Time 0.14104270935058594, Overall 0.14333629608154297 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 219.62506103515625, Time 0.1474475860595703, Overall 0.14974212646484375 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 24.402784559461807, Time 0.14753270149230957, Overall 0.1498260498046875 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 349.08203125, Time 0.15982890129089355, Overall 0.1621232032775879 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 20.534237132352942, Time 0.1599104404449463, Overall 0.16220355033874512 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 240.68614196777344, Time 0.16615915298461914, Overall 0.16845297813415527 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 26.742904663085938, Time 0.16624021530151367, Overall 0.1685330867767334 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 351.6190490722656, Time 0.17769765853881836, Overall 0.1799917221069336 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 20.683473474839154, Time 0.17777752876281738, Overall 0.1800706386566162 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 304.0992431640625, Time 0.1840665340423584, Overall 0.18636107444763184 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 33.78880479600694, Time 0.18414926528930664, Overall 0.18644237518310547 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 429.276123046875, Time 0.19563007354736328, Overall 0.19792413711547852 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 25.251536649816178, Time 0.19570708274841309, Overall 0.19800043106079102 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 97.95563507080078, Time 0.2019968032836914, Overall 0.20429110527038574 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 10.883959452311197, Time 0.20208382606506348, Overall 0.2043769359588623 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 413.65203857421875, Time 0.21374917030334473, Overall 0.21604323387145996 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 24.332472857306986, Time 0.21382880210876465, Overall 0.21612167358398438 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 209.68174743652344, Time 0.22020339965820312, Overall 0.22249841690063477 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 23.297971937391495, Time 0.22031116485595703, Overall 0.22260451316833496 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 391.8335266113281, Time 0.2324659824371338, Overall 0.23476004600524902 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 23.049030977136947, Time 0.23254179954528809, Overall 0.23483490943908691 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 216.04360961914062, Time 0.23913931846618652, Overall 0.24143338203430176 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 24.004845513237846, Time 0.23922419548034668, Overall 0.2415175437927246 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 369.58856201171875, Time 0.25153303146362305, Overall 0.2538280487060547 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 21.740503647748163, Time 0.251636266708374, Overall 0.25392985343933105 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 213.26376342773438, Time 0.26241207122802734, Overall 0.2647063732147217 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 23.695973714192707, Time 0.2625124454498291, Overall 0.26480531692504883 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 398.03533935546875, Time 0.27445006370544434, Overall 0.27674436569213867 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 23.413843491498163, Time 0.2745344638824463, Overall 0.276827335357666 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 198.72315979003906, Time 0.28382229804992676, Overall 0.2861180305480957 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 22.08035108778212, Time 0.28394031524658203, Overall 0.28623461723327637 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 472.06964111328125, Time 0.3011009693145752, Overall 0.30339527130126953 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 27.768802418428308, Time 0.3011796474456787, Overall 0.30347299575805664 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 180.45413208007812, Time 0.3078129291534424, Overall 0.3101069927215576 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 20.050459120008682, Time 0.3079040050506592, Overall 0.310197114944458 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 406.7854919433594, Time 0.3202507495880127, Overall 0.32254505157470703 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 23.928558349609375, Time 0.3203568458557129, Overall 0.3226499557495117 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 214.03390502929688, Time 0.32683730125427246, Overall 0.3291313648223877 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 23.781545003255207, Time 0.32692742347717285, Overall 0.3292202949523926 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 383.7011413574219, Time 0.340038537979126, Overall 0.3423328399658203 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 22.57065537396599, Time 0.34012579917907715, Overall 0.3424191474914551 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 291.46673583984375, Time 0.3471670150756836, Overall 0.34946107864379883 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 32.38519287109375, Time 0.3472607135772705, Overall 0.34955430030822754 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 385.89410400390625, Time 0.3596019744873047, Overall 0.361896276473999 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 22.699653176700366, Time 0.35970067977905273, Overall 0.36199498176574707 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 264.1129455566406, Time 0.36725354194641113, Overall 0.36954784393310547 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 29.345882839626736, Time 0.3673746585845947, Overall 0.3696749210357666 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 329.06695556640625, Time 0.37897706031799316, Overall 0.3812711238861084 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 19.356879739200366, Time 0.37906885147094727, Overall 0.3813626766204834 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 182.725830078125, Time 0.38541412353515625, Overall 0.3877084255218506 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 20.302870008680557, Time 0.3855161666870117, Overall 0.38780951499938965 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 297.21319580078125, Time 0.3973419666290283, Overall 0.39963650703430176 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 17.483129164751837, Time 0.3974442481994629, Overall 0.3997378349304199 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 229.74191284179688, Time 0.4039626121520996, Overall 0.40625691413879395 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 25.526879204644096, Time 0.4040651321411133, Overall 0.4063587188720703 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 358.4234313964844, Time 0.011151313781738281, Overall 0.4203476905822754 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 21.083731258616726, Time 0.011243343353271484, Overall 0.4204392433166504 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 125.86417388916016, Time 0.017628192901611328, Overall 0.42682480812072754 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 13.984908209906685, Time 0.017724275588989258, Overall 0.42691969871520996 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 462.6322937011719, Time 0.02950453758239746, Overall 0.4387021064758301 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 27.213664335363053, Time 0.029601097106933594, Overall 0.4387967586517334 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 156.225341796875, Time 0.036119699478149414, Overall 0.4453158378601074 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 17.35837131076389, Time 0.03622174263000488, Overall 0.4454169273376465 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 370.5702209472656, Time 0.048233985900878906, Overall 0.4574298858642578 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 21.798248291015625, Time 0.048325538635253906, Overall 0.4575214385986328 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 187.25411987304688, Time 0.054689884185791016, Overall 0.4638857841491699 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 20.806013319227432, Time 0.05478358268737793, Overall 0.46397876739501953 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 380.6238708496094, Time 0.06677865982055664, Overall 0.47597455978393555 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 22.389639461741726, Time 0.066864013671875, Overall 0.4760594367980957 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 218.3116912841797, Time 0.0734107494354248, Overall 0.4826068878173828 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 24.256854587131077, Time 0.07351279258728027, Overall 0.482708215713501 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 351.0431213378906, Time 0.08513188362121582, Overall 0.49432802200317383 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 20.649595372817096, Time 0.08523988723754883, Overall 0.49443578720092773 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 223.0906982421875, Time 0.09169602394104004, Overall 0.500891923904419 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 24.787855360243057, Time 0.09179306030273438, Overall 0.5009884834289551 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 412.4347229003906, Time 0.10329961776733398, Overall 0.5124955177307129 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 24.260866052964154, Time 0.10340332984924316, Overall 0.5125987529754639 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 205.18292236328125, Time 0.1097421646118164, Overall 0.5189383029937744 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 22.79810248480903, Time 0.10983800888061523, Overall 0.5190329551696777 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 340.03607177734375, Time 0.12146472930908203, Overall 0.5306611061096191 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 20.002121869255514, Time 0.12156200408935547, Overall 0.5307576656341553 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 219.86654663085938, Time 0.12793445587158203, Overall 0.5371301174163818 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 24.429616292317707, Time 0.1280372142791748, Overall 0.5372333526611328 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 378.55316162109375, Time 0.14002466201782227, Overall 0.5492210388183594 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 22.267833036534928, Time 0.14012551307678223, Overall 0.5493206977844238 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 252.07968139648438, Time 0.14792609214782715, Overall 0.5571234226226807 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 28.008853488498264, Time 0.14806103706359863, Overall 0.5572571754455566 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 439.616943359375, Time 0.1654660701751709, Overall 0.574662446975708 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 25.859820197610293, Time 0.16556334495544434, Overall 0.5747585296630859 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 226.9439697265625, Time 0.17193937301635742, Overall 0.5811352729797363 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 25.21599663628472, Time 0.17203855514526367, Overall 0.5812335014343262 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 377.4131164550781, Time 0.18370676040649414, Overall 0.5929028987884521 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 22.200771556181067, Time 0.18379950523376465, Overall 0.5929946899414062 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 243.5690155029297, Time 0.1901407241821289, Overall 0.5993366241455078 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 27.063223944769966, Time 0.19024419784545898, Overall 0.5994396209716797 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 371.4774169921875, Time 0.20201420783996582, Overall 0.6112101078033447 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 21.851612764246322, Time 0.20210719108581543, Overall 0.611302375793457 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 220.32505798339844, Time 0.20852041244506836, Overall 0.6177163124084473 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 24.48056199815538, Time 0.20861244201660156, Overall 0.6178081035614014 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 387.30523681640625, Time 0.22045254707336426, Overall 0.6296489238739014 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 22.782660989200366, Time 0.2205491065979004, Overall 0.6297445297241211 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 164.11573791503906, Time 0.2268977165222168, Overall 0.6360936164855957 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 18.235081990559895, Time 0.22699475288391113, Overall 0.6361908912658691 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 355.0196533203125, Time 0.2386939525604248, Overall 0.6478898525238037 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 20.883509018841913, Time 0.23878812789916992, Overall 0.6479835510253906 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 194.06773376464844, Time 0.24526405334472656, Overall 0.6544604301452637 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 21.56308152940538, Time 0.24538111686706543, Overall 0.6545765399932861 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 424.0707702636719, Time 0.2586171627044678, Overall 0.667813777923584 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 24.945339427274817, Time 0.25871968269348145, Overall 0.667914628982544 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 127.55115509033203, Time 0.267822265625, Overall 0.6770191192626953 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 14.172350565592447, Time 0.26793694496154785, Overall 0.6771318912506104 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 344.68524169921875, Time 0.2806737422943115, Overall 0.6898701190948486 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 20.27560245289522, Time 0.2807729244232178, Overall 0.6899685859680176 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 156.14535522460938, Time 0.2871744632720947, Overall 0.6963703632354736 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 17.349483913845486, Time 0.28727006912231445, Overall 0.696465253829956 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 415.1403503417969, Time 0.2988724708557129, Overall 0.7080683708190918 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 24.42002060834099, Time 0.2989668846130371, Overall 0.708162784576416 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 254.8116912841797, Time 0.30529093742370605, Overall 0.7144870758056641 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 28.31241014268663, Time 0.3054049015045166, Overall 0.7146005630493164 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 288.9560852050781, Time 0.3171837329864502, Overall 0.72637939453125 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 16.997416776769303, Time 0.317272424697876, Overall 0.7264680862426758 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 169.96908569335938, Time 0.323636531829834, Overall 0.7328324317932129 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 18.885453965928818, Time 0.3237316608428955, Overall 0.732926607131958 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 331.5986633300781, Time 0.33558082580566406, Overall 0.7447769641876221 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 19.505803725298712, Time 0.3356754779815674, Overall 0.7448713779449463 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 236.79454040527344, Time 0.3420908451080322, Overall 0.7512869834899902 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 26.310504489474827, Time 0.3421914577484131, Overall 0.7513871192932129 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 359.50726318359375, Time 0.3542335033416748, Overall 0.7634294033050537 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 21.147486069623163, Time 0.35433006286621094, Overall 0.7635254859924316 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 235.54261779785156, Time 0.3607306480407715, Overall 0.7699265480041504 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 26.171401977539062, Time 0.3608253002166748, Overall 0.7700204849243164 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 353.63232421875, Time 0.37267446517944336, Overall 0.7818703651428223 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 20.80190142463235, Time 0.3727591037750244, Overall 0.7819545269012451 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 180.36102294921875, Time 0.3789863586425781, Overall 0.7881820201873779 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 20.040113661024307, Time 0.37908077239990234, Overall 0.7882764339447021 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 339.4406433105469, Time 0.011201858520507812, Overall 0.8022816181182861 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 18.857813517252605, Time 0.011295557022094727, Overall 0.802375316619873 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 155.30670166015625, Time 0.017549753189086914, Overall 0.8086297512054443 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 19.41333770751953, Time 0.01766180992126465, Overall 0.8087408542633057 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 456.10394287109375, Time 0.029715538024902344, Overall 0.8207955360412598 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 25.339107937282986, Time 0.029805660247802734, Overall 0.8208847045898438 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 164.77960205078125, Time 0.035927534103393555, Overall 0.8270070552825928 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 20.597450256347656, Time 0.036026716232299805, Overall 0.8271057605743408 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 290.02154541015625, Time 0.048371076583862305, Overall 0.8394508361816406 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 16.112308078342014, Time 0.048506736755371094, Overall 0.8395867347717285 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 173.8430938720703, Time 0.05479574203491211, Overall 0.8458750247955322 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 21.73038673400879, Time 0.054889678955078125, Overall 0.8459682464599609 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 294.1435241699219, Time 0.06767725944519043, Overall 0.858757495880127 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 16.341306898328995, Time 0.06777286529541016, Overall 0.8588523864746094 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 174.06576538085938, Time 0.07727909088134766, Overall 0.8683602809906006 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 21.758220672607422, Time 0.0773916244506836, Overall 0.8684711456298828 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 447.9836120605469, Time 0.09130501747131348, Overall 0.8823850154876709 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 24.88797844780816, Time 0.09140205383300781, Overall 0.882481575012207 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 190.83644104003906, Time 0.09847593307495117, Overall 0.8895561695098877 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 23.854555130004883, Time 0.09859657287597656, Overall 0.8896753787994385 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 416.45330810546875, Time 0.11085677146911621, Overall 0.9019367694854736 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 23.136294894748264, Time 0.11095309257507324, Overall 0.9020328521728516 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 192.57286071777344, Time 0.11708950996398926, Overall 0.9081690311431885 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 24.07160758972168, Time 0.11718440055847168, Overall 0.9082632064819336 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 351.50457763671875, Time 0.1292707920074463, Overall 0.9203507900238037 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 19.528032090928818, Time 0.12937378883361816, Overall 0.9204528331756592 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 194.06060791015625, Time 0.13602805137634277, Overall 0.9271080493927002 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 24.25757598876953, Time 0.1361372470855713, Overall 0.9272158145904541 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 449.3291931152344, Time 0.14833474159240723, Overall 0.9394147396087646 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 24.962732950846355, Time 0.14843440055847168, Overall 0.9395132064819336 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 208.35952758789062, Time 0.15463042259216309, Overall 0.9457097053527832 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 26.044940948486328, Time 0.1547396183013916, Overall 0.9458186626434326 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 319.7312927246094, Time 0.16710138320922852, Overall 0.9581811428070068 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 17.76284959581163, Time 0.1671898365020752, Overall 0.9582686424255371 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 245.91761779785156, Time 0.17326617240905762, Overall 0.9643454551696777 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 30.739702224731445, Time 0.17336344718933105, Overall 0.964442253112793 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 344.342529296875, Time 0.18731999397277832, Overall 0.9783997535705566 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 19.130140516493057, Time 0.18741297721862793, Overall 0.9784917831420898 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 190.2950439453125, Time 0.19464540481567383, Overall 0.9857251644134521 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 23.786880493164062, Time 0.1947472095489502, Overall 0.9858262538909912 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 444.4509582519531, Time 0.20662546157836914, Overall 0.9977052211761475 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 24.691719902886284, Time 0.20672178268432617, Overall 0.997800350189209 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 231.36065673828125, Time 0.21288800239562988, Overall 1.0039677619934082 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 28.920082092285156, Time 0.21298623085021973, Overall 1.0040655136108398 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 265.1795654296875, Time 0.22483563423156738, Overall 1.0159151554107666 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 14.732198079427084, Time 0.22492742538452148, Overall 1.0160062313079834 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 194.08763122558594, Time 0.23135089874267578, Overall 1.022430419921875 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 24.260953903198242, Time 0.23144984245300293, Overall 1.022528886795044 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 318.2929382324219, Time 0.24332237243652344, Overall 1.0344018936157227 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 17.682941012912327, Time 0.24341869354248047, Overall 1.0344982147216797 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 195.58888244628906, Time 0.24981403350830078, Overall 1.0408935546875 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 24.448610305786133, Time 0.24991512298583984, Overall 1.0409939289093018 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 368.2962951660156, Time 0.2617948055267334, Overall 1.0528743267059326 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 20.46090528700087, Time 0.2618870735168457, Overall 1.052966833114624 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 166.54151916503906, Time 0.268552303314209, Overall 1.0596320629119873 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 20.817689895629883, Time 0.2686471939086914, Overall 1.0597262382507324 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 358.68133544921875, Time 0.2804992198944092, Overall 1.0715789794921875 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 19.926740858289932, Time 0.28060126304626465, Overall 1.071681261062622 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 180.30210876464844, Time 0.2867774963378906, Overall 1.077857255935669 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 22.537763595581055, Time 0.28687286376953125, Overall 1.0779516696929932 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 401.2189636230469, Time 0.29874324798583984, Overall 1.0898230075836182 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 22.289942423502605, Time 0.29883337020874023, Overall 1.089911937713623 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 207.9300537109375, Time 0.3049592971801758, Overall 1.096039056777954 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 25.991256713867188, Time 0.3050553798675537, Overall 1.0961341857910156 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 326.4639892578125, Time 0.31683897972106934, Overall 1.1079182624816895 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 18.136888292100693, Time 0.3169243335723877, Overall 1.1080029010772705 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 233.79144287109375, Time 0.32294154167175293, Overall 1.1140210628509521 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 29.22393035888672, Time 0.3230316638946533, Overall 1.1141107082366943 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 424.1366882324219, Time 0.33499884605407715, Overall 1.1260783672332764 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 23.56314934624566, Time 0.33508872985839844, Overall 1.1261677742004395 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 155.51434326171875, Time 0.3411738872528076, Overall 1.1322534084320068 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 19.439292907714844, Time 0.3412744998931885, Overall 1.1323540210723877 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 304.5262756347656, Time 0.3531644344329834, Overall 1.1442439556121826 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 16.918126424153645, Time 0.35326194763183594, Overall 1.1443414688110352 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 166.5332794189453, Time 0.35944700241088867, Overall 1.150527000427246 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 20.816659927368164, Time 0.3595597743988037, Overall 1.1506388187408447 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 278.43121337890625, Time 0.3742969036102295, Overall 1.1653783321380615 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 15.46840074327257, Time 0.37439727783203125, Overall 1.1654770374298096 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 145.83433532714844, Time 0.38332653045654297, Overall 1.1744062900543213 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 18.229291915893555, Time 0.38343143463134766, Overall 1.1745100021362305 \n",
            "It took 1.176135540008545 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark Output Folder on toy.dblp for Baselines**"
      ],
      "metadata": {
        "id": "-Q06TnofpXeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/toy.dblp.v12.json/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ion5hv6viDa2",
        "outputId": "df735689-6bc5-4bde-91c0-7c1eacc6bebe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnn  bnn_emb  fnn  fnn_emb  random\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's look at the Bayesian (bnn) Results**\n",
        "\n",
        "```\n",
        "#team:30, #skills:11, #members:12\n",
        "layers:[100], learning rate:0.1, batch size:4096, epoch:20, \n",
        "#negative samples:2, negative sampling: unigram_b, elbo samples:1\n",
        "```"
      ],
      "metadata": {
        "id": "AMe6O86CpuPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5P-YCCFkAkg",
        "outputId": "f634c00c-08be-435a-869e-5441b1924756"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.test.pred\t\t    state_dict_model.f1.e15.pt\n",
            "f0.test.pred.eval.mean.csv  state_dict_model.f1.e16.pt\n",
            "f0.test.pred.eval.roc.pkl   state_dict_model.f1.e17.pt\n",
            "f0.train_valid_loss.png     state_dict_model.f1.e18.pt\n",
            "f1.test.pred\t\t    state_dict_model.f1.e19.pt\n",
            "f1.test.pred.eval.mean.csv  state_dict_model.f1.e1.pt\n",
            "f1.test.pred.eval.roc.pkl   state_dict_model.f1.e2.pt\n",
            "f1.train_valid_loss.png     state_dict_model.f1.e3.pt\n",
            "f2.test.pred\t\t    state_dict_model.f1.e4.pt\n",
            "f2.test.pred.eval.mean.csv  state_dict_model.f1.e5.pt\n",
            "f2.test.pred.eval.roc.pkl   state_dict_model.f1.e6.pt\n",
            "f2.train_valid_loss.png     state_dict_model.f1.e7.pt\n",
            "state_dict_model.f0.e0.pt   state_dict_model.f1.e8.pt\n",
            "state_dict_model.f0.e10.pt  state_dict_model.f1.e9.pt\n",
            "state_dict_model.f0.e11.pt  state_dict_model_f1.pt\n",
            "state_dict_model.f0.e12.pt  state_dict_model.f2.e0.pt\n",
            "state_dict_model.f0.e13.pt  state_dict_model.f2.e10.pt\n",
            "state_dict_model.f0.e14.pt  state_dict_model.f2.e11.pt\n",
            "state_dict_model.f0.e15.pt  state_dict_model.f2.e12.pt\n",
            "state_dict_model.f0.e16.pt  state_dict_model.f2.e13.pt\n",
            "state_dict_model.f0.e17.pt  state_dict_model.f2.e14.pt\n",
            "state_dict_model.f0.e18.pt  state_dict_model.f2.e15.pt\n",
            "state_dict_model.f0.e19.pt  state_dict_model.f2.e16.pt\n",
            "state_dict_model.f0.e1.pt   state_dict_model.f2.e17.pt\n",
            "state_dict_model.f0.e2.pt   state_dict_model.f2.e18.pt\n",
            "state_dict_model.f0.e3.pt   state_dict_model.f2.e19.pt\n",
            "state_dict_model.f0.e4.pt   state_dict_model.f2.e1.pt\n",
            "state_dict_model.f0.e5.pt   state_dict_model.f2.e2.pt\n",
            "state_dict_model.f0.e6.pt   state_dict_model.f2.e3.pt\n",
            "state_dict_model.f0.e7.pt   state_dict_model.f2.e4.pt\n",
            "state_dict_model.f0.e8.pt   state_dict_model.f2.e5.pt\n",
            "state_dict_model.f0.e9.pt   state_dict_model.f2.e6.pt\n",
            "state_dict_model_f0.pt\t    state_dict_model.f2.e7.pt\n",
            "state_dict_model.f1.e0.pt   state_dict_model.f2.e8.pt\n",
            "state_dict_model.f1.e10.pt  state_dict_model.f2.e9.pt\n",
            "state_dict_model.f1.e11.pt  state_dict_model_f2.pt\n",
            "state_dict_model.f1.e12.pt  test.pred.eval.mean.csv\n",
            "state_dict_model.f1.e13.pt  test.roc.png\n",
            "state_dict_model.f1.e14.pt  train_valid_loss.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Plot for 3-Fold Cross-Validated Models on Test Set**"
      ],
      "metadata": {
        "id": "KhtwppXbrEEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1/test.roc.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-75NPqckkbGm",
        "outputId": "ba4b6900-b3b6-41d4-9f70-ab5cf3466d69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1/test.pred.eval.mean.csv', index_col = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "bdooeMNexjjl",
        "outputId": "cd0c84e9-2caf-4a94-f3e6-a6c9b6fb4fe0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cec5c832-a120-4330-8cda-e8e39565c019\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.226667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.383333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.051580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.238343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.437073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.139352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.254440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.530325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cec5c832-a120-4330-8cda-e8e39565c019')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cec5c832-a120-4330-8cda-e8e39565c019 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cec5c832-a120-4330-8cda-e8e39565c019');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 mean\n",
              "P_2          0.066667\n",
              "P_5          0.200000\n",
              "P_10         0.226667\n",
              "recall_2     0.055556\n",
              "recall_5     0.383333\n",
              "recall_10    0.866667\n",
              "ndcg_cut_2   0.051580\n",
              "ndcg_cut_5   0.238343\n",
              "ndcg_cut_10  0.437073\n",
              "map_cut_2    0.027778\n",
              "map_cut_5    0.139352\n",
              "map_cut_10   0.254440\n",
              "aucroc       0.530325"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}