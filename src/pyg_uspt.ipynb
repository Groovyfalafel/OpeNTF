{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def load_pkl():\n",
    "    # path_to_pickle = '../data/preprocessed/uspt/toy.patent.tsv'\n",
    "    path_to_pickle = '../data/preprocessed/uspt/patent.tsv.filtered.mt90.ts7'\n",
    "\n",
    "    teams_pkl = path_to_pickle + '/teams.pkl'\n",
    "    indexes_pkl = path_to_pickle + '/indexes.pkl'\n",
    "    teamsvecs_pkl = path_to_pickle + '/teamsvecs.pkl'\n",
    "\n",
    "    with open(teams_pkl, 'rb') as tb:\n",
    "        teams = pickle.load(tb)\n",
    "\n",
    "    with open(indexes_pkl, 'rb') as tb:\n",
    "        indexes = pickle.load(tb)\n",
    "\n",
    "    with open(teamsvecs_pkl, 'rb') as tb:\n",
    "        teamsvecs = pickle.load(tb)\n",
    "\n",
    "    return teams, indexes, teamsvecs\n",
    "\n",
    "\n",
    "teams, indexes, teamsvecs = load_pkl()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]))"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamsvecs['skill'][1].nonzero()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4608 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not Patent",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [51], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ix, each \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mteams\u001B[49m\u001B[43m[\u001B[49m\u001B[43mteam\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmembers):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     10\u001B[0m         name \u001B[38;5;241m=\u001B[39m teams[team]\u001B[38;5;241m.\u001B[39mmembers[ix]\u001B[38;5;241m.\u001B[39mname\n",
      "\u001B[1;31mTypeError\u001B[0m: list indices must be integers or slices, not Patent"
     ]
    }
   ],
   "source": [
    "demo_df = pd.DataFrame(columns=['loc_id', 'loc_name', 'ex_id', 'skills_columns'])\n",
    "# demo_series = pd.Series()\n",
    "for tx, team in tqdm.tqdm(enumerate(teams), total=len(teams)):\n",
    "    try:\n",
    "        team_skills = list(teamsvecs['skill'][tx].nonzero()[1])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    for ix, each in enumerate(teams[team].members):\n",
    "        try:\n",
    "            name = teams[team].members[ix].name\n",
    "            ex_id = indexes['c2i'][f'{each.id}_{name}']\n",
    "            loc_name = teams[team].members_details[ix][2]\n",
    "            loc_id = indexes['l2i'][loc_name]\n",
    "            demo_series = pd.Series(data={'loc_id':loc_id, 'loc_name':loc_name, 'ex_id':ex_id, 'skills_columns':team_skills})\n",
    "            # demo_df = demo_df.append(demo_series, ignore_index=True)\n",
    "            temp_df = pd.DataFrame([{'loc_id':loc_id, 'loc_name':loc_name, 'ex_id':ex_id, 'skills_columns':team_skills}])\n",
    "            demo_df = pd.concat([demo_df, temp_df], axis=0, ignore_index=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        # demo_dict = {'loc_id':loc_id, 'loc_name':loc_name, 'ex_id':ex_id, 'skills_columns':team_skills}\n",
    "        # break\n",
    "    # break\n",
    "demo_df.to_csv('uspt_graph_90_7.csv', index=False)\n",
    "# demo_df = pd.read_csv('uspt_graph.csv', dtype={'loc_id': np.float64, 'ex_id': np.float64})\n",
    "# print(demo_df.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "skills_matrix = torch.load('skills_matrix.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Location Nodes:  [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 26. 27. 25. 31. 29. 32. 33. 35. 36. 37. 38.\n",
      " 40. 41. 42. 43. 45. 46. 47. 48. 39. 44. 51. 52. 55. 28. 56. 57. 54. 59.\n",
      " 60. 58. 30. 61. 63. 50. 64. 65. 66. 70. 68. 69.]\n",
      "Total Number of Unique Location Nodes:  66\n",
      "\n",
      "Unique Locations:  ['JP' 'KR' 'DE' 'US' 'TW' 'CN' 'NL' 'IN' 'HU' 'IL' 'FI' 'AT' 'RU' 'SE'\n",
      " 'SG' 'IT' 'MX' 'GB' 'CH' 'CA' 'IE' 'FR' 'AU' 'DK' 'SA' 'JO' 'ES' 'BE'\n",
      " 'BR' 'HK' 'DZ' 'CZ' 'CY' 'PL' 'KE' 'VN' 'AR' 'RO' 'PT' 'TH' 'ZA' 'UA'\n",
      " 'CL' 'TR' 'EG' 'CR' 'DT' 'ID' 'BG' 'NO' 'LI' 'PH' 'LU' 'IR' 'GR' 'PK'\n",
      " 'NZ' 'DD' 'AE' 'MY' 'GE' 'KY' 'SK' 'TT' 'BB' 'JE']\n",
      "Total Number of Unique Locations:  66\n",
      "\n",
      "Unique Expert Nodes:  [0.0000e+00 1.0000e+00 2.0000e+00 ... 1.3628e+04 1.3629e+04 1.3630e+04]\n",
      "Total Number of Experts:  13631\n",
      "\n",
      "Edge Index Loc to Expert:  tensor([[  0.,   0.,   0.,  ...,   3.,   3.,   3.],\n",
      "        [  0.,   1.,   2.,  ..., 681., 682., 679.]], dtype=torch.float64)\n",
      "Shape of Tensor for Edge Index:  torch.Size([2, 629521])\n"
     ]
    }
   ],
   "source": [
    "unique_loc_nodes = demo_df['loc_id'].unique()\n",
    "unique_loc_names = demo_df['loc_name'].unique()\n",
    "unique_ex_nodes = demo_df['ex_id'].unique()\n",
    "\n",
    "edge_index_loc_to_expert = torch.stack([torch.from_numpy(demo_df['loc_id'].values.astype('float64')), torch.from_numpy(demo_df['ex_id'].values.astype('float64'))], dim=0)\n",
    "\n",
    "print('Unique Location Nodes: ', unique_loc_nodes)\n",
    "print('Total Number of Unique Location Nodes: ', len(unique_loc_nodes))\n",
    "print()\n",
    "print('Unique Locations: ', unique_loc_names)\n",
    "print('Total Number of Unique Locations: ', len(unique_loc_names))\n",
    "print()\n",
    "print('Unique Expert Nodes: ', unique_ex_nodes)\n",
    "print('Total Number of Experts: ', len(unique_ex_nodes))\n",
    "print()\n",
    "print('Edge Index Loc to Expert: ', edge_index_loc_to_expert)\n",
    "print('Shape of Tensor for Edge Index: ', edge_index_loc_to_expert.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001B[1mlocation\u001B[0m={ node_id=[66] },\n",
      "  \u001B[1mexperts\u001B[0m={\n",
      "    node_id=[629521],\n",
      "    x=[24, 111]\n",
      "  },\n",
      "  \u001B[1m(location, of, experts)\u001B[0m={ edge_index=[2, 629521] },\n",
      "  \u001B[1m(experts, rev_of, location)\u001B[0m={ edge_index=[2, 629521] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "data[\"location\"].node_id = torch.Tensor(unique_loc_nodes.astype('int8')).type(torch.LongTensor)\n",
    "data[\"experts\"].node_id = torch.Tensor(demo_df['ex_id'].astype('int8')).type(torch.LongTensor)\n",
    "# data[\"location\"].node_id = torch.Tensor(unique_loc_nodes.astype('float64'))\n",
    "# data[\"experts\"].node_id = torch.Tensor(unique_ex_nodes.astype('float64'))\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "data[\"experts\"].x = skills_matrix.type(torch.int8).type(torch.LongTensor)\n",
    "data[\"location\", \"of\", \"experts\"].edge_index = edge_index_loc_to_expert.type(torch.int8).type(torch.LongTensor)\n",
    "\n",
    "# For Message Passing in both the directions\n",
    "transform = T.Compose([T.ToUndirected()])\n",
    "data = transform(data)\n",
    "\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "torch.save(data, 'uspt_hetero.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "<1x69679 sparse matrix of type '<class 'numpy.float64'>'\n\twith 10 stored elements in List of Lists format>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_skills = demo_df['skills_columns'][0]\n",
    "total_skills = teamsvecs['skill'].shape[1]\n",
    "dummy_array = np.zeros([1,total_skills], dtype=float)\n",
    "dummy_array[0, dummy_skills] = 1\n",
    "dummy_sparse = sparse.lil_matrix(dummy_array)\n",
    "dummy_sparse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: 0                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n1                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n2                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n3                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n4         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...\n                                ...                        \n629516    [1939, 5335, 5337, 5402, 7638, 15937, 21152, 2...\n629517                  [12446, 14458, 14460, 14462, 23855]\n629518                  [12446, 14458, 14460, 14462, 23855]\n629519                  [12446, 14458, 14460, 14462, 23855]\n629520                  [12446, 14458, 14460, 14462, 23855]\nName: skills_columns, Length: 629521, dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [27], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mast\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mliteral_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdemo_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mskills_columns\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\ast.py:105\u001B[0m, in \u001B[0;36mliteral_eval\u001B[1;34m(node_or_string)\u001B[0m\n\u001B[0;32m    103\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m left \u001B[38;5;241m-\u001B[39m right\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _convert_signed_num(node)\n\u001B[1;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_or_string\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\ast.py:104\u001B[0m, in \u001B[0;36mliteral_eval.<locals>._convert\u001B[1;34m(node)\u001B[0m\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    103\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m left \u001B[38;5;241m-\u001B[39m right\n\u001B[1;32m--> 104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_convert_signed_num\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\ast.py:78\u001B[0m, in \u001B[0;36mliteral_eval.<locals>._convert_signed_num\u001B[1;34m(node)\u001B[0m\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     77\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m operand\n\u001B[1;32m---> 78\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_convert_num\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\ast.py:69\u001B[0m, in \u001B[0;36mliteral_eval.<locals>._convert_num\u001B[1;34m(node)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_convert_num\u001B[39m(node):\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, Constant) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(node\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mcomplex\u001B[39m):\n\u001B[1;32m---> 69\u001B[0m         \u001B[43m_raise_malformed_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m node\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\ast.py:66\u001B[0m, in \u001B[0;36mliteral_eval.<locals>._raise_malformed_node\u001B[1;34m(node)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_raise_malformed_node\u001B[39m(node):\n\u001B[1;32m---> 66\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmalformed node or string: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnode\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: malformed node or string: 0                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n1                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n2                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n3                            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n4         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...\n                                ...                        \n629516    [1939, 5335, 5337, 5402, 7638, 15937, 21152, 2...\n629517                  [12446, 14458, 14460, 14462, 23855]\n629518                  [12446, 14458, 14460, 14462, 23855]\n629519                  [12446, 14458, 14460, 14462, 23855]\n629520                  [12446, 14458, 14460, 14462, 23855]\nName: skills_columns, Length: 629521, dtype: object"
     ]
    }
   ],
   "source": [
    "x = ast.literal_eval(demo_df['skills_columns'])\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills Matrix Shape, X:  24\n",
      "Skills Matrix Shape, Y:  111\n"
     ]
    }
   ],
   "source": [
    "print('Skills Matrix Shape, X: ', len(demo_df['skills_columns'])) #629521\n",
    "print('Skills Matrix Shape, Y: ',teamsvecs['skill'].shape[1]) #69679"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Matrix\n",
      "torch.Size([629521, 69679])\n",
      "Dr. Fani\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 629521/629521 [03:54<00:00, 2679.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([629521, 69679])\n"
     ]
    }
   ],
   "source": [
    "# total_skills = teamsvecs['skill'].shape[1]\n",
    "# skills_df = pd.DataFrame(columns=['skx', 'skills'])\n",
    "# skills_list = list()\n",
    "print('Creating Matrix')\n",
    "skills_matrix = torch.zeros(size=(629521, 69679), dtype=bool)\n",
    "print(skills_matrix.shape)\n",
    "print('Dr. Fani')\n",
    "for sx, sk in tqdm.tqdm(enumerate(demo_df['skills_columns']), total=len(demo_df['skills_columns'])):\n",
    "    skill_zeros = torch.from_numpy(np.zeros([1, 69679], dtype=bool))\n",
    "    sk = ast.literal_eval(sk)\n",
    "    # print(skill_zeros.shape)\n",
    "    skill_zeros[0, sk] = 1\n",
    "    # skills_list.append(skill_zeros)\n",
    "    skills_matrix[sx, :] = skill_zeros\n",
    "    # break\n",
    "    # skills_temp = pd.DataFrame({'skx':skx, 'skills':skill_zeros.tolist()})\n",
    "    # skills_df = pd.concat([skills_df, skills_temp], axis=0, ignore_index=True)\n",
    "    # break\n",
    "# skills_sparse = sparse.lil_matrix(sk_arr)\n",
    "print(skills_matrix.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# torch.save(skills_matrix, 'skills_matrix.pt')\n",
    "torch.save(skills_matrix, 'skills_matrix_90_5.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skills_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [33], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mskills_list\u001B[49m)\n\u001B[0;32m      2\u001B[0m first_sk \u001B[38;5;241m=\u001B[39m skills_list[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m      3\u001B[0m second_sk \u001B[38;5;241m=\u001B[39m skills_list[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'skills_list' is not defined"
     ]
    }
   ],
   "source": [
    "first_sk = skills_list[0]\n",
    "second_sk = skills_list[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_sk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfirst_sk\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'first_sk' is not defined"
     ]
    }
   ],
   "source": [
    "first_sk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skills_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [29], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(\u001B[43mskills_list\u001B[49m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mskills_list.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'skills_list' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(skills_list,'skills_list.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 43864393759 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m stacked_skills \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mskills_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 43864393759 bytes."
     ]
    }
   ],
   "source": [
    "stacked_skills = torch.cat(skills_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacked_skills.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(stacked_skills, 'stacked_skills.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.,  ..., 0., 0., 0.]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(skills_list[0]).to(torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dummy_sparse.data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dummy_array.nonzero()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64))"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_skills = teamsvecs['skill'].shape[1]\n",
    "total_skills"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uspt:\n",
      "===========\n"
     ]
    },
    {
     "data": {
      "text/plain": "        loc_id loc_name  ex_id  \\\n0            0       JP      0   \n1            0       JP      1   \n2            0       JP      2   \n3            0       JP      3   \n4            0       JP      4   \n...        ...      ...    ...   \n629458       3       US    608   \n629459       3       US    680   \n629460       3       US    681   \n629461       3       US    682   \n629462       3       US    679   \n\n                                                   skills  \n0       H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...  \n1       H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...  \n2       H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...  \n3       H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...  \n4       B41J15/005B41J15/04B65H29/60B65H35/0006B41J29/...  \n...                                                   ...  \n629458  B05D3/0254C08G12/043B05D1/02C08G12/08C09D161/2...  \n629459  B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...  \n629460  B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...  \n629461  B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...  \n629462  B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...  \n\n[629463 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loc_id</th>\n      <th>loc_name</th>\n      <th>ex_id</th>\n      <th>skills</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>JP</td>\n      <td>0</td>\n      <td>H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>JP</td>\n      <td>1</td>\n      <td>H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>JP</td>\n      <td>2</td>\n      <td>H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>JP</td>\n      <td>3</td>\n      <td>H01L41/297B41J2/14233H01L41/0471B41J2/14201B41...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>JP</td>\n      <td>4</td>\n      <td>B41J15/005B41J15/04B65H29/60B65H35/0006B41J29/...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>629458</th>\n      <td>3</td>\n      <td>US</td>\n      <td>608</td>\n      <td>B05D3/0254C08G12/043B05D1/02C08G12/08C09D161/2...</td>\n    </tr>\n    <tr>\n      <th>629459</th>\n      <td>3</td>\n      <td>US</td>\n      <td>680</td>\n      <td>B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...</td>\n    </tr>\n    <tr>\n      <th>629460</th>\n      <td>3</td>\n      <td>US</td>\n      <td>681</td>\n      <td>B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...</td>\n    </tr>\n    <tr>\n      <th>629461</th>\n      <td>3</td>\n      <td>US</td>\n      <td>682</td>\n      <td>B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...</td>\n    </tr>\n    <tr>\n      <th>629462</th>\n      <td>3</td>\n      <td>US</td>\n      <td>679</td>\n      <td>B25J15/0633B25J15/0625B25J15/0691B25J15/0658B6...</td>\n    </tr>\n  </tbody>\n</table>\n<p>629463 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uspt_path = 'link_df_75_3_skills.csv'\n",
    "\n",
    "print('uspt:')\n",
    "print('===========')\n",
    "uspt_df = pd.read_csv(uspt_path)\n",
    "uspt_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Before Splitting HeteroData(\n",
      "  \u001B[1mlocation\u001B[0m={ node_id=[3] },\n",
      "  \u001B[1mexperts\u001B[0m={\n",
      "    node_id=[24],\n",
      "    x=[24, 111]\n",
      "  },\n",
      "  \u001B[1mmovie\u001B[0m={},\n",
      "  \u001B[1m(location, of, experts)\u001B[0m={ edge_index=[2, 24] },\n",
      "  \u001B[1m(experts, rev_of, location)\u001B[0m={ edge_index=[2, 24] }\n",
      ")\n",
      "==============\n",
      "\n",
      "Training data:\n",
      "==============\n",
      "HeteroData(\n",
      "  \u001B[1mlocation\u001B[0m={ node_id=[3] },\n",
      "  \u001B[1mexperts\u001B[0m={\n",
      "    node_id=[24],\n",
      "    x=[24, 111]\n",
      "  },\n",
      "  \u001B[1mmovie\u001B[0m={},\n",
      "  \u001B[1m(location, of, experts)\u001B[0m={\n",
      "    edge_index=[2, 14],\n",
      "    edge_label=[6],\n",
      "    edge_label_index=[2, 6]\n",
      "  },\n",
      "  \u001B[1m(experts, rev_of, location)\u001B[0m={ edge_index=[2, 14] }\n",
      ")\n",
      "\n",
      "Validation data:\n",
      "================\n",
      "HeteroData(\n",
      "  \u001B[1mlocation\u001B[0m={ node_id=[3] },\n",
      "  \u001B[1mexperts\u001B[0m={\n",
      "    node_id=[24],\n",
      "    x=[24, 111]\n",
      "  },\n",
      "  \u001B[1mmovie\u001B[0m={},\n",
      "  \u001B[1m(location, of, experts)\u001B[0m={\n",
      "    edge_index=[2, 20],\n",
      "    edge_label=[6],\n",
      "    edge_label_index=[2, 6]\n",
      "  },\n",
      "  \u001B[1m(experts, rev_of, location)\u001B[0m={ edge_index=[2, 20] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.10,\n",
    "    num_test=0.10,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"location\", \"of\", \"experts\"),\n",
    "    rev_edge_types=(\"experts\", \"rev_of\", \"location\"),\n",
    ")\n",
    "\n",
    "print('Data Before Splitting', data)\n",
    "print(\"==============\")\n",
    "print()\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"================\")\n",
    "print(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  \u001B[1mlocation\u001B[0m={ node_id=[3] },\n",
      "  \u001B[1mexperts\u001B[0m={\n",
      "    node_id=[22],\n",
      "    x=[22, 111]\n",
      "  },\n",
      "  \u001B[1mmovie\u001B[0m={},\n",
      "  \u001B[1m(location, of, experts)\u001B[0m={\n",
      "    edge_index=[2, 14],\n",
      "    edge_label=[18],\n",
      "    edge_label_index=[2, 18],\n",
      "    input_id=[6]\n",
      "  },\n",
      "  \u001B[1m(experts, rev_of, location)\u001B[0m={ edge_index=[2, 14] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "edge_label_index = train_data[\"location\", \"of\", \"experts\"].edge_label_index\n",
    "edge_label = train_data[\"location\", \"of\", \"experts\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"location\", \"of\", \"experts\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import tqdm\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [38], line 64\u001B[0m\n\u001B[0;32m     55\u001B[0m         pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(\n\u001B[0;32m     56\u001B[0m             x_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     57\u001B[0m             x_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperts\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     58\u001B[0m             data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperts\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39medge_label_index,\n\u001B[0;32m     59\u001B[0m         )\n\u001B[0;32m     61\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pred\n\u001B[1;32m---> 64\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mprint\u001B[39m(model)\n",
      "Cell \u001B[1;32mIn [38], line 41\u001B[0m, in \u001B[0;36mModel.__init__\u001B[1;34m(self, hidden_channels)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgnn \u001B[38;5;241m=\u001B[39m GNN(hidden_channels)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Convert GNN model into a heterogeneous variant:\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgnn \u001B[38;5;241m=\u001B[39m \u001B[43mto_hetero\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier \u001B[38;5;241m=\u001B[39m Classifier()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:119\u001B[0m, in \u001B[0;36mto_hetero\u001B[1;34m(module, metadata, aggr, input_map, debug)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03mwhich node representations are learned for each node type in\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m:obj:`metadata[0]`, and messages are exchanged between each edge type in\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;124;03m        transformation in debug mode. (default: :obj:`False`)\u001B[39;00m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    118\u001B[0m transformer \u001B[38;5;241m=\u001B[39m ToHeteroTransformer(module, metadata, aggr, input_map, debug)\n\u001B[1;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\site-packages\\torch_geometric\\nn\\fx.py:157\u001B[0m, in \u001B[0;36mTransformer.transform\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m is_global_pooling_op(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule, op, node\u001B[38;5;241m.\u001B[39mtarget):\n\u001B[0;32m    156\u001B[0m         op \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcall_global_pooling_module\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 157\u001B[0m     \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# Remove all unused nodes in the computation graph, i.e., all nodes\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# which have been replaced by node type-wise or edge type-wise variants\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;66;03m# but which are still present in the computation graph.\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;66;03m# We do this by iterating over the computation graph in reversed order,\u001B[39;00m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m# and try to remove every node. This does only succeed in case there\u001B[39;00m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m# are no users of that node left in the computation graph.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mnodes)):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:295\u001B[0m, in \u001B[0;36mToHeteroTransformer.call_method\u001B[1;34m(self, node, target, name)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minserting_after(node)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata[\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_edge_level(node))]:\n\u001B[1;32m--> 295\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_args_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    296\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mcreate_node(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcall_method\u001B[39m\u001B[38;5;124m'\u001B[39m, target\u001B[38;5;241m=\u001B[39mtarget,\n\u001B[0;32m    297\u001B[0m                                  args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m    298\u001B[0m                                  name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey2str(key)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minserting_after(out)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:398\u001B[0m, in \u001B[0;36mToHeteroTransformer.map_args_kwargs\u001B[1;34m(self, node, key)\u001B[0m\n\u001B[0;32m    395\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    396\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m--> 398\u001B[0m args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_recurse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m {k: _recurse(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m    400\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m args, kwargs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:398\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    395\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    396\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m--> 398\u001B[0m args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[43m_recurse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39margs)\n\u001B[0;32m    399\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m {k: _recurse(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m    400\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m args, kwargs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pyg6\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:388\u001B[0m, in \u001B[0;36mToHeteroTransformer.map_args_kwargs.<locals>._recurse\u001B[1;34m(value)\u001B[0m\n\u001B[0;32m    383\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    384\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfind_by_name(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey2str(key[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m    385\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfind_by_name(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m__\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey2str(key[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m    386\u001B[0m         )\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 388\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {k: _recurse(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m value\u001B[38;5;241m.\u001B[39mitems()}\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        # Define a 2-layer GNN computation graph.\n",
    "        # Use a *single* `ReLU` non-linearity in-between.\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Our final classifier applies the dot-product between source and destination\n",
    "# node embeddings to derive edge-level predictions:\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"location\"].num_nodes, hidden_channels)\n",
    "        self.movie_emb = torch.nn.Embedding(data[\"experts\"].num_nodes, hidden_channels)\n",
    "\n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "            \"location\": self.user_emb(data[\"location\"].node_id),\n",
    "            \"experts\": self.movie_lin(data[\"experts\"].x) + self.movie_emb(data[\"experts\"].node_id),\n",
    "        }\n",
    "\n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"location\"],\n",
    "            x_dict[\"experts\"],\n",
    "            data[\"location\", \"of\", \"experts\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=64)\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import tqdm\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}